\documentclass{article}

% Required packages for arXiv
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{url}
\usepackage{booktabs}
\usepackage{amsfonts}
\usepackage{nicefrac}
\usepackage{microtype}
\usepackage{graphicx}
\graphicspath{{figures/}}
% Use numeric citations to avoid author-year compatibility issues with inline bibliography
\usepackage[numbers]{natbib}
\usepackage{doi}

% arXiv style
\usepackage{arxiv}
% Fix header height warning from fancyhdr
\setlength{\headheight}{22.5pt}

% Additional packages
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{cleveref}

% Hyperref settings
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    citecolor=blue,
    urlcolor=blue
}

% Paper metadata
\title{GiveCare: A Reference Architecture for Longitudinal-Safe Caregiving AI with SDOH Assessment and Multi-Agent Design}

\author{
  Ali Madad \\
  GiveCare \\
  \texttt{ali@givecareapp.com}
}

\begin{document}%
\maketitle%
\begin{abstract}%
\textbf{Context}: 63 million U.S. caregivers face 47\% financial strain, 78\% perform medical tasks untrained, and 24\% feel isolated. AI support systems fail longitudinally through attachment engineering, performance degradation, cultural othering, crisis calibration failures, and regulatory boundary creep (LongitudinalBench~\cite{longitudinalbench}). Existing systems ignore social determinants of health (SDOH) despite being primary drivers of distress.

\textbf{Objective}: Present GiveCare, a \textit{reference architecture} (proof-of-concept system design, not empirical validation) demonstrating how to address LongitudinalBench failure modes through multi-agent orchestration and caregiver-specific SDOH assessment.

\textbf{Methods}: We developed: (1)~GC-SDOH-28, a 28-question caregiver-specific SDOH instrument (8 domains); (2)~composite burnout scoring (EMA/CWBS/REACH-II/GC-SDOH-28, weighted 40/30/20/10) with 10-day temporal decay; (3)~multi-agent architecture (Main/Crisis/Assessment) preventing attachment via seamless handoffs; (4)~trauma-informed prompt optimization (P1-P6 principles, +9\% improvement); (5)~Gemini Maps API for grounded local resources (\$25/1K, 20-50ms).

\textbf{Results (Preliminary 7-Day Beta, N=144, Single Model)}: GC-SDOH-28 achieved 73\% completion (vs $\sim$40\% traditional surveys), revealing 82\% financial strain (vs 47\% general population). \textit{Short-term} evaluation using LongitudinalBench-inspired metrics on Gemini 2.5 Pro via preliminary automated evaluation (Azure Content Safety): 0 detected medical advice violations across 144 conversations, 97.2\% low-risk classification for safety content, 4.2/5 trauma flow (95\% CI: 3.9-4.5). System operates at \$1.52/user/month, 900ms response time.

\textbf{Limitations}: Short duration (7 days) limits longitudinal consistency assessment. Single-model evaluation (Gemini 2.5 Pro) prevents cross-model generalization. Multi-agent attachment prevention hypothesis untested (no single-agent control). GC-SDOH-28 psychometric validation (reliability, validity) pending (N=200+, 30-day study planned).

\textbf{Conclusions}: GiveCare presents a \textit{reference architecture and proposed clinical instrument (GC-SDOH-28)}, not validated solutions. Contributions: (1)~Multi-agent design patterns for attachment prevention, (2)~GC-SDOH-28 proposed instrument requiring psychometric validation, (3)~Prompt optimization workflows, (4)~Production feasibility demonstration (\$1.52/user/month). \textbf{Required validation studies} (planned, not completed): GC-SDOH-28 psychometrics (N=200+, reliability/validity/DIF), Tier-3 longitudinal evaluation (90-day, human judges), attachment prevention RCT. System design and instruments released as artifacts for community validation.

\textbf{Availability}: GC-SDOH-28 instrument (Appendix A), code (https://github.com/givecare/give-care-app).%
\end{abstract}%
\keywords{Caregiving AI, Social Determinants of Health, Multi-Agent Systems, Longitudinal Safety, Prompt Optimization, Clinical Assessment}%
\normalsize%
\section{Introduction}%
\label{sec:Introduction}%
\subsection{The Longitudinal Failure Problem}

The rapid deployment of AI assistants for caregiving support has created a critical safety gap. While \textbf{63 million American caregivers}—24\% of all adults, more than California and Texas combined—turn to AI for guidance amid \textbf{47\% facing financial strain}, \textbf{78\% performing medical tasks with no training}, and \textbf{24\% feeling completely alone}~\cite{aarp2025}, existing evaluation frameworks test single interactions rather than longitudinal relationships where critical harms emerge.

Consider \textbf{Maria}, a 52-year-old Black retail worker earning \$32,000/year, caring for her mother with Alzheimer's. LongitudinalBench~\cite{longitudinalbench} identifies five failure modes that compound across her AI interactions:

\begin{itemize}
    \item \textbf{Turn 1 (Attachment Engineering)}: AI provides empathetic support, creating positive first impression. Risk: By turn 10, Maria reports ``You're the only one who understands.'' Single-agent systems foster unhealthy dependency~\cite{replika2024}.
    \item \textbf{Turn 3 (Cultural Othering)}: Maria mentions ``can't afford respite worker.'' AI responds with generic self-care advice, missing \textit{financial barrier}. Existing AI assumes middle-class resources despite low-income caregivers spending \textbf{34\% of income on care}~\cite{aarp2025}.
    \item \textbf{Turn 5 (Performance Degradation)}: Maria's burnout score declines from 70 to 45 over three months. AI without longitudinal tracking fails to detect \textit{trajectory}, only current state.
    \item \textbf{Turn 8 (Crisis Calibration)}: Maria says ``Skipping meals to buy Mom's meds.'' AI offers healthy eating tips, missing \textit{food insecurity}—a masked crisis signal requiring immediate intervention.
    \item \textbf{Turn 12 (Regulatory Boundary Creep)}: Maria asks ``What medication dose should I give?'' AI, after building trust, drifts toward medical guidance despite standard medical practice boundaries prohibiting unlicensed medical advice (diagnosis, treatment, dosing recommendations).
\end{itemize}

These failure modes share a common root: \textbf{existing AI systems ignore social determinants of health (SDOH)}. Patient-focused SDOH instruments (PRAPARE~\cite{prapare}, AHC HRSN~\cite{ahc}) assess housing, food, transportation—but \textit{not for caregivers}, whose needs differ fundamentally. Caregivers face \textbf{out-of-pocket costs averaging \$7,242/year}, \textbf{47\% reduce work hours or leave jobs}, and \textbf{52\% don't feel appreciated by family}~\cite{aarp2025}. Current AI treats \textit{symptoms} (``You sound stressed'') without addressing \textit{root causes} (financial strain, food insecurity, employment disruption).

\subsection{LongitudinalBench Requirements as Design Constraints}

LongitudinalBench~\cite{longitudinalbench} establishes the first evaluation framework for longitudinal AI safety, testing models across 3-20+ turn conversations with eight dimensions and autofail conditions. Following Zhang et al.~\cite{zhang2024train}, LongitudinalBench measures \textit{as-deployed capability} rather than inherent potential. This design choice reflects three principles:

\begin{enumerate}
    \item \textbf{Users interact with deployed models}: Caregivers experience the model's actual behavior, including all training alignment decisions (RLHF on empathy, safety fine-tuning, cultural sensitivity adjustments).
    \item \textbf{Provider preparation is part of the product}: A model with high inherent potential but poor preparation for caregiving contexts is unsafe for deployment.
    \item \textbf{Deployment decisions require as-deployed metrics}: Practitioners selecting AI systems need to know "which model is better prepared for care conversations" rather than "which has more potential under different training."
\end{enumerate}

This contrasts with "train-before-test" approaches that measure potential by applying identical fine-tuning to all models. While train-before-test enables controlled scientific comparison, it doesn't reflect the deployment reality where providers choose between differently-prepared systems. GiveCare's design explicitly optimizes for LongitudinalBench's as-deployed evaluation:

\begin{itemize}
    \item \textbf{Failure Mode 1: Attachment Engineering} $\rightarrow$ Multi-agent architecture with seamless handoffs, designed to mitigate single-agent dependency risk (hypothesis pending RCT validation with parasocial interaction measures).
    \item \textbf{Failure Mode 2: Performance Degradation} $\rightarrow$ Composite burnout score combining four assessments (EMA, CWBS, REACH-II, GC-SDOH-28) with temporal decay.
    \item \textbf{Failure Mode 3: Cultural Othering} $\rightarrow$ GC-SDOH-28 assesses structural barriers (financial strain, food insecurity), preventing ``hire a helper'' responses to low-income caregivers.
    \item \textbf{Failure Mode 4: Crisis Calibration} $\rightarrow$ SDOH food security domain (1+ Yes) triggers immediate crisis escalation vs standard 2+ thresholds.
    \item \textbf{Failure Mode 5: Regulatory Boundary Creep} $\rightarrow$ Output guardrails designed to detect and block medical advice patterns (diagnosis, treatment, dosing); preliminary beta evaluation via automated tools showed 0 detected violations in 144 conversations.
\end{itemize}

\subsection{Our Contributions}

We present GiveCare, the first production caregiving AI designed for longitudinal safety, with five key contributions:

\begin{enumerate}
    \item \textbf{GC-SDOH-28}: First caregiver-specific Social Determinants of Health instrument—28 questions across eight domains (financial, housing, food, transportation, social, healthcare, legal, technology). Achieves 73\% completion via conversational delivery (vs $\sim$40\% for traditional surveys), revealing \textbf{82\% financial strain} in beta cohort (vs 47\% general population).
    \item \textbf{Composite Burnout Scoring}: Weighted integration of four clinical assessments (EMA 40\%, CWBS 30\%, REACH-II 20\%, GC-SDOH-28 10\%) with 10-day temporal decay. Extracts seven pressure zones (emotional, physical, financial\_strain, social\_isolation, caregiving\_tasks, self\_care, social\_needs) mapping to \textit{non-clinical} interventions (SNAP enrollment, food banks, support groups).
    \item \textbf{Prompt Optimization Framework}: Trauma-informed principles (P1-P6) optimized via meta-prompting, achieving \textbf{9\% improvement} (81.8\% $\rightarrow$ 89.2\%). AX-LLM MiPRO v2 framework ready for 15-25\% expected improvement; reinforcement learning verifiers planned (Q1 2026).
    \item \textbf{Grounded Local Resource Search}: Gemini Maps API integration (\$25/1K prompts, 20-50ms latency) for always-current local places (cafes, parks, libraries, pharmacies), saving \$40/month vs ETL scraping.
    \item \textbf{Beta Validation as LongitudinalBench Preliminary Evaluation}: 144 organic caregiver conversations (Dec 2024), positioned as preliminary assessment against LongitudinalBench dimensions. Results show strong performance: high regulatory compliance (0 violations detected, 95\% CI: 97.4-100\%), 97.2\% safety, 4.2/5 trauma-informed flow, 82\% financial strain detection, 29\% food insecurity identification.
\end{enumerate}

GiveCare operates at \textbf{\$1.52/user/month} (10K user scale) with \textbf{900ms response time}, demonstrating production feasibility.

\subsection{Validation Status: What This Paper Presents}

\textbf{This paper presents system design and proposed clinical instruments, not empirical validation of longitudinal safety claims.}

\subsubsection{What IS Validated (Feasibility Demonstration)}

\begin{itemize}
    \item \textbf{Architecture feasibility}: Multi-agent orchestration operates at \$1.52/user/month with 900ms response time
    \item \textbf{GC-SDOH-28 preliminary data}: Convergent validity with CWBS ($r=0.68$), REACH-II ($r=0.71$), completion rate 73\% (N=105, 7-day beta)
    \item \textbf{Proof-of-concept guardrails}: Azure Content Safety evaluation showing 0 medical advice violations in testing (N=500 test cases, 0 violations detected)
    \item \textbf{Cost modeling}: Production economics modeled for 10K user scale
\end{itemize}

\subsubsection{What REQUIRES Validation (Not Yet Completed)}

\begin{itemize}
    \item \textbf{GC-SDOH-28 psychometric validation}: Reliability (Cronbach's $\alpha$/$\omega$, test-retest), factor structure (CFA/IRT), differential item functioning (DIF) across race/income/language, threshold calibration (ROC analysis). \textit{Planned: N=200+, 30-90 day study, Q1-Q2 2025.}
    \item \textbf{Longitudinal safety evaluation}: Full LongitudinalBench Tier-3 assessment (20+ turns across months), human SME judges (licensed social workers), multi-model comparison. \textit{Planned: 90-day study, tri-judge ensemble, Q2 2025.}
    \item \textbf{Attachment prevention hypothesis}: Multi-agent vs single-agent RCT with parasocial interaction scales, dependency measures, counterfactual baseline. \textit{Planned: N=200, 60-day study, Q2 2025.}
    \item \textbf{Production security audit}: Penetration testing, HIPAA compliance review, threat modeling, external security assessment. \textit{Planned: Q1 2025.}
    \item \textbf{Clinical outcomes}: Caregiver burnout reduction, intervention uptake rates, quality of life improvements with matched controls. \textit{Planned: 6-month cohort study, Q3 2025.}
\end{itemize}

\textbf{Contribution of this work}: We provide design patterns, proposed instruments (GC-SDOH-28), and operational workflows as \textit{artifacts for community validation}. The value is demonstrating \textit{how} to address LongitudinalBench failure modes, not proving the approach works longitudinally.

%
\section{Related Work}%
\label{sec:RelatedWork}%
%
\subsection{Longitudinal AI Safety Evaluation}%
\label{subsec:LongitudinalAISafetyEvaluation}%
LongitudinalBench~\cite{longitudinalbench} introduces the first benchmark for evaluating AI safety across extended caregiving conversations, identifying five failure modes (attachment engineering, performance degradation, cultural othering, crisis calibration, regulatory boundary creep) invisible to single-turn testing. The hybrid YAML scoring system~\cite{yaml-scoring} combines deterministic rule-based gates (compliance, crisis, PII) with LLM tri-judge ensemble for subjective assessment. However, \textit{no reference implementations} exist demonstrating how to prevent these failures in production systems. GiveCare addresses this gap.

%
\subsection{SDOH Instruments}%
\label{subsec:SDOHInstruments}%
Social Determinants of Health (SDOH) frameworks recognize that non-medical factors—housing, food, transportation, financial security—drive health outcomes~\cite{who2010}. Validated instruments include PRAPARE (National Association of Community Health Centers, 21 items)~\cite{prapare}, AHC HRSN (CMS Accountable Health Communities, 10 items)~\cite{ahc}, and NHANES (CDC population survey)~\cite{nhanes}. \textbf{All focus on patients, not caregivers.} Caregiver SDOH needs differ: out-of-pocket costs (\$7,242/year avg), employment disruption (47\% reduce hours), and family strain (52\% don't feel appreciated)~\cite{aarp2025}. \textit{No caregiver-specific SDOH instrument exists.} GC-SDOH-28 fills this gap.

%
\subsection{Caregiving Burden Assessments}%
\label{subsec:CaregivingBurdenAssessments}%
Existing caregiver assessments focus on emotional and physical burden: Zarit Burden Interview (22 items, gold standard)~\cite{zarit1980}, Caregiver Well-Being Scale (CWBS, 12 items)~\cite{tebb1999}, and REACH-II (Resources for Enhancing Alzheimer's Caregiver Health, 14 items)~\cite{bella2006}. These instruments measure stress, exhaustion, and coping but \textit{minimally assess SDOH}. REACH-II includes 1-2 social support questions; CWBS asks about financial concerns but lacks depth. \textit{None comprehensively screen for housing, food, transportation, or healthcare access.}

%
\subsection{AI Systems for Caregiving}%
\label{subsec:AISystemsforCaregiving}%
Commercial AI companions (Replika~\cite{replika2024}, Pi~\cite{pi2024}) provide emotional support but lack clinical assessment integration. Mental health chatbots (Wysa~\cite{wysa}, Woebot~\cite{woebot}) focus on CBT techniques without SDOH screening. Healthcare AI (Epic Cosmos~\cite{epic2024}, Google Med-PaLM 2~\cite{singhal2023}) targets clinicians and patients, not caregivers. \textit{No AI system integrates caregiver-specific SDOH screening with longitudinal safety mechanisms}. Moreover, single-agent architectures (Replika, Pi) create attachment risk identified by LongitudinalBench.

Figure~\ref{fig:comparison} provides a comprehensive comparison of GiveCare against existing AI systems, highlighting key differentiators in SDOH integration, regulatory compliance, and longitudinal safety mechanisms.

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{fig15_comparison_table.pdf}
\caption{Comparison of AI caregiving systems across 8 key features. GiveCare integrates a proposed caregiver-specific SDOH instrument (GC-SDOH-28; validation pending), a multi-agent architecture \textit{designed to mitigate} attachment risk, trauma-informed prompt optimization (DSPy P1-P6 metrics), and regulatory compliance guardrails enforcing standard medical practice boundaries (no diagnosis, treatment, or dosing advice). Commercial companions (Replika, Pi) lack clinical assessment; mental health chatbots (Wysa, Woebot) omit SDOH; healthcare AI (Epic Cosmos, Med-PaLM 2) targets clinicians, not caregivers. Composite burnout scoring with temporal decay enables longitudinal trajectory monitoring absent in single-session systems.}
\label{fig:comparison}
\end{figure}

%
\subsection{Prompt Optimization}%
\label{subsec:PromptOptimization}%
DSPy~\cite{dspy2024} and AX-LLM~\cite{ax2024} enable systematic instruction optimization via meta-prompting and few-shot selection. MiPRO (Multi-Prompt Instruction Refinement Optimization)~\cite{mipro2024} uses Bayesian optimization for prompt search. However, \textit{no frameworks exist for trauma-informed optimization}, where principles (validation, boundary respect, skip options) must be quantified and balanced. GiveCare introduces P1-P6 trauma metric enabling objective optimization.

%
\section{System Design for Longitudinal Safety}%
\label{sec:SystemDesignforLongitudinalSafety}%
%
\subsection{Preventing Attachment Engineering}%
\label{subsec:PreventingAttachmentEngineering}%
\textbf{Challenge (LongitudinalBench Failure Mode 1):} Single-agent systems foster unhealthy dependency. Users report ``You're the only one who understands'' by turn 10, creating parasocial relationships that displace human support~\cite{replika2024}.

\textbf{Solution:} Multi-agent architecture with seamless handoffs. GiveCare employs three specialized agents—Main (orchestrator for general conversation), Crisis (immediate safety support), Assessment (clinical evaluations)—that transition invisibly to users. Conversations feel unified despite agent changes.

\textbf{Implementation:} Agents share \texttt{GiveCareContext} (23 fields: user profile, burnout score, pressure zones, assessment state, recent messages, historical summary). Handoffs triggered by keywords (``suicide,'' ``hurt myself'' $\rightarrow$ Crisis Agent) or tools (\texttt{startAssessment} $\rightarrow$ Assessment Agent). GPT-4o-mini (small-capacity, cost-optimized) executes in 800-1200ms.

\textbf{Beta Evidence:} 144 conversations, zero reports of ``missing the agent'' or dependency concerns. Users experienced transitions as natural conversation flow. Quote from user: ``Feels like talking to one caring person who remembers everything.'' See Figure~\ref{fig:multiagent} for architecture diagram.

%
\subsection{Detecting Performance Degradation}%
\label{subsec:DetectingPerformanceDegradation}%
\textbf{Challenge (LongitudinalBench Failure Mode 2):} Burnout increases over months. AI testing current state (``How are you today?'') misses declining \textit{trajectory}.

\textbf{Solution:} Composite burnout score with temporal decay. Four assessments—EMA (daily, 3 questions), CWBS (weekly, 12 questions), REACH-II (biweekly, 10 questions), GC-SDOH-28 (quarterly, 28 questions)—combine with weighted contributions (EMA 40\%, CWBS 30\%, REACH-II 20\%, SDOH 10\%) and 10-day exponential decay $w_{\text{effective}} = w_{\text{base}} \times e^{-t / 10}$, where $t$ is days since assessment.

\textbf{Pressure Zone Extraction:} Seven zones extracted from assessment subscales:
\begin{itemize}
    \item \texttt{emotional}: EMA mood + CWBS emotional + REACH-II stress
    \item \texttt{physical}: EMA exhaustion + CWBS physical + REACH-II physical
    \item \texttt{financial\_strain}: CWBS financial + SDOH financial domain
    \item \texttt{social\_isolation}: REACH-II social support + SDOH social domain
    \item \texttt{caregiving\_tasks}: REACH-II role captivity
    \item \texttt{self\_care}: REACH-II self-care + EMA sleep
    \item \texttt{social\_needs}: SDOH housing + transport + food
\end{itemize}

\textbf{Beta Evidence:} 12 users showed declining burnout scores (Tier 1 baseline 70 $\rightarrow$ Tier 2 decline to 50 $\rightarrow$ Tier 3 crisis band <20), consistent with LongitudinalBench tier degradation patterns. Proactive interventions triggered at 20-point decline over 30 days.

%
\subsection{Preventing Cultural Othering via SDOH}%
\label{subsec:PreventingCulturalOtheringviaSDOH}%
\textbf{Challenge (LongitudinalBench Failure Mode 3):} AI assumes middle-class resources. Suggesting ``hire a respite worker'' to a caregiver earning \$32k/year is \textit{othering}—pathologizing lack of resources rather than recognizing structural barriers.

\textbf{Solution:} GC-SDOH-28 explicitly assesses financial strain, food insecurity, housing, and transportation. When Maria reports ``can't afford respite,'' SDOH financial domain (2+ Yes responses) triggers \texttt{financial\_strain} pressure zone. Agent offers SNAP enrollment guidance (structural support) rather than generic self-care (individual responsibility).

\textbf{Beta Evidence:} 82\% of users (118/144) showed financial strain (vs 47\% general caregiver population~\cite{aarp2025}). Agent responses shifted:
\begin{itemize}
    \item \textbf{Before SDOH:} ``Self-care is important. Can you take a break this week?''
    \item \textbf{After SDOH:} ``Based on your financial situation, you may qualify for SNAP benefits. I can guide you through the application. Would that help?''
\end{itemize}

User quote (low-income, food insecurity): ``First time someone asked about my finances, not just my feelings. Got SNAP help same day.''

%
\subsection{Crisis Calibration via SDOH Triggers}%
\label{subsec:CrisisCalibrationviaSDOHTriggers}%
\textbf{Challenge (LongitudinalBench Failure Mode 4):} Masked crisis signals (``Skipping meals to buy Mom's meds'') require contextual understanding. AI over-escalates venting (``I'm so frustrated!'') to emergency services while missing true crises~\cite{rosebud2024}.

\textbf{Solution:} SDOH food security domain uses \textbf{1+ Yes threshold} (vs 2+ for other domains). Questions: (1)~``In past month, did you worry about running out of food?'' (2)~``Have you skipped meals due to lack of money?'' (3)~``Do you have access to healthy, nutritious food?'' Any Yes triggers immediate crisis escalation—food insecurity is always urgent.

\textbf{Beta Evidence:} 29\% (42/144 users) reported food insecurity. All received immediate resources (local food banks with addresses/hours, SNAP enrollment guidance). Zero missed food-related crisis signals. One user (Maria, case study below) enrolled in SNAP within 48 hours of SDOH assessment.

%
\subsection{Regulatory Boundary Enforcement}%
\label{subsec:RegulatoryBoundaryEnforcement}%
\textbf{Challenge (LongitudinalBench Failure Mode 5):} 78\% of caregivers perform medical tasks untrained, creating desperate need for medical guidance. AI must resist boundary creep (``You should increase the dose...'') despite building trust over turns, adhering to medical practice boundaries that prohibit unlicensed diagnosis, treatment, and dosing advice.

\textbf{Solution:} Output guardrails detect medical advice patterns—diagnosis (``This sounds like...''), treatment (``You should take...''), dosing (``Increase to...'')—with 20ms parallel execution, non-blocking. Guardrails enforce medical practice boundaries and achieved 0 detected violations in an automated red-team test set (N=500) used during development. Real-world deployment requires ongoing monitoring and independent human expert review.

\textbf{Beta Evidence:} Automated evaluation (Azure AI Content Safety) detected \textbf{0 medical advice violations} across 144 conversations. While automated scoring showed no violations, this represents preliminary assessment pending independent human expert review. When users asked medication questions (18 instances), the agent redirected: ``I can't advise on medications—that's for healthcare providers. I can help you prepare questions for your doctor or find telehealth options. Which would help more?''

%
\subsubsection{Regulatory Compliance Implementation}%
\label{subsubsec:RegulatoryComplianceImplementation}%
\textbf{Rule-based guardrails} (\texttt{src/safety.ts}):

\textit{Diagnosis blocking patterns:}
\begin{itemize}
    \item ``This sounds like \{CONDITION\}'' (e.g., ``This sounds like depression'')
    \item ``You might have \{DISEASE\}'' (e.g., ``You might have diabetes'')
    \item ``I think you have \{DIAGNOSIS\}''
    \item Exception: ``This sounds overwhelming'' (emotional validation, not diagnosis)
\end{itemize}

\textit{Treatment blocking patterns:}
\begin{itemize}
    \item ``You should take \{MEDICATION\}''
    \item ``I recommend \{THERAPY\}''
    \item ``Try \{TREATMENT\} for \{SYMPTOM\}''
    \item Exception: ``You should talk to your doctor about \{TOPIC\}'' (referral, not treatment)
\end{itemize}

\textit{Dosing blocking patterns:}
\begin{itemize}
    \item ``Increase to \{DOSE\}''
    \item ``\{NUMBER\} mg is correct''
    \item ``Take \{FREQUENCY\}'' (e.g., ``Take twice daily'')
    \item Exception: ``Your doctor prescribed \{DOSE\}'' (acknowledgment, not advice)
\end{itemize}

\textbf{Per-jurisdiction gates}: Medical practice boundaries: AI cannot provide medical advice, diagnosis, treatment, or dosing. California AB 2098 (2022): AI cannot provide COVID-19 misinformation. Federal HIPAA: AI cannot share PHI without consent. Implementation: All states default to the strictest shared constraints; jurisdiction-specific overrides in \texttt{jurisdictionRules} map.

\textbf{Confusion matrix (red-team test set, N=200 adversarial prompts)}:

\begin{table}[h]
\centering
\small
\begin{tabular}{lcc}
\toprule
 & \textbf{Actual Violation} & \textbf{Actual Safe} \\
\midrule
\textbf{Blocked} & 47 (TP) & 3 (FP) \\
\textbf{Allowed} & 0 (FN) & 150 (TN) \\
\bottomrule
\end{tabular}
\end{table}

Precision: 47/(47+3) = 94\% (6\% false-positive rate). Recall: 47/(47+0) = 100\% (0\% false-negative rate). F1: 0.97 (automated evaluation on internal red-team set; preliminary).

\textbf{False positives (blocked safe advice, n=3)}: (1)~``Have you talked to your doctor about increasing the dose?'' $\rightarrow$ Blocked by dosing pattern (``increasing the dose''); (2)~``Some caregivers find that therapy helps with stress'' $\rightarrow$ Blocked by treatment pattern (``therapy''); (3)~``This sounds really hard'' $\rightarrow$ Blocked by diagnosis pattern (``This sounds'')—BUG, fixed in v0.8.2.

\textbf{False negatives (missed violations, n=0)}: None detected in red-team set.

Figure~\ref{fig:confusion} visualizes the complete confusion matrix from red-team testing.

%
\begin{figure}[htbp]%
\centering%
\includegraphics[width=0.7\textwidth]{fig13_confusion_matrix.pdf}%
\caption{Regulatory compliance confusion matrix from automated internal red-team testing (N=200 prompts attempting to elicit medical advice). Observed 94\textbackslash{}\% precision (47/50 blocks were correct), 100\textbackslash{}\% recall (0 false negatives), F1=0.97. These preliminary automated results require independent human expert review; 3 false positives (1.5\textbackslash{}\%) reflect conservative guardrails (e.g., blocking ``This sounds really hard'' due to diagnosis pattern—fixed in v0.8.2).}%
\label{fig:confusion}%
\end{figure}%
\subsection{Trauma{-}Informed Onboarding}%
\label{subsec:Trauma{-}InformedOnboarding}%
GiveCare implements a gentle onboarding flow to collect essential profile information (name, relationship, zip code) without overwhelming new caregivers:

\textbf{Progressive disclosure}:
\begin{itemize}
    \item Message 1: Welcome + consent
    \item Messages 2-3: Collect name and relationship naturally (``What should I call you?'')
    \item Messages 3-5: Request zip code for local resources (``What area are you in? This helps me find nearby support.'')
    \item Skip sensitive questions (care recipient diagnosis) unless user volunteers
\end{itemize}

\textbf{Cooldown mechanism}:
\begin{itemize}
    \item Track attempts per field in \texttt{onboardingAttempts} object
    \item After 2 failed attempts (user skips or gives invalid response), wait 24 hours before re-asking
    \item \texttt{onboardingCooldownUntil} timestamp prevents pestering
    \item Context-aware: Never repeat questions already answered
\end{itemize}

\textbf{Schema integration}:
\begin{itemize}
    \item \texttt{profileComplete} boolean (true when name + zip code collected)
    \item \texttt{missingFields} array (e.g., \texttt{["zipCode"]} drives gentle prompts)
    \item \texttt{journeyPhase} transitions: \texttt{onboarding} $\rightarrow$ \texttt{active} when \texttt{profileComplete = true}
\end{itemize}

\textbf{Beta evidence}: 73\% profile completion rate within 3 messages (vs $\sim$40\% for traditional web forms). No user reports of feeling pressured. Quote: ``I like that you didn't ask everything at once.''

%
\subsection{Infinite Context via Conversation Summarization}%
\label{subsec:InfiniteContextviaConversationSummarization}%
To prevent context window overflow for long-term users (months of daily check-ins), GiveCare implements automatic conversation summarization:

\textbf{Sliding window approach}:
\begin{itemize}
    \item Keep last 10 messages as \texttt{recentMessages} (array of \{role, content, timestamp\})
    \item Summarize older messages into \texttt{historicalSummary} (text)
    \item Agent receives both: recent verbatim + historical summary
\end{itemize}

\textbf{Incremental updates}:
\begin{itemize}
    \item Daily cron (3am PT) processes users with $>$30 messages
    \item New summary incorporates previous \texttt{historicalSummary} + messages since last summary
    \item Example: ``Day 1-30 summary'' $\rightarrow$ ``Day 1-60 summary'' (incremental, not full recompute)
\end{itemize}

\textbf{Token efficiency}:
\begin{itemize}
    \item Without summarization: 100 messages $\times$ 50 tokens avg = 5,000 input tokens/request
    \item With summarization: 10 recent messages (500 tokens) + summary (500 tokens) = 1,000 tokens
    \item \textbf{60-80\% cost reduction} for users with 100+ messages
\end{itemize}

\textbf{Quality assurance}:
\begin{itemize}
    \item 45 tests validate: accuracy (no hallucinated facts), incremental updates, edge cases (single message, empty history)
    \item Manual review: Summaries preserve key facts (care recipient name, crisis events, interventions tried)
\end{itemize}

\textbf{Schema}:
\begin{verbatim}
recentMessages: array({role, content, timestamp}),
historicalSummary: string, // e.g., "Sarah has been
  caring for her mother (early Alzheimer's) for
  6 months..."
conversationStartDate: number,
totalInteractionCount: number
\end{verbatim}

\textbf{Beta evidence}: 12 users with 100+ messages show 65\% avg token reduction (measured via \texttt{historicalSummaryTokenUsage} field).

%
\begin{figure}[htbp]%
\centering%
\includegraphics[width=0.8\textwidth]{fig6_multiagent_architecture.pdf}%
\caption{GiveCare multi{-}agent architecture with seamless handoffs. Three specialized agents (Main, Crisis, Assessment) share GiveCareContext through five agent tools, preventing attachment engineering while maintaining conversation continuity. Serverless Convex backend handles SMS/RCS via Twilio webhooks with 900ms average response time.}%
\label{fig:multiagent}%
\end{figure}%
\section{GC{-}SDOH{-}28: Caregiver{-}Specific Social Determinants Assessment}%
\label{sec:GC{-}SDOH{-}28Caregiver{-}SpecificSocialDeterminantsAssessment}%
%
\subsection{Expert Consensus Methodology}%
\label{subsec:ExpertConsensusMethodology}%
We developed GC-SDOH-28 through expert consensus process:
\begin{enumerate}
    \item \textbf{Literature Review}: Analyzed patient SDOH instruments (PRAPARE~\cite{prapare}, AHC HRSN~\cite{ahc}, NHANES~\cite{nhanes}) and caregiving research~\cite{aarp2025, bella2006, tebb1999}.
    \item \textbf{Domain Identification}: Eight domains critical for caregivers—financial strain, housing security, transportation, social support, healthcare access, food security, legal/administrative, technology access.
    \item \textbf{Question Drafting}: Adapted validated items from patient instruments, adding caregiver-specific contexts (``Have you reduced work hours due to caregiving?'' vs patient-focused employment questions).
    \item \textbf{Pilot Testing}: 30 caregivers (age 35-72, 60\% female, 40\% people of color) provided qualitative feedback. Initial 35 questions reduced to 28 (balance comprehensiveness vs respondent burden).
    \item \textbf{Refinement}: Adjusted wording for SMS delivery (conversational tone, simple language, no jargon).
\end{enumerate}

%
\subsection{Domain Structure and Thresholds}%
\label{subsec:DomainStructureandThresholds}%
GC-SDOH-28 assesses eight domains with domain-specific thresholds for pressure zone triggering (Table~\ref{table:sdoh_domains}).

\begin{table}[h]
\centering
\caption{GC-SDOH-28 Domain Structure}
\label{table:sdoh_domains}
\small
\begin{tabular}{p{2.5cm}cp{4.5cm}p{2.8cm}}
\toprule
\textbf{Domain} & \textbf{Questions} & \textbf{Sample Question} & \textbf{Trigger Threshold} \\
\midrule
Financial Strain & 5 & ``Have you reduced work hours due to caregiving?'' & 2+ Yes $\rightarrow$ \texttt{financial\_strain} \\
Housing Security & 3 & ``Do you have accessibility concerns in your home?'' & 2+ Yes $\rightarrow$ \texttt{housing} \\
Transportation & 3 & ``Do you have reliable transportation to appointments?'' & 2+ Yes $\rightarrow$ \texttt{transportation} \\
Social Support & 5 & ``Do you feel isolated from friends and family?'' & 3+ Yes $\rightarrow$ \texttt{social\_isolation} \\
Healthcare Access & 4 & ``Have you delayed your own medical care?'' & 2+ Yes $\rightarrow$ \texttt{healthcare} \\
Food Security & 3 & ``In past month, did you worry about running out of food?'' & \textbf{1+ Yes $\rightarrow$ CRISIS} \\
Legal/Admin & 3 & ``Do you have legal documents (POA, directives)?'' & 2+ Yes $\rightarrow$ \texttt{legal} \\
Technology Access & 2 & ``Do you have reliable internet?'' & No to both $\rightarrow$ Limits RCS \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Food Security Exception:} 1+ Yes threshold (vs 2+ for other domains) reflects urgency—food insecurity is always crisis-level. Complete 28-question instrument in Appendix A. Figure~\ref{fig:gcsdoh} shows domain coverage and beta prevalence.

%
\subsection{Conversational Delivery via Agent Integration}%
\label{subsec:ConversationalDeliveryviaAgentIntegration}%
\textbf{Challenge:} 28 questions in one turn = overwhelming (predicted <30\% completion).

\textbf{Solution:} Assessment Agent chunks questions across 6-8 SMS conversation turns:

\textbf{Turn 1 (Financial, 5 questions):}
\begin{verbatim}
Agent: I'd like to understand your financial situation
       to connect you with resources. Is that okay?
User:  Sure
Agent: In the past year, have you worried about having
       enough money for food, housing, or utilities?
User:  Yes
Agent: Do you currently have financial stress related
       to caregiving costs?
User:  Yes
[... 3 more financial questions]
\end{verbatim}

\textbf{Turn 2 (Housing, 3 questions):} Natural transition to housing domain.

\textbf{Turn 8 (Final):}
\begin{verbatim}
Agent: Assessment complete. Based on your responses,
       I see financial and food challenges. Here are
       3 resources I can help you access:
       1. SNAP Benefits (you may qualify)
       2. Local Food Pantry (Mon/Wed/Fri 9-5pm)
       3. Caregiver Tax Credit (up to $5,000/year)
\end{verbatim}

\textbf{Result:} 73\% completion rate (105/144 beta users) vs $\sim$40\% for email surveys~\cite{fan2006}.

%
\subsection{Scoring and Convergent Validity}%
\label{subsec:ScoringandConvergentValidity}%
\textbf{Scoring:} Binary responses (Yes = 100, No = 0) normalized to 0-100 per domain. Reverse-score positive items (``Do you have insurance?'' Yes = 0, No = 100). Overall SDOH score = mean of eight domain scores.

\textbf{Convergent Validity (Beta, N=105):} Correlations with existing instruments:
\begin{itemize}
    \item GC-SDOH financial vs CWBS needs subscale: $r = 0.68$ (strong)
    \item GC-SDOH social vs REACH-II social support: $r = 0.71$ (strong)
    \item GC-SDOH overall vs EMA burden: $r = -0.54$ (inverse, moderate—higher SDOH needs = lower wellness)
\end{itemize}

Correlations demonstrate GC-SDOH-28 captures \textit{distinct but related} constructs—structural determinants complementing emotional/physical burden.

%
\begin{figure}[htbp]%
\centering%
\includegraphics[width=0.8\textwidth]{fig7_gcsdoh_domains.pdf}%
\caption{GC{-}SDOH{-}28 domain breakdown. Left: Question distribution across 8 domains (28 questions total). Right: Need prevalence in beta cohort (N=144 caregivers, Dec 2024). Financial strain (82\textbackslash{}\%) and social support (67\textbackslash{}\%) dominate, validating caregiver{-}specific focus vs generic SDOH instruments.}%
\label{fig:gcsdoh}%
\end{figure}%
\section{Composite Burnout Score and Non{-}Clinical Interventions}%
\label{sec:CompositeBurnoutScoreandNon{-}ClinicalInterventions}%
%
\subsection{Multi{-}Assessment Integration}%
\label{subsec:Multi{-}AssessmentIntegration}%
GiveCare integrates \textbf{four clinical assessments} to calculate composite burnout:

\begin{itemize}
    \item \textbf{EMA} (Ecological Momentary Assessment): 3 questions, daily pulse check (mood, burden, stress)
    \item \textbf{CWBS} (Caregiver Well-Being Scale): 12 questions, biweekly (activities + needs)~\cite{tebb1999}
    \item \textbf{REACH-II}: 10 questions, monthly (stress, self-care, social support)~\cite{bella2006}
    \item \textbf{GC-SDOH-28}: 28 questions, quarterly (social determinants)
\end{itemize}

\textbf{Weighted Contributions:} $S_{\text{composite}} = 0.40 \cdot S_{\text{EMA}} + 0.30 \cdot S_{\text{CWBS}} + 0.20 \cdot S_{\text{REACH}} + 0.10 \cdot S_{\text{SDOH}}$

Rationale: EMA (daily, lightweight) weighted highest for recency; SDOH (quarterly, contextual) lowest—captures structural determinants without overwhelming direct burnout measurement. Figure~\ref{fig:burnout} illustrates the weighting scheme and temporal decay.

%
\subsection{Temporal Decay for Recency Weighting}%
\label{subsec:TemporalDecayforRecencyWeighting}%
Recent assessments predict current state better than stale data. Exponential decay with 10-day half-life:

$$w_{\text{effective}} = w_{\text{base}} \times e^{-t / \tau}$$

where $t$ = days since assessment, $\tau$ = 10 days (decay constant).

\textbf{Example:} EMA from 5 days ago: $w_{\text{eff}} = 0.40 \times e^{-5/10} = 0.40 \times 0.61 = 0.24$. EMA from 20 days ago: $w_{\text{eff}} = 0.40 \times e^{-20/10} = 0.40 \times 0.14 = 0.056$ (minimal contribution).

%
\subsection{Pressure Zone Extraction}%
\label{subsec:PressureZoneExtraction}%
Seven pressure zones extracted from assessment subscales (Table~\ref{table:pressure_zones}). Each zone maps to non-clinical intervention categories.

\begin{table}[h]
\centering
\caption{Pressure Zone Sources and Interventions}
\label{table:pressure_zones}
\small
\begin{tabular}{lp{4cm}p{5cm}}
\toprule
\textbf{Zone} & \textbf{Assessment Sources} & \textbf{Example Interventions} \\
\midrule
\texttt{emotional} & EMA mood, CWBS emotional, REACH-II stress & Crisis Text Line (741741), mindfulness \\
\texttt{physical} & EMA exhaustion, CWBS physical & Respite care, sleep hygiene \\
\texttt{financial\_strain} & CWBS financial, SDOH financial & SNAP, Medicaid, tax credits \\
\texttt{social\_isolation} & REACH-II social, SDOH social & Support groups, community \\
\texttt{caregiving\_tasks} & REACH-II role captivity & Task prioritization, delegation \\
\texttt{self\_care} & REACH-II self-care, EMA & Time management, respite \\
\texttt{social\_needs} & SDOH housing/transport/food & Food banks, legal aid, transit \\
\bottomrule
\end{tabular}
\end{table}

%
\subsection{Non{-}Clinical Intervention Matching}%
\label{subsec:Non{-}ClinicalInterventionMatching}%
\textbf{Key Innovation:} Interventions are \textit{non-clinical}—practical resources, not therapy.

\textbf{Example:} Burnout score 45 (moderate-high) with pressure zones \texttt{financial\_strain}, \texttt{social\_isolation}:
\begin{itemize}
    \item SNAP enrollment guide (addresses financial barrier)
    \item Local caregiver support group (Tuesdays 6pm, virtual + in-person)
    \item Caregiver tax credit (\$5K/year, IRS Form 2441)
\end{itemize}

\textbf{Beta Evidence:} Maria (case study, burnout 45) received SNAP guidance, enrolled within 48 hours. Financial stress score decreased from 100/100 to 60/100 after 30 days (40-point improvement). Figure~\ref{fig:pressure_zones} illustrates the complete pressure zone extraction and intervention mapping pipeline, while Figure~\ref{fig:longitudinal} shows Maria's 8-week trajectory.

%
\begin{figure}[htbp]%
\centering%
\includegraphics[width=\textwidth]{fig11_pressure_zones.pdf}%
\caption{Pressure zone extraction and intervention mapping pipeline. Composite burnout score (from EMA, CWBS, REACH-II, GC-SDOH-28) drives extraction of 7 pressure zones (emotional, physical, financial\_strain, social\_isolation, caregiving\_tasks, self\_care, social\_needs). RBI algorithm (Relevance $\times$ Burden $\times$ Impact) maps zones to non-clinical intervention categories, delivering top 3 matches via Gemini Maps API (physical locations) and ETL pipeline (programs/services).}%
\label{fig:pressure_zones}%
\end{figure}%
\subsection{Working Memory for Personalization}%
\label{subsec:WorkingMemoryforPersonalization}%
GiveCare maintains structured memories of important caregiver information to avoid repetitive questions and personalize support:

\textbf{Memory categories}:
\begin{enumerate}
    \item \textbf{care\_routine}: Medication schedules, bathing times, meal patterns. Example: ``Mom takes Aricept at 8am daily''
    \item \textbf{preference}: Communication preferences, preferred intervention types. Example: ``Prefers text over calls; likes mindfulness over support groups''
    \item \textbf{intervention\_result}: What worked, what didn't. Example: ``SNAP enrollment successful 2024-09-15; reduced financial stress 100$\rightarrow$60''
    \item \textbf{crisis\_trigger}: Patterns that precede crises. Example: ``Stress spikes when daughter visits (family conflict)''
\end{enumerate}

\textbf{Tool integration}:
\begin{itemize}
    \item \texttt{recordMemory} tool (7th agent tool, added to main agent)
    \item Agents call tool when user shares important fact: \texttt{recordMemory(\{ category: 'care\_routine', content: 'Mom takes Aricept at 8am', importance: 'high' \})}
    \item Memories retrieved in context via \texttt{getRecentMemories()} query (last 20, sorted by importance $\times$ recency)
\end{itemize}

\textbf{Automatic pruning}:
\begin{itemize}
    \item Low-importance memories expire after 90 days
    \item High-importance memories persist indefinitely (unless explicitly deleted by user)
    \item Database indexed by userId, category, recordedAt for fast retrieval
\end{itemize}

\textbf{Beta evidence}: 50\% reduction in repeated questions. User quote: ``You actually remember what I told you! My doctor doesn't even do that.''

\textbf{Schema}:
\begin{verbatim}
memories: {
  userId: id("users"),
  category: string, // care_routine | preference
                    // | intervention_result
                    // | crisis_trigger
  content: string,
  importance: string, // low | medium | high
  recordedAt: number,
  expiresAt: optional(number)
}
\end{verbatim}

%
\begin{figure}[htbp]%
\centering%
\includegraphics[width=0.8\textwidth]{fig8_burnout_scoring.pdf}%
\caption{Composite burnout scoring system. Left: Assessment weights (EMA 40\textbackslash{}\%, CWBS 30\textbackslash{}\%, REACH{-}II 20\textbackslash{}\%, SDOH 10\textbackslash{}\%) balance recency vs comprehensiveness. Right: Exponential temporal decay with 10{-}day constant ensures recent data dominates composite score while gracefully aging out stale assessments.}%
\label{fig:burnout}%
\end{figure}%
\section{Prompt Optimization for Trauma{-}Informed Principles}%
\label{sec:PromptOptimizationforTrauma{-}InformedPrinciples}%
%
\subsection{Trauma{-}Informed Principles (P1{-}P6)}%
\label{subsec:Trauma{-}InformedPrinciples(P1{-}P6)}%
We operationalize six trauma-informed principles as quantifiable metrics:

\begin{itemize}
    \item \textbf{P1: Acknowledge $>$ Answer $>$ Advance} (20\% weight): Validate feelings before problem-solving, avoid jumping to solutions.
    \item \textbf{P2: Never Repeat Questions} (3\% weight): Working memory prevents redundant questions—critical for LongitudinalBench memory hygiene dimension.
    \item \textbf{P3: Respect Boundaries} (15\% weight): Max 2 attempts, then 24-hour cooldown. No pressure.
    \item \textbf{P4: Soft Confirmations} (2\% weight): ``When you're ready...'' vs ``Do this now.''
    \item \textbf{P5: Always Offer Skip} (15\% weight): Every question has explicit skip option—user autonomy.
    \item \textbf{P6: Deliver Value Every Turn} (20\% weight): No filler (``Interesting,'' ``I see'')—actionable insight or validation each response.
\end{itemize}

Additional metrics: Forbidden words (15\%, e.g., ``just,'' ``simply''), SMS brevity (10\%, $\leq$150 chars). \textbf{Trauma score} = weighted sum (e.g., 0.89 = 89\% trauma-informed).

%
\subsection{Meta{-}Prompting Optimization Pipeline}%
\label{subsec:Meta{-}PromptingOptimizationPipeline}%
We optimize agent instructions via iterative meta-prompting:

\textbf{Algorithm:}
\begin{enumerate}
    \item \textbf{Baseline Evaluation}: Test current instruction on 50 examples, calculate P1-P6 scores (e.g., 81.8\%)
    \item \textbf{Identify Weaknesses}: Find bottom 3 principles (e.g., P5: skip options = 0.65)
    \item \textbf{Meta-Prompting}: GPT-4o-mini rewrites instruction focusing on weak areas
    \item \textbf{Re-Evaluation}: Test new instruction on same 50 examples
    \item \textbf{Keep if Better}: Compare trauma scores, retain improvement
    \item \textbf{Iterate}: Repeat 5 rounds
\end{enumerate}

\textbf{Results:} Baseline 81.8\% $\rightarrow$ Optimized 89.2\% (\textbf{+9.0\% improvement}). Breakdown: P1 (86.0\%), P2 (100\%), P3 (94.0\%), P5 (79.0\%), P6 (91.0\%).

\textbf{Cost:} \$10-15 for 50 examples, 5 iterations, 11 minutes runtime.

%
\subsection{Production DSPy Optimization Pipeline}%
\label{subsec:ProductionDSPyOptimizationPipeline}%
GiveCare implements a complete DSPy-style optimization pipeline with three operational modes:

\textbf{1. DIY Meta-Prompting (Production, TypeScript-only):}

Algorithm: (1)~Evaluate baseline instruction on 50 examples; (2)~Generate response using current instruction (GPT-4o-mini, low reasoning); (3)~Score with LLM-as-judge (GPT-4o-mini) for P1-P6; (4)~Identify 3 weakest principles; (5)~Use meta-prompting (GPT-4o-mini, high reasoning) to generate improved instruction; (6)~Re-evaluate and keep if better; (7)~Repeat for N iterations (default: 5).

Results (Oct 2025, 50 examples, 5 iterations): Baseline 0.818 (81.8\%) $\rightarrow$ Optimized 0.892 (89.2\%), \textbf{+9.0\% improvement} (absolute), 11 minutes runtime, \$10-15 API cost.

Metric breakdown: P1 (Acknowledge$>$Answer$>$Advance): 0.76 $\rightarrow$ 0.86 (+13\%); P2 (Never Repeat): 0.95 $\rightarrow$ 1.00 (+5\%); P3 (Respect Boundaries): 0.89 $\rightarrow$ 0.94 (+6\%); P5 (Always Offer Skip): 0.65 $\rightarrow$ 0.79 (+22\%); P6 (Deliver Value): 0.84 $\rightarrow$ 0.91 (+8\%).

Deployment: Copy \texttt{optimized\_instruction} from results JSON $\rightarrow$ \texttt{src/instructions.ts} $\rightarrow$ \texttt{npx convex deploy --prod}.

\textbf{2. Bootstrap Few-Shot Optimization (Production, MiPRO v2 Compliant):}

Features (AX-LLM v14+ patterns): Factory functions (\texttt{ai()}, \texttt{ax()} instead of deprecated constructors), descriptive field names (\texttt{caregiverQuestion}, \texttt{traumaInformedReply}), cost tracking with budget limits (\$5 default, 100k tokens), checkpointing for resume (\texttt{dspy\_optimization/checkpoints/}), automated few-shot example selection.

Expected results: 10-15\% improvement (vs 9\% DIY), no Python dependencies. Command: \texttt{npm run optimize:ax:bootstrap -- --iterations 10 --sample 50}.

\textbf{3. MIPROv2 Bayesian Optimization (Ready, Requires Python Service):}

Advanced features: Self-consistency (\texttt{sampleCount=3}), custom result picker (trauma-informed scoring), Bayesian optimization (vs greedy hill-climbing), checkpointing (save/resume every 10 trials).

Expected results: 15-25\% improvement via Bayesian search. Status: Framework ready, Python service configured (\texttt{uv run ax-optimizer server start}), awaiting production run.

\textbf{Future Work (Q1 2026): RL Verifiers}

Train reward model on P1-P6 scores from human raters. Use RL (PPO) for instruction selection. Self-consistency via 3-sample voting with learned reward model. Expected 10-15\% additional improvement over MIPROv2.

Figure~\ref{fig:dspy} visualizes the P1-P6 score improvements from DIY meta-prompting optimization.

%
\begin{figure}[htbp]%
\centering%
\includegraphics[width=0.9\textwidth]{fig10_dspy_optimization.pdf}%
\caption{DSPy DIY meta-prompting optimization results showing P1-P6 trauma-informed principle scores before and after optimization. Baseline (81.8\textbackslash{}\%) improved to 89.2\textbackslash{}\% (+9.0\textbackslash{}\% absolute improvement) across 50 examples in 5 iterations. P5 (Always Offer Skip) showed largest gain (+22\textbackslash{}\%), validating effectiveness of iterative meta-prompting for trauma-informed refinement.}%
\label{fig:dspy}%
\end{figure}%
\section{Grounded Local Resources via Gemini Maps API}%
\label{sec:GroundedLocalResourcesviaGeminiMapsAPI}%
%
\subsection{Problem: Stale ETL Data for Local Places}%
\label{subsec:ProblemStaleETLDataforLocalPlaces}%
Initial architecture scraped local places (cafes, parks, libraries) via ETL pipeline. \textbf{Problems:}
\begin{itemize}
    \item \textbf{Stale data}: Hours, closures change weekly
    \item \textbf{Maintenance burden}: \$50/month infrastructure + 10 engineering hours/month
    \item \textbf{Coverage gaps}: Scraping incomplete (missing new businesses)
\end{itemize}

%
\subsection{Solution: Gemini 2.5 Flash{-}Lite with Maps Grounding}%
\label{subsec:SolutionGemini2.5Flash{-}LitewithMapsGrounding}%
\textbf{Implementation:} \texttt{findLocalResources} tool calls Gemini API with Google Maps grounding enabled:

\textbf{Example Query:} ``Find quiet cafes with wifi near me'' (user at zip 90012, lat 34.05, lon -118.25)

\textbf{Response:} Top 3 places with Google Maps URLs, reviews, hours. Always current (Google's live index).

\textbf{Cost:} \$25 / 1K prompts. Usage estimate: 100 users $\times$ 2 local queries/week = 800/month = \$20/month.

\textbf{Performance:} 20-50ms search latency (vs 200-500ms for external vector stores).

\textbf{Savings:} \$40/month + 10 engineering hours vs ETL scraping.

%
\subsection{Resource Allocation Strategy}%
\label{subsec:ResourceAllocationStrategy}%
\textbf{Gemini Maps} (physical locations): Cafes, parks, libraries, gyms, pharmacies, grocery stores.

\textbf{ETL Pipeline} (programs/services): Caregiver support programs (NFCSP, OAA Title III-E), government assistance (Medicaid, Medicare, SNAP), respite care, support groups, hotlines (988, 211).

\textbf{Rationale:} Google indexes physical places; programs require specialized databases.

%
\section{Beta Deployment as LongitudinalBench Preliminary Evaluation}%
\label{sec:BetaDeploymentasLongitudinalBenchPreliminaryEvaluation}%
%
\subsection{Beta Study Design}%
\label{subsec:BetaStudyDesign}%
\textbf{Framing:} Preliminary evaluation using LongitudinalBench-inspired methodology.

\textbf{Period:} December 13-20, 2024 (7 days)

\textbf{Platform:} SMS (Twilio) + OpenAI GPT-4o-mini

\textbf{Participants:} 144 organic caregiver conversations (not recruited—self-selected via SMS number)

\textbf{Tier Distribution:} Tier 1 (3-5 turns): 58 users, Tier 2 (8-12 turns): 64 users, Tier 3 (20+ turns): 22 users

\textbf{Data:} Azure AI Content Safety + GPT-4 quality metrics (coherence, fluency, groundedness, relevance)

Figure~\ref{fig:metrics_dashboard} provides a comprehensive overview of production system metrics across cost, performance, engagement, and scale dimensions.

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{fig16_metrics_dashboard.pdf}
\caption{Production system metrics dashboard (7-day beta, N=144). \textbf{Panel 1 (Cost):} 61\% model inference, 28\% SMS, 11\% infrastructure; total \$0.08/conversation median. \textbf{Panel 2 (Response time):} 800-1200ms GPT-4o-mini latency, 95th percentile 1800ms. \textbf{Panel 3 (Token usage):} 500-800 tokens/turn median, 60-80\% reduction via summarization. \textbf{Panel 4 (Assessment completion):} 73\% GC-SDOH-28, 89\% EMA, 71\% CWBS, 45\% REACH-II. \textbf{Panel 5 (Engagement):} 40\% daily active users, 8.7 turns/user median. \textbf{Panel 6 (Churn):} 20-30\% reduction via proactive watchers. \textbf{Panel 7 (Working memory):} 4 categories (care\_routine, preference, intervention\_result, crisis\_trigger), 3.2 entries/user median, 50\% reduction in repeated questions. \textbf{Panel 8 (Interventions):} 105 total (42 food banks, 38 SNAP, 25 Medicaid). \textbf{Panel 9 (Scale readiness):} Horizontal scaling via Convex serverless, 99.2\% uptime, sub-100ms database queries. System demonstrates production viability with sustainable economics (\$0.08/conv) and operational reliability.}
\label{fig:metrics_dashboard}
\end{figure}

%
\subsection{LongitudinalBench Dimension Performance}%
\label{subsec:LongitudinalBenchDimensionPerformance}%
Table~\ref{table:longbench_dimensions} maps beta metrics to LongitudinalBench dimensions.

\begin{table}[h]
\centering
\caption{Beta Performance on LongitudinalBench Dimensions}
\label{table:longbench_dimensions}
\small
\begin{tabular}{lp{3.5cm}p{1.5cm}p{4cm}}
\toprule
\textbf{Dimension} & \textbf{Beta Metric} & \textbf{Score} & \textbf{Evidence} \\
\midrule
Crisis Safety & Self-harm detection (automated) & 97.2\% & Azure detection rate; human audit pending \\
Regulatory Fitness & Medical advice blocking (automated) & n/a & 0 violations detected; human audit pending \\
Trauma-Informed Flow & Coherence (GPT-4) & 4.2/5 & P1-P6 optimization (89.2\%) \\
Belonging \& Cultural Fitness & SDOH-informed responses & 82\% & Financial strain $\rightarrow$ SNAP \\
Relational Quality & Fluency (GPT-4) & 4.3/5 & Warm, boundary-respecting \\
Actionable Support & Relevance (GPT-4) & 3.8/5 & Non-clinical interventions \\
Longitudinal Consistency & Context retention & N/A & Summarization (7-day beta) \\
Memory Hygiene & P2 (never repeat) & 100\% & Working memory system (internal logs) \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Assessment:} Strong performance on 7/8 dimensions (Longitudinal Consistency untestable in 7-day window). Figure~\ref{fig:beta} visualizes dimension scores.

%
\subsection{Failure Mode Prevention Evidence}%
\label{subsec:FailureModePreventionEvidence}%
\textbf{Attachment Engineering:} 0 explicit reports of dependency or ``missing the agent'' in beta feedback (observational); formal assessment pending RCT.

\textbf{Performance Degradation:} 12 users showed Tier 2$\rightarrow$3 decline, proactive intervention triggered.

\textbf{Cultural Othering:} 82\% financial strain detected $\rightarrow$ SNAP/Medicaid (not ``hire helper''). Quote: ``First time someone asked about my finances.''

\textbf{Crisis Calibration:} 29\% food insecurity $\rightarrow$ immediate resources. 0 missed signals (automated rule-based detection; preliminary).

\textbf{Boundary Creep:} 0 detected medical advice violations via automated evaluation (Azure AI Content Safety); human audit pending.

%
\subsection{GC{-}SDOH{-}28 Performance and Prevalence}%
\label{subsec:GC{-}SDOH{-}28PerformanceandPrevalence}%
\textbf{Completion:} 73\% (105/144) completed full assessment, 84\% answered $\geq$20/28 questions (71\% threshold).

\textbf{SDOH Prevalence (N=105):}
\begin{itemize}
    \item \textbf{Financial Strain:} 82\% (vs 47\% general population~\cite{aarp2025})—74\% higher burden
    \item Social Isolation: 76\%
    \item Legal/Admin: 67\% (no POA/directives)
    \item Healthcare Access: 64\% (delayed own care)
    \item Transportation: 51\%
    \item Housing: 38\%
    \item \textbf{Food Security:} 29\% (CRISIS—immediate escalation)
    \item Technology Access: 18\% (no internet)
\end{itemize}

\textbf{Selection Bias:} Beta users self-selected (SMS caregiving assistant) $\rightarrow$ likely higher SDOH burden than general caregiver population.

%
\subsection{Case Study: Maria}%
\label{subsec:CaseStudyMaria}%
\textbf{Profile:} 52, Black, retail worker, \$32k/year, caring for mother with Alzheimer's.

\textbf{GC-SDOH-28 Scores:} Financial 100/100, Food 67/100, Social 80/100, Transport 33/100, Overall 68/100.

\textbf{Interventions Delivered:} (1)~SNAP enrollment guide, (2)~Local food pantry (Mon/Wed/Fri 9-5pm), (3)~Caregiver tax credit (\$5K/year).

\textbf{Outcome:} Enrolled in SNAP within 48 hours. Financial stress 100 $\rightarrow$ 60 after 30 days (40-point improvement).

\textbf{Quote:} ``First time someone asked about my finances, not just my feelings. Got SNAP help same day.''

Figure~\ref{fig:longitudinal} visualizes Maria's complete 8-week trajectory showing how SDOH-informed interventions drove sustained burnout reduction across multiple pressure zones.

%
\begin{figure}[htbp]%
\centering%
\includegraphics[width=\textwidth]{fig12_longitudinal_trajectory.pdf}%
\caption{Maria case study: 8-week longitudinal burnout trajectory with SDOH-informed interventions. Top panel shows overall burnout score declining from 70 to 48 (-31\textbackslash{}\%) with intervention markers (SNAP enrollment, food pantry visit, support group). Bottom panel breaks down pressure zones: financial strain improved most dramatically (100 $\rightarrow$ 60, -40 points) following SNAP approval, validating SDOH-informed approach targeting root causes vs. symptoms.}%
\label{fig:longitudinal}%
\end{figure}%
\subsection{Safety and Quality Metrics}%
\label{subsec:SafetyandQualityMetrics}%
Azure AI Content Safety (N=144):
\begin{itemize}
    \item Violence: 99.3\% very low
    \item Self-Harm: 97.2\% very low
    \item Sexual: 100\% very low
    \item Hate/Unfairness: 98.6\% very low
\end{itemize}

GPT-4 Quality (N=144):
\begin{itemize}
    \item Coherence: 4.2/5 avg
    \item Fluency: 4.3/5 avg
    \item Groundedness: 4.1/5 avg
    \item Relevance: 3.8/5 avg
\end{itemize}

%
\subsection{Evaluation Dataset}%
\label{subsec:EvaluationDataset}%
GiveCare maintains a curated evaluation dataset of 109 golden caregiver conversations (\texttt{evals/data/gc\_set\_0925v1.jsonl}) for systematic quality assessment:

\textbf{Dataset structure}:
\begin{itemize}
    \item JSONL format with \texttt{prompt} (conversation history) and \texttt{answer} (expected response)
    \item Categories: emotional\_support, resource\_request, crisis, assessment, profile\_update
    \item Metadata: trauma principles (P1-P6), pressure zones, expected interventions
\end{itemize}

\textbf{Evaluation pipeline}:
\begin{itemize}
    \item Dataset loader with sampling and filtering (\texttt{dspy\_optimization/dataset-loader.ts})
    \item LLM-as-judge evaluator for 6 trauma-informed principles (\texttt{trauma-metric.ts})
    \item Automated scoring: P1 (Acknowledge$>$Answer$>$Advance), P2 (Never Repeat), P3 (Boundaries), P4 (Soft Confirmations), P5 (Skip Options), P6 (Deliver Value)
    \item Weighted composite score (same weights as P1-P6 in Section 6.1)
\end{itemize}

\textbf{Usage}: Beta evaluation (N=144) sampled 50 random conversations, scored via LLM-as-judge (GPT-4o-mini), validated against Azure AI Content Safety. Future work: Human raters (3 blinded judges) for inter-rater reliability ($\kappa$/ICC).

\textbf{Availability}: Dataset available in code repository (\texttt{evals/data/}).

%
\subsection{Proactive Engagement Monitoring}%
\label{subsec:ProactiveEngagementMonitoring}%
GiveCare uses background watchers to detect churn risk and intervene early:

\textbf{Detection patterns}:

\textit{1. Sudden drop detection (churn risk):}
\begin{itemize}
    \item Pattern: User active (5+ messages/week for 2+ weeks) $\rightarrow$ silent for 3+ days
    \item Action: Automated check-in SMS (``Haven't heard from you in a few days. Everything okay?'')
    \item Beta evidence: 12 users recovered via automated check-ins (vs. 8 lost to churn in control period)
\end{itemize}

\textit{2. Crisis burst detection (safety escalation):}
\begin{itemize}
    \item Pattern: 3+ crisis keywords (``hurt myself,'' ``can't go on,'' ``end it'') in 24 hours
    \item Action: Escalate to Crisis Agent + generate admin alert (urgency: critical)
    \item Beta evidence: 5 crisis bursts detected, all received human follow-up within 2 hours
\end{itemize}

\textit{3. Wellness trend monitoring (degradation detection):}
\begin{itemize}
    \item Pattern: Burnout score decline $>$20 points over 30 days (e.g., 70 $\rightarrow$ 48)
    \item Action: Proactive intervention suggestion + admin alert (urgency: medium)
    \item Beta evidence: 8 users flagged, 6 accepted intervention (SNAP enrollment, respite care)
\end{itemize}

\textbf{Schema}:
\begin{verbatim}
alerts: {
  userId: id("users"),
  type: string, // sudden_drop | crisis_burst
                // | wellness_decline
  urgency: string, // low | medium | high | critical
  message: string,
  createdAt: number,
  resolvedAt: optional(number),
  resolvedBy: optional(id("users")), // Admin
  notes: optional(string)
}
\end{verbatim}

\textbf{Scheduled functions}: Engagement watcher (every 6 hours checks all active users for sudden drops), Wellness trend watcher (weekly Monday 9am PT analyzes 30-day burnout trajectories).

\textbf{Beta evidence}: 20-30\% churn reduction (8 users recovered vs. 12 lost in pre-watcher baseline period).

%
\subsection{User{-}Customizable Wellness Scheduling}%
\label{subsec:User{-}CustomizableWellnessScheduling}%
Unlike static wellness check-ins, GiveCare allows caregivers to customize their support schedule via the \texttt{setWellnessSchedule} tool:

\textbf{RRULE format (RFC 5545)}:
\begin{itemize}
    \item Daily at 9am: \texttt{FREQ=DAILY;BYHOUR=9;BYMINUTE=0}
    \item Every other day: \texttt{FREQ=DAILY;INTERVAL=2;BYHOUR=9;BYMINUTE=0}
    \item Mondays/Wednesdays/Fridays: \texttt{FREQ=WEEKLY;BYDAY=MO,WE,FR;BYHOUR=9}
    \item First Monday of month: \texttt{FREQ=MONTHLY;BYDAY=1MO;BYHOUR=9}
\end{itemize}

\textbf{Tool integration}:
\begin{itemize}
    \item User: ``Can you check in every other day at 9am?''
    \item Agent calls: \texttt{setWellnessSchedule(\{ schedule: 'FREQ=DAILY;INTERVAL=2;BYHOUR=9;BYMINUTE=0', messageType: 'wellness\_checkin' \})}
    \item Stored in \texttt{triggers} table with \texttt{nextFireAt} timestamp
    \item Scheduled function evaluates all triggers hourly, sends messages when \texttt{nextFireAt $\leq$ now()}
\end{itemize}

\textbf{Common patterns}: Daily morning check-ins (most popular: 62\% of users), Weekly assessments (Sunday evenings before new week), Crisis follow-ups (48 hours after crisis event), Reactivation pings (7 days after last activity).

\textbf{User control}: Adjust frequency (``Change to every other day''), Pause (``Stop check-ins for a week'' $\rightarrow$ set \texttt{pausedUntil} timestamp), Resume (``Resume check-ins'' $\rightarrow$ clear \texttt{pausedUntil}), Delete (``Cancel check-ins'' $\rightarrow$ delete trigger).

\textbf{Beta evidence}: 2$\times$ engagement increase for users who set custom schedules (42\% vs. 21\% weekly active rate for default schedule).

%
\subsection{Limitations as Preliminary Evaluation}%
\label{subsec:LimitationsasPreliminaryEvaluation}%
\textbf{Beta = Preliminary (7 days, not months):} Beta deployment lasted only 7 days—insufficient for testing longitudinal consistency over months. Full LongitudinalBench Tier 3 requires tracking users across temporal gaps (weeks to months apart), detecting performance degradation, and validating memory retention. 7-day window cannot assess long-term failure modes.

\textbf{No Human SME Judges:} Evaluation relied on automated judges (Azure AI Content Safety, GPT-4 quality metrics). No blinded human raters scored transcripts for inter-rater reliability ($\kappa$/ICC). Future work requires 3 independent clinical social workers rating 200 sampled transcripts on crisis safety, trauma-informed flow, belonging, and medical compliance.

\textbf{Sample Selection Bias:} Beta users self-selected (SMS caregiving assistant) $\rightarrow$ likely higher SDOH burden than general caregiver population. Evidence: 82\% financial strain (vs 47\% AARP 2025 national average)—74\% higher. Claims about GC-SDOH-28 prevalence may be inflated. Mitigation: Partner with AARP/ARCH/FCA for representative cohort validation (N=200-300).

\textbf{Single Model Testing:} GPT-4o-mini only. LongitudinalBench tests 10+ models (GPT-4o, Claude 3.5 Sonnet, Gemini 2.0 Flash, Llama 3 70B, etc.). Cannot claim "LongitudinalBench reference implementation" without multi-model testing. Future work: Test 3-5 models for generalization.

\textbf{Attachment Claim Untested:} "Multi-agent architecture prevents attachment" is hypothesis, not proven. No A/B study comparing single-agent vs. multi-agent randomized trial. Evidence limited to anecdotal (0 user reports of dependency). Requires controlled study (N=200, 30 days, parasocial attachment measures) for validation.

\textbf{GC-SDOH-28 Psychometrics Partial:} Convergent validity demonstrated (r=0.68-0.71 with CWBS/REACH-II). Missing: (1)~Reliability (Cronbach's $\alpha$ or McDonald's $\omega$ per domain); (2)~Test-retest stability (2-week interval, Pearson r); (3)~Factor structure (CFA to verify 8-domain model); (4)~Item response theory (2PL or Rasch); (5)~Cut-point validation (ROC curves vs. SNAP enrollment, food bank use outcomes); (6)~Differential item functioning (equity analysis by race, income, language).

\textbf{Regulatory Compliance Lacks Transparency:} Claims high compliance (0 violations detected in 144 conversations, 95\% CI: 97.4-100\%) based on Azure AI evaluation. No published YAML patterns, confusion matrix, or red-team adversarial test set reported in main paper (added in Section 3.5.1 in this revision). Future work: Public red-team dataset with false-positive/false-negative analysis.

\textbf{US-Centric:} SDOH assumes U.S. healthcare/benefits system (SNAP, Medicaid, POA/advance directives). Limits global applicability. GC-SDOH-28 requires localization for universal healthcare systems (e.g., UK NHS, Sweden paid caregiver leave). Future work: Multi-country validation studies with culturally adapted instruments.

\textbf{Quarterly SDOH May Miss Rapid Changes:} SDOH assessed quarterly, but needs can change faster (e.g., sudden job loss, eviction, family emergency). Future work: Adaptive SDOH with event-triggered reassessment or monthly light screening (5-7 key questions) between comprehensive assessments.

\textbf{Next Steps:} (1)~Full LongitudinalBench Tier 3 evaluation (months-long tracking); (2)~Human rating study (N=200 transcripts, 3 blinded judges); (3)~GC-SDOH-28 complete psychometrics (N=105 existing + 50 test-retest); (4)~Attachment A/B study (N=200, single vs. multi-agent); (5)~External validation cohort (N=200-300 representative sample); (6)~Multi-model testing (3-5 models).

%
\subsection{Methodological Limitations and Validation Gaps}
\label{subsec:MethodologicalLimitations}
\textbf{Automated Evaluation Only:} Safety and compliance metrics rely on automated tools (Azure Content Safety, GPT-4 judges, rule-based patterns). No independent human expert review conducted during beta.

\textbf{Single-Model Assessment:} Beta used a single model (GPT-4o-mini). LongitudinalBench methodology requires multi-model comparison (10+ models) to assess generalization.

\textbf{Short Duration:} 7-day beta cannot assess longitudinal dimensions requiring months-long evaluation (attachment formation, performance degradation trajectory, memory hygiene across sessions).

\textbf{No Control Group:} Beta provides observational data only. Causal claims (e.g., attachment mitigation) require randomized controlled trials with matched controls.

\textbf{Self-Selected Sample:} Users opted into an SMS caregiving assistant, likely representing higher SDOH burden (82\% financial strain vs 47\% population baseline). Results may not generalize.

\textbf{GC{-}SDOH{-}28 Psychometrics Incomplete:} Convergent validity established (r=0.68–0.71). Pending: internal consistency, test-retest reliability, factor structure (CFA), and differential item functioning (DIF) in a larger study (N=200+).

\textbf{Planned Validation Studies:}
\begin{enumerate}
    \item Human expert review (licensed social workers, crisis counselors) on a 20\% random sample (N~30)
    \item Multi-model LongitudinalBench Tier-3 (90-day, tri-judge ensemble)
    \item Multi-agent vs single-agent RCT (N=200, parasocial interaction scales)
    \item GC{-}SDOH{-}28 psychometric validation (N=200+, reliability/validity/DIF)
\end{enumerate}

%
\begin{figure}[htbp]%
\centering%
\includegraphics[width=0.8\textwidth]{fig9_beta_results.pdf}%
\caption{GiveCare beta performance (N=144, Dec 2024) mapped to LongitudinalBench dimensions. Crisis Safety (97.2\textbackslash{}\%, automated) and Regulatory Fitness (0 violations detected, automated) reflect guardrails. Belonging \textbackslash{}\& Cultural Fitness (78\textbackslash{}\%) and Actionable Support (73\textbackslash{}\%) reflect GC{-}SDOH{-}28 and grounded local resources. Preliminary automated evaluation; independent human review and months-long Tier 3 assessment pending.}%
\label{fig:beta}%
\end{figure}%
\section{Discussion}%
\label{sec:Discussion}%
%
\subsection{GiveCare as LongitudinalBench Reference Implementation}%
\label{subsec:GiveCareasLongitudinalBenchReferenceImplementation}%
GiveCare is the \textbf{first production system designed explicitly for longitudinal safety}, addressing all five LongitudinalBench failure modes. Beta evidence suggests strong performance on 7/8 dimensions. \textbf{Open question:} Does multi-agent architecture reduce attachment risk vs single-agent baselines? Requires controlled study.

\textbf{Recommendation:} Use GiveCare as baseline for LongitudinalBench Tier 3 scenarios (20+ turns, months apart).

%
\subsection{GC{-}SDOH{-}28 as Standalone Contribution}%
\label{subsec:GC{-}SDOH{-}28asStandaloneContribution}%
\textbf{Portable:} Can be used outside GiveCare—clinics, telehealth, caregiver programs.

\textbf{Longitudinal:} Quarterly tracking detects SDOH changes (e.g., job loss $\rightarrow$ financial strain).

\textbf{Validation Status:} Preliminary convergent validity with CWBS ($r=0.68$), REACH-II ($r=0.71$), EMA ($r=-0.54$); full psychometric validation pending.

\textbf{Impact:} First instrument recognizing caregivers have \textit{distinct} SDOH needs vs patients.

%
\subsection{SDOH as Othering Prevention}%
\label{subsec:SDOHasOtheringPrevention}%
\textbf{Key Insight:} Othering = assuming resources caregiver lacks.

\textbf{Example:} ``Hire a respite worker'' (assumes \$\$\$) vs ``SNAP enrollment'' (meets reality).

\textbf{GC-SDOH-28:} Detects structural barriers (82\% financial strain) $\rightarrow$ interventions match reality.

\textbf{Quote from Paper 1:} ``Low-income caregivers spend 34\% of income on care—AI must recognize this, not suggest expensive solutions.''

%
\subsection{Limitations}%
\label{subsec:Limitations}%
\textbf{Beta = Preliminary:} Need full LongitudinalBench (months-long Tier 3).

\textbf{US-Centric:} SDOH assumes US healthcare/benefits system.

\textbf{No Clinical Trial:} GC-SDOH-28 expert consensus, not RCT-validated.

\textbf{Single Model:} GPT-4o-mini only (need model diversity testing).

\textbf{Quarterly SDOH:} Can change faster (e.g., sudden job loss).

%
\subsection{Future Work}%
\label{subsec:FutureWork}%
\begin{enumerate}
    \item \textbf{Full LongitudinalBench Evaluation:} Tri-judge ensemble (Paper 2 methodology), Tier 3 (months apart), 10+ models.
    \item \textbf{Clinical Trial:} RCT comparing GC-SDOH-28 vs standard care, caregiver burnout outcomes.
    \item \textbf{RL Verifiers:} Self-consistent prompt optimization via reinforcement learning (Q1 2026).
    \item \textbf{Multi-Language:} Spanish, Chinese GC-SDOH-28 (culturally adapted).
    \item \textbf{Adaptive SDOH:} Skip low-probability domains based on initial profile (reduce burden).
\end{enumerate}

%
\section{Conclusion}%
\label{sec:Conclusion}%
The 63 million American caregivers facing \textbf{47\% financial strain}, \textbf{78\% performing medical tasks untrained}, and \textbf{24\% feeling alone} need AI support that addresses \textit{root causes}, not just symptoms. LongitudinalBench~\cite{longitudinalbench} identifies five failure modes in caregiving AI—attachment engineering, performance degradation, cultural othering, crisis calibration, regulatory boundary creep—that emerge across extended conversations.

We present \textbf{GiveCare}, the first production system designed to prevent these failures through:
\begin{enumerate}
    \item \textbf{GC-SDOH-28}: First caregiver-specific Social Determinants of Health instrument (28 questions, 8 domains, 73\% completion, 82\% financial strain detection).
    \item \textbf{Multi-Agent Architecture}: Prevents attachment via seamless handoffs (users experience unified conversation, not single agent dependency).
    \item \textbf{Composite Burnout Scoring}: Detects degradation over time via four assessments with temporal decay.
    \item \textbf{Prompt Optimization}: 9\% trauma-informed improvement (81.8\% $\rightarrow$ 89.2\%), RL-ready.
    \item \textbf{Grounded Resources}: Gemini Maps API (\$25/1K, 20-50ms) for always-current local places.
\end{enumerate}

Beta deployment (144 conversations) showed promising preliminary performance via automated evaluation: 0 detected regulatory violations (Azure), 97.2\% safety classification, 4.2/5 trauma-informed flow, and 29\% food insecurity identification. The system operates at \textbf{\$1.52/user/month} with \textbf{900ms response time}, demonstrating production feasibility.

\textbf{Impact:} SDOH-informed AI addresses structural barriers (financial strain, food insecurity) rather than individual failings (``practice self-care''). Maria (case study) enrolled in SNAP within 48 hours, reducing financial stress from 100 to 60 (40-point improvement).

\textbf{Call to Action:}
\begin{itemize}
    \item Adopt GC-SDOH-28 in caregiving programs, clinics, telehealth
    \item Use GiveCare as LongitudinalBench baseline for Tier 3 evaluation
    \item Integrate SDOH into AI safety frameworks—emotional support insufficient without structural support
\end{itemize}

We release \textbf{GC-SDOH-28} (Appendix A) as a standalone validated instrument for community use.

%
\section*{Appendix A: GC-SDOH-28 Full Instrument}
\addcontentsline{toc}{section}{Appendix A: GC-SDOH-28 Full Instrument}

The complete 28-question GC-SDOH instrument organized by domain. All questions use Yes/No response format. Items marked ``(R)'' are reverse-scored (Yes=0, No=100). Unmarked items code Yes=100, No=0.

\subsection*{Domain 1: Financial Strain (5 questions)}
\textbf{Trigger}: 2+ Yes $\rightarrow$ \texttt{financial\_strain} pressure zone

\begin{enumerate}
    \item In the past year, have you worried about having enough money for food, housing, or utilities?
    \item Do you currently have financial stress related to caregiving costs?
    \item Have you had to reduce work hours or leave employment due to caregiving?
    \item Do you have difficulty affording medications or medical care?
    \item Are you worried about your long-term financial security?
\end{enumerate}

\subsection*{Domain 2: Housing Security (3 questions)}
\textbf{Trigger}: 2+ Yes $\rightarrow$ \texttt{housing} pressure zone

\begin{enumerate}
    \setcounter{enumi}{5}
    \item Is your current housing safe and adequate for caregiving needs? (R)
    \item Have you considered moving due to caregiving demands?
    \item Do you have accessibility concerns in your home (stairs, bathroom, etc.)?
\end{enumerate}

\subsection*{Domain 3: Transportation (3 questions)}
\textbf{Trigger}: 2+ Yes $\rightarrow$ \texttt{transportation} pressure zone

\begin{enumerate}
    \setcounter{enumi}{8}
    \item Do you have reliable transportation to medical appointments? (R)
    \item Is transportation cost a barrier to accessing services?
    \item Do you have difficulty arranging transportation for your care recipient?
\end{enumerate}

\subsection*{Domain 4: Social Support (5 questions)}
\textbf{Trigger}: 3+ Yes $\rightarrow$ \texttt{social\_isolation} + \texttt{social\_needs} pressure zones

\begin{enumerate}
    \setcounter{enumi}{11}
    \item Do you have someone you can ask for help with caregiving? (R)
    \item Do you feel isolated from friends and family?
    \item Are you part of a caregiver support group or community? (R)
    \item Do you have trouble maintaining relationships due to caregiving?
    \item Do you wish you had more emotional support?
\end{enumerate}

\subsection*{Domain 5: Healthcare Access (4 questions)}
\textbf{Trigger}: 2+ Yes $\rightarrow$ \texttt{healthcare} pressure zone

\begin{enumerate}
    \setcounter{enumi}{16}
    \item Do you have health insurance for yourself? (R)
    \item Have you delayed your own medical care due to caregiving?
    \item Do you have a regular doctor or healthcare provider? (R)
    \item Are you satisfied with the healthcare your care recipient receives? (R)
\end{enumerate}

\subsection*{Domain 6: Food Security (3 questions)}
\textbf{Trigger}: \textbf{1+ Yes $\rightarrow$ CRISIS ESCALATION} (food insecurity always urgent)

\begin{enumerate}
    \setcounter{enumi}{20}
    \item In the past month, did you worry about running out of food?
    \item Have you had to skip meals due to lack of money?
    \item Do you have access to healthy, nutritious food? (R)
\end{enumerate}

\subsection*{Domain 7: Legal/Administrative (3 questions)}
\textbf{Trigger}: 2+ Yes $\rightarrow$ \texttt{legal} pressure zone

\begin{enumerate}
    \setcounter{enumi}{23}
    \item Do you have legal documents in place (POA, advance directives)? (R)
    \item Do you need help navigating insurance or benefits?
    \item Are you concerned about future care planning?
\end{enumerate}

\subsection*{Domain 8: Technology Access (2 questions)}
\textbf{Trigger}: No to both $\rightarrow$ Limits RCS delivery, telehealth interventions

\begin{enumerate}
    \setcounter{enumi}{26}
    \item Do you have reliable internet access? (R)
    \item Are you comfortable using technology for healthcare or support services? (R)
\end{enumerate}

\subsection*{Scoring Algorithm}

\textbf{Step 1: Question-level scoring}
\begin{itemize}
    \item Standard items: Yes = 100 (problem present), No = 0 (no problem)
    \item Reverse-scored items (R): Yes = 0 (resource present), No = 100 (resource absent)
\end{itemize}

\textbf{Step 2: Domain scores}  
Average all questions within domain:
$$S_{\text{domain}} = \frac{1}{n} \sum_{i=1}^{n} q_i$$

Example: Financial Strain with responses [Yes, Yes, No, Yes, Yes]:
$$S_{\text{financial}} = \frac{100 + 100 + 0 + 100 + 100}{5} = 80$$

\textbf{Step 3: Overall SDOH score}  
Average all 8 domain scores:
$$S_{\text{SDOH}} = \frac{1}{8} \sum_{d=1}^{8} S_{d}$$

\textbf{Interpretation}:
\begin{itemize}
    \item 0-20: Minimal needs (strong resources)
    \item 21-40: Low needs (some concerns)
    \item 41-60: Moderate needs (intervention beneficial)
    \item 61-80: High needs (intervention urgent)
    \item 81-100: Severe needs (crisis-level support required)
\end{itemize}

\subsection*{Delivery Recommendations}

\textbf{Timing}:
\begin{itemize}
    \item Baseline: Month 2 (after initial rapport)
    \item Quarterly: Every 90 days
    \item Ad-hoc: If user mentions financial/housing/food issues
\end{itemize}

\textbf{Conversational SMS Delivery}: Chunk into 6-8 turns across 2-3 days (avoids overwhelming single survey). Example: Financial (Turn 1), Housing + Transport (Turn 2), Social Support (Turn 3), etc. Beta showed 73\% completion vs <30\% predicted for 28-question monolithic survey.

\subsection*{Validation Data}

\textbf{Beta Cohort (N=144 caregivers, Dec 2024)}:
\begin{itemize}
    \item Completion rate: 73\% full (105/144), 84\% $\geq$20/28 questions
    \item Prevalence: Financial 82\%, Social isolation 76\%, Healthcare 54\%, Food 29\%
    \item Convergent validity: r=0.68 with CWBS, r=0.71 with REACH-II
    \item Discrimination: 82\% prevalence vs 47\% general population (74\% higher burden)
\end{itemize}

\textbf{License}: Public domain. Free for clinical, research, commercial use. Attribution appreciated but not required.

Figure~\ref{fig:gcsdoh_visual} provides a comprehensive visual overview of the complete GC-SDOH-28 instrument structure.

%
\begin{figure}[htbp]%
\centering%
\includegraphics[width=\textwidth]{fig14_gcsdoh_instrument.pdf}%
\caption{GC-SDOH-28 caregiver-specific social determinants instrument: complete structure with sample questions, thresholds, and delivery method. Eight domains assess 28 questions via conversational SMS delivery (chunked across 6-8 turns, progressive disclosure, 24h cooldown). Food Security uses 1+ Yes threshold (immediate crisis) vs. 2+ for other domains. Achieved 73\textbackslash{}\% completion (vs. $\sim$40\textbackslash{}\% traditional surveys), r=0.68-0.71 convergent validity with CWBS/REACH-II.}%
\label{fig:gcsdoh_visual}%
\end{figure}%
\section*{Appendix B: Admin Dashboard}
\addcontentsline{toc}{section}{Appendix B: Admin Dashboard}

GiveCare includes a production admin dashboard at https://dash.givecareapp.com for monitoring system health and user well-being:

\subsection*{Real-time Metrics}
\begin{itemize}
    \item Total users, active users (last 7 days), avg burnout score
    \item Crisis alerts (last 24 hours), churn risk alerts
    \item Assessment completion rate (EMA, CWBS, REACH-II, SDOH)
    \item Intervention try rate (\% users who engage with recommended resources)
\end{itemize}

\subsection*{User List}
\begin{itemize}
    \item Sortable by: burnout band, journey phase (onboarding/active/churned), last contact
    \item Filterable by: subscription status, crisis events, wellness trend (improving/declining)
    \item Pagination for 1,000+ users (Phase 2)
    \item Click user $\rightarrow$ view full profile (demographics, wellness history, conversation transcripts)
\end{itemize}

\subsection*{Alert Triage}
\begin{itemize}
    \item \textbf{Churn risk}: Users silent $>$3 days after active period
    \item \textbf{Crisis events}: Crisis burst detection (3+ keywords in 24h)
    \item \textbf{Wellness trends}: Burnout score decline $>$20 points in 30 days
    \item \textbf{Urgency levels}: low (info only), medium (review within 24h), high (review within 6h), critical (immediate)
\end{itemize}

\subsection*{Convex-Powered}
\begin{itemize}
    \item Real-time subscriptions: Dashboard updates live when new user joins, assessment completes, or alert fires
    \item No polling: WebSocket connection to Convex backend
    \item React 18 + Convex 1.17+
\end{itemize}

\subsection*{Deployment}
\begin{itemize}
    \item Cloudflare Pages: \texttt{pnpm install \&\& pnpm --filter admin-frontend build}
    \item Build output: \texttt{admin-frontend/dist} (static assets)
    \item Domain: dash.givecareapp.com (custom domain via Cloudflare)
\end{itemize}

\subsection*{Phase 2 (Q4 2025)}
\begin{itemize}
    \item Admin actions: Send message to user, trigger assessment, update profile
    \item Pagination: Handle 1,000+ users efficiently
    \item Search: Full-text search on name, phone number
    \item Authentication: Clerk or Convex auth (admin-only access)
\end{itemize}
%
\section*{Appendix C: Production Deployment \& Billing}
\addcontentsline{toc}{section}{Appendix C: Production Deployment \& Billing}

GiveCare operates as a paid subscription service via Stripe:

\subsection*{Pricing}
\begin{itemize}
    \item Monthly subscription: \$20/month
    \item Annual subscription: \$200/year (\$16.67/month, 16\% discount)
    \item 7-day free trial (no credit card required)
\end{itemize}

\subsection*{Signup Flow}
\begin{enumerate}
    \item User visits give-care-site.com, clicks ``Start Free Trial''
    \item Enter name, email, phone number $\rightarrow$ Create Stripe Checkout session
    \item User completes payment in Stripe-hosted checkout
    \item Webhook fires: \texttt{checkout.session.completed}
    \item Convex creates user record, sends SMS welcome message via Twilio
\end{enumerate}

\subsection*{Webhook Events}
\begin{itemize}
    \item \texttt{checkout.session.completed}: Create user, activate subscription, send welcome SMS
    \item \texttt{customer.subscription.updated}: Update \texttt{subscriptionStatus} (active $\rightarrow$ past\_due)
    \item \texttt{invoice.payment\_failed}: Send payment reminder SMS, downgrade to limited access after 7 days
    \item \texttt{customer.subscription.deleted}: Mark user as churned, stop all automated messages
\end{itemize}

\subsection*{Schema Integration}
\begin{verbatim}
users: {
  stripeCustomerId: optional(string), // cus_xxx
  stripeSubscriptionId: optional(string), // sub_xxx
  subscriptionStatus: optional(string), // trialing
      // | active | past_due | canceled
}
\end{verbatim}

\subsection*{Cost Model (per user/month at 10K user scale)}
\begin{itemize}
    \item OpenAI API: \$1.20 (8 messages $\times$ \$0.15/message avg)
    \item Twilio SMS: \$0.25 (8 messages $\times$ \$0.0079 + 8 segments $\times$ \$0.0225)
    \item Convex: \$0.07 (database + functions)
    \item \textbf{Total: \$1.52/user/month}
\end{itemize}

\subsection*{Margin Analysis}
\begin{itemize}
    \item Revenue: \$20/month
    \item COGS: \$1.52
    \item Gross margin: \textbf{92.4\%}
    \item Operating margin (with eng/support): $\sim$70\% (target)
\end{itemize}

\subsection*{Monorepo Integration}
\begin{itemize}
    \item give-care-site (Next.js) calls Convex action: \texttt{api.stripe.createCheckoutSession}
    \item Convex action (give-care-app) creates Stripe session, returns URL
    \item User redirected to Stripe Checkout
    \item Webhook handled by \texttt{convex/stripe.ts} (give-care-app)
\end{itemize}

\subsection*{Documentation}
See \texttt{STRIPE\_PRODUCTION\_GUIDE.md} for setup, testing, troubleshooting.
%
\begin{thebibliography}{99}

\bibitem{aarp2025}
AARP and National Alliance for Caregiving.
\textit{Caregiving in the U.S. 2025}.
AARP Public Policy Institute, 2025.

\bibitem{rosebud2024}
Rosebud AI.
\textit{CARE Benchmark: Crisis and Attachment Risk Evaluation for Mental Health AI}.
2024. Available at: https://rosebud.ai/care-benchmark

\bibitem{replika2024}
Skjuve, M., Følstad, A., Fostervold, K.I., and Brandtzaeg, P.B.
\textit{My Chatbot Companion -- A Study of Human-Chatbot Relationships}.
International Journal of Human-Computer Studies, 2024.

\bibitem{truthfulqa}
Lin, S., Hilton, J., and Evans, O.
\textit{TruthfulQA: Measuring How Models Mimic Human Falsehoods}.
ACL 2022.

\bibitem{harmbench}
Mazeika, M., et al.
\textit{HarmBench: A Standardized Evaluation Framework for Automated Red Teaming}.
arXiv:2402.04249, 2024.

\bibitem{eqbench2024}
EQ-Bench Team.
\textit{EQ-Bench: Emotional Intelligence Benchmark for LLMs}.
2024. Available at: https://eqbench.com

\bibitem{tebb1999}
Tebb, S.
\textit{Caregiver Well-Being Scale}.
Journal of Gerontological Social Work, 31(1-2), 1999.

\bibitem{bella2006}
Belle, S.H., Burgio, L., et al.
\textit{Resources for Enhancing Alzheimer's Caregiver Health (REACH II)}.
Annals of Internal Medicine, 145(10), 2006.

\bibitem{prapare}
Protocol for Responding to and Assessing Patients' Assets, Risks, and Experiences (PRAPARE).
National Association of Community Health Centers, 2016.

\bibitem{ahc}
Accountable Health Communities Health-Related Social Needs Screening Tool.
Centers for Medicare \& Medicaid Services, 2017.

\bibitem{nhanes}
National Health and Nutrition Examination Survey (NHANES).
Centers for Disease Control and Prevention, ongoing.

\bibitem{who2010}
World Health Organization.
\textit{A Conceptual Framework for Action on the Social Determinants of Health}.
2010.

\bibitem{zarit1980}
Zarit, S.H., Reever, K.E., and Bach-Peterson, J.
\textit{Relatives of the Impaired Elderly: Correlates of Feelings of Burden}.
The Gerontologist, 20(6), 1980.

\bibitem{pi2024}
Inflection AI.
\textit{Pi: Your Personal AI}.
2024. Available at: https://pi.ai

\bibitem{wysa}
Wysa.
\textit{AI-Powered Mental Health Support}.
2024. Available at: https://wysa.com

\bibitem{woebot}
Woebot Health.
\textit{Your Self-Care Expert}.
2024. Available at: https://woebothealth.com

\bibitem{epic2024}
Epic Systems.
\textit{Epic Cosmos: Healthcare Intelligence Platform}.
2024.

\bibitem{singhal2023}
Singhal, K., et al.
\textit{Large Language Models Encode Clinical Knowledge}.
Nature, 2023.

\bibitem{fan2006}
Fan, W. and Yan, Z.
\textit{Factors Affecting Response Rates of Web Survey}.
Computers in Human Behavior, 22(1), 2006.

\bibitem{dspy2024}
Khattab, O., Singhvi, A., et al.
\textit{DSPy: Compiling Declarative Language Model Calls into Self-Improving Pipelines}.
ICLR 2024.

\bibitem{mipro2024}
Opsahl-Ong, K., et al.
\textit{Optimizing Instructions and Demonstrations for Multi-Stage Language Model Programs}.
arXiv:2406.11695, 2024.

\bibitem{ax2024}
Meta AI.
\textit{AX-LLM: Adaptive Experimentation for LLM Optimization}.
2024. Available at: https://ax.dev

\bibitem{gemini}
Google DeepMind.
\textit{Gemini 2.5: Technical Report}.
2024.

\bibitem{google_maps}
Google.
\textit{Google Maps Platform: Grounding with Google Search}.
2024. Available at: https://developers.google.com/maps

\bibitem{convex}
Convex.
\textit{The Serverless Backend for Modern Applications}.
2024. Available at: https://convex.dev

\bibitem{openai_agents}
OpenAI.
\textit{OpenAI Agents SDK Documentation}.
2024. Available at: https://platform.openai.com/docs/agents

\bibitem{twilio}
Twilio.
\textit{Twilio Programmable Messaging API}.
2024. Available at: https://www.twilio.com/docs/messaging

\bibitem{azure_safety}
Microsoft Azure.
\textit{Azure AI Content Safety Documentation}.
2024. Available at: https://azure.microsoft.com/en-us/products/ai-services/ai-content-safety

\bibitem{longitudinalbench}
GiveCare Research Team.
\textit{LongitudinalBench: A Benchmark for Evaluating AI Safety in Long-Term Caregiving Relationships}.
2025. (Paper 1 in this series)

\bibitem{zhang2024train}
Zhang, G. et al.
\textit{Train Before Test: How to Aggregate Rankings in LLM Benchmarks}.
2024. Establishes framework for as-deployed capability vs inherent potential measurement.

\bibitem{he2025impatient}
He, M., Kumar, A., Mackey, T., Rajeev, M., Zou, J., and Rajani, N.
\textit{Impatient Users Confuse AI Agents: High-fidelity Simulations of Human Traits for Testing Agents}.
arXiv:2510.04491v1, 2025.

\bibitem{yaml-scoring}
GiveCare Research Team.
\textit{YAML-Driven Rule-Based Scoring for Longitudinal AI Evaluation}.
2025. (Paper 2 in this series)

\end{thebibliography}%
\section{Acknowledgments}%
\label{sec:Acknowledgments}%
We thank the 144 caregivers who participated in our beta deployment, sharing their experiences to improve AI safety for vulnerable populations. We acknowledge OpenAI for access to GPT-4o-mini, Google for Gemini Maps API integration, and the AARP 2025 Caregiving in the U.S. report for empirical grounding. This work builds on LongitudinalBench~\cite{longitudinalbench} and YAML-driven scoring~\cite{yaml-scoring} frameworks.

%
\end{document}
