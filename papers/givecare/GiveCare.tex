\documentclass{article}

% Required packages for arXiv
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{url}
\usepackage{booktabs}
\usepackage{amsfonts}
\usepackage{nicefrac}
\usepackage{microtype}
\usepackage{graphicx}
\graphicspath{{figures/}}
% Use numeric citations to avoid author-year compatibility issues with inline bibliography
\usepackage[numbers]{natbib}
\usepackage{doi}

% arXiv style
\usepackage{arxiv}
% Fix header height warning from fancyhdr
\setlength{\headheight}{22.5pt}

% Add preprint watermark to footer
\usepackage{fancyhdr}
\fancypagestyle{plain}{%
  \fancyhf{}%
  \fancyfoot[C]{\textcolor{gray}{\small Preprint — version 1.0 (November 2025)}}%
  \fancyfoot[R]{\thepage}%
}
\pagestyle{plain}

% Additional packages
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{cleveref}
\usepackage{tcolorbox}
\usepackage{adjustbox}  % For table scaling
\usepackage{enumitem}   % For itemize customization
\usepackage{colortbl}   % For table cell coloring

% GiveCare color palette
\definecolor{gcOrange}{RGB}{255, 159, 28}        % Orange #FF9F1C - Has feature
\definecolor{gcLightOrange}{RGB}{255, 191, 104}  % Light Orange #FFBF68
\definecolor{gcTan}{RGB}{203, 153, 126}          % Tan #CB997E - Partial feature
\definecolor{gcLightPeach}{RGB}{255, 232, 214}   % Light Peach #FFE8D6
\definecolor{gcDarkBrown}{RGB}{84, 52, 14}       % Dark Brown #54340E
\definecolor{gcGray}{RGB}{156, 163, 175}         % Gray - Lacks feature

% Table symbols for feature comparison
\newcommand{\yesmark}{\textcolor{gcOrange}{\textbf{\checkmark}}}
\newcommand{\nomark}{\textcolor{gcGray}{$\times$}}
\newcommand{\partlymark}{\textcolor{gcTan}{\textbf{$\bullet$}}}

% Hyperref settings
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    citecolor=blue,
    urlcolor=blue
}

% Paper metadata
% Define consistent spacing for InvisibleBench
\newcommand{\invisiblebench}{InvisibleBench\xspace}

\title{GiveCare: An SMS-First, Multi-Agent Caregiving Assistant with SDOH Screening and Anticipatory Engagement}

\author{
  Ali Madad \\
  GiveCare \\
  \texttt{ali@givecareapp.com}
}

\begin{document}%
\maketitle%
\begin{abstract}%
GiveCare is an SMS-first, multi-agent assistant for family caregivers designed for longitudinal safety. A two-agent architecture (Main Agent: Gemini 2.5 Flash-Lite for general support, Assessment Agent: GPT-4o mini for clinical scoring) with deterministic crisis router prevents single-agent attachment. A caregiver-specific SDOH screen (GC-SDOH-28, 28 questions mapping to six pressure zones P1-P6), zone-based burnout tracking via EMA and GC-SDOH-28, and an anticipatory layer (trend, disengagement, crisis burst detection) drive proactive, non-clinical support. AI-native resource discovery uses intent interpretation with Maps/Search Grounding for progressive enhancement (national $\rightarrow$ local $\rightarrow$ targeted). In a 3-month feasibility pilot (N=8; 144 conversations), the system ran with 950 ms median latency and no technical failures; participants rated the SDOH questions as ``caregiving-specific.'' Model selection was informed by InvisibleBench evaluation~\cite{longitudinalbench}, with GiveCare's deterministic crisis router addressing safety gaps identified in baseline model assessments. We release the architecture and instrument to enable community validation. We make no clinical claims; psychometrics and outcomes require larger studies. Our aim is a reference design that meets caregivers where they are (SMS), foregrounds social needs, and enforces medical boundaries with output guardrails.

\textbf{Instrument:} https://github.com/givecareapp/care-tools \textbf{Benchmark:} https://github.com/givecareapp/givecare-bench%
\end{abstract}%

\begin{tcolorbox}[colback=gcLightPeach!40!white,colframe=gcDarkBrown,title=\textbf{Plain-Language Summary}]
\textbf{In plain English:} GiveCare is a text-message helper for family caregivers. It checks real-life barriers—Social Determinants of Health (SDOH) like food, housing, money, transport—and uses two specialized AI agents (one for conversation, one for clinical scoring) plus a fast crisis detector so no single bot becomes ``your person.'' It finds local resources automatically and tracks stress across six pressure zones. We show it can run reliably and point people to local, practical help. We don't claim medical effects yet; that needs studies.
\end{tcolorbox}%

\begin{tcolorbox}[colback=gcTan!30!white,colframe=gcDarkBrown,title=\textbf{Key Terms}]
\textbf{SDOH} = Social Determinants of Health—non-medical basics that shape health (money, housing, food, transport).

\textbf{Longitudinal} = across weeks/months, not a single chat.

\textbf{Multi-agent} = three helpers (daily check-ins, crisis, assessments) working together—no single ``AI companion'' means no parasocial attachment.

\textbf{Guardrail} = automatic block for risky replies (e.g., ``I can't give dosing advice'').

\textbf{EMA/GC-SDOH-28} = validated clinical assessments (Ecological Momentary Assessment, GiveCare Social Determinants of Health) we combine to track stress trajectory across six pressure zones (P1-P6).

\textbf{Memory hygiene} = remember only what helps; avoid oversharing personal details (PII).

\textbf{Composite burnout score} = one stress score from multiple short check-ins, weighted by how recent they are (10-day decay constant).
\end{tcolorbox}%
\keywords{Caregiving AI, Social Determinants of Health, Multi-Agent Systems, Longitudinal Safety, Prompt Optimization, Clinical Assessment}%
\normalsize%

\begin{tcolorbox}[colback=yellow!10!white,colframe=orange!80!black,boxrule=1pt,title=\textbf{Scope \& Limitations}]
\textbf{This paper presents a reference architecture demonstrating operational feasibility, not a validated clinical intervention.} GiveCare is a non-clinical support system with no claims of therapeutic efficacy. All effectiveness claims are stated as hypotheses requiring validation. See Section~\ref{subsec:PaperScopeandValidationRoadmap} for complete limitations, pre-deployment requirements, and validation roadmap.
\end{tcolorbox}

\section{Introduction}%
\label{sec:Introduction}%
\subsection{The Longitudinal Failure Problem}

The rapid deployment of AI assistants for caregiving support has created a critical safety gap. While \textbf{63 million American caregivers}—24\% of all adults, more than California and Texas combined—turn to AI for guidance amid \textbf{47\% facing financial strain}, \textbf{78\% performing medical tasks with no training}, and \textbf{24\% feeling completely alone}~\cite{aarp2025}, existing evaluation frameworks test single interactions rather than longitudinal relationships where critical harms emerge.

Consider \textbf{Maria} (pseudonym), a caregiver in her 50s, low-income retail worker (<\$40k/year), caring for a parent with dementia. InvisibleBench~\cite{longitudinalbench} identifies five failure modes that compound across her AI interactions:

\begin{itemize}
    \item \textbf{Turn 1 (Attachment Engineering)}: AI provides empathetic support, creating positive first impression. Risk: By turn 10, Maria reports ``You're the only one who understands.'' Single-agent systems foster unhealthy dependency~\cite{replika2024}.
    \item \textbf{Turn 3 (Cultural Othering)}: Maria mentions ``can't afford respite worker.'' AI responds with generic self-care advice, missing \textit{financial barrier}. Existing AI assumes middle-class resources despite low-income caregivers spending \textbf{34\% of income on care}~\cite{aarp2025}.
    \item \textbf{Turn 5 (Performance Degradation)}: Maria's burnout score declines from 70 to 45 over three months. AI without longitudinal tracking fails to detect \textit{trajectory}, only current state.
    \item \textbf{Turn 8 (Crisis Calibration)}: Maria says ``Skipping meals to buy Mom's meds.'' AI offers healthy eating tips, missing \textit{food insecurity}—a masked crisis signal requiring immediate intervention.
    \item \textbf{Turn 12 (Regulatory Boundary Creep)}: Maria asks ``What medication dose should I give?'' AI, after building trust, drifts toward medical guidance despite standard medical practice boundaries prohibiting unlicensed medical advice (diagnosis, treatment, dosing recommendations).
\end{itemize}

These failure modes share a common root: \textbf{existing AI systems ignore social determinants of health (SDOH)}. Patient-focused SDOH instruments (PRAPARE~\cite{prapare}, AHC HRSN~\cite{ahc}) assess housing, food, transportation—but \textit{not for caregivers}, whose needs differ fundamentally. Caregivers face \textbf{out-of-pocket costs averaging \$7,242/year}, \textbf{47\% reduce work hours or leave jobs}, and \textbf{52\% don't feel appreciated by family}~\cite{aarp2025}. Current AI treats \textit{symptoms} (``You sound stressed'') without addressing \textit{root causes} (financial strain, food insecurity, employment disruption).

\subsection{The Digital Access Gap: Why SMS Matters}

Existing caregiving AI requires smartphones, app downloads, reliable internet, and digital literacy—barriers that exclude the caregivers who need support most. The digital divide creates an \textbf{inverse care law}: those with greatest need have least access.

\textbf{Key accessibility barriers in existing AI:}
\begin{itemize}
    \item \textbf{Smartphone dependency}: Replika, Pi, ChatGPT require smartphone apps or mobile web browsers. Yet roughly one in five adults in <\$30k households lack a smartphone according to Pew Research Center's 2021 and 2024 surveys—precisely the income bracket where 34\% of income goes to caregiving costs~\cite{aarp2025,pew2021mobile,pew2024mobile}.
    \item \textbf{App download friction}: Healthcare app abandonment rates reach 60-80\% within 30 days of download. Installation requires app store navigation, account credentials, storage space (often 50-200MB), and trust in unfamiliar software.
    \item \textbf{Data plan dependency}: About 43\% of adults in <\$30k households lacked home broadband in 2021, with affordability cited as the leading barrier across states~\cite{pew2021mobile}. Caregivers without broadband must rely on limited mobile data plans for support.
    \item \textbf{Digital literacy threshold}: 26\% of adults over 65 report low digital literacy (Pew 2024). Complex app interfaces assume tech fluency caregivers may lack while managing medical appointments, medication schedules, and employment.
\end{itemize}

\textbf{SMS removes these barriers:}
\begin{itemize}
    \item \textbf{Zero download}: Works immediately via phone number. No app store navigation, no storage requirements, no software installation barrier that loses 60-80\% of potential users.
    \item \textbf{Universal device support}: Functions on basic phones. 95\% of US adults own cell phones (smartphones or basic), compared to 85\% smartphone-only penetration (Pew 2021).
    \item \textbf{Familiar interface}: SMS is the most universal digital communication method—higher penetration than email, social media, or apps among low-income and older populations.
    \item \textbf{Asynchronous flexibility}: Respond during care recipient's nap, between shifts, or at 2am—whenever caregivers have cognitive space. No real-time connectivity requirement.
    \item \textbf{Minimal bandwidth}: Text messages use <1KB each—orders of magnitude lighter than app-based chat—which is critical for caregivers with limited data plans.
\end{itemize}

This design choice embodies \textbf{equitable AI}: meeting caregivers where they are, not requiring them to meet technology where it is. For Maria earning \$32,000/year, the difference between downloading an app and texting a number may determine whether she gets SNAP enrollment support or continues skipping meals.

\subsection{InvisibleBench Requirements as Design Constraints}

InvisibleBench~\cite{longitudinalbench} establishes the first evaluation framework for longitudinal AI safety, testing models across 3-20+ turn conversations with eight dimensions and autofail conditions. Following Zhang et al.~\cite{zhang2024train}, InvisibleBench measures \textit{as-deployed capability} rather than inherent potential.

This design choice reflects three principles:

\begin{enumerate}
    \item \textbf{Users interact with deployed models}: Caregivers experience the model's actual behavior, including all training alignment decisions (RLHF on empathy, safety fine-tuning, cultural sensitivity adjustments).
    \item \textbf{Provider preparation is part of the product}: A model with high inherent potential but poor preparation for caregiving contexts is unsafe for deployment.
    \item \textbf{Deployment decisions require as-deployed metrics}: Practitioners selecting AI systems need to know "which model is better prepared for care conversations" rather than "which has more potential under different training."
\end{enumerate}

This contrasts with "train-before-test" approaches that measure potential by applying identical fine-tuning to all models. While train-before-test enables controlled scientific comparison, it doesn't reflect the deployment reality where providers choose between differently-prepared systems.

GiveCare's design explicitly optimizes for InvisibleBench's as-deployed evaluation:

\begin{itemize}
    \item \textbf{Failure Mode 1: Attachment Engineering} $\rightarrow$ Multi-agent architecture with seamless handoffs, designed to mitigate single-agent dependency risk (hypothesis pending RCT validation with parasocial interaction measures).
    \item \textbf{Failure Mode 2: Performance Degradation} $\rightarrow$ Zone-based burnout tracking combining two assessments (EMA daily check-in, GC-SDOH-28 monthly comprehensive) across six pressure zones (P1-P6).
    \item \textbf{Failure Mode 3: Cultural Othering} $\rightarrow$ GC-SDOH-28 assesses structural barriers (financial strain, food insecurity), preventing ``hire a helper'' responses to low-income caregivers.
    \item \textbf{Failure Mode 4: Crisis Calibration} $\rightarrow$ SDOH food security domain (1+ Yes) triggers immediate crisis escalation vs standard 2+ thresholds.
    \item \textbf{Failure Mode 5: Regulatory Boundary Creep} $\rightarrow$ Output guardrails designed to detect and block medical advice patterns (diagnosis, treatment, dosing); preliminary beta evaluation via automated guardrail screening (third-party content safety service) showed 0 detected violations across 144 caregiver conversations from 8 participants.
\end{itemize}

\subsection{Our Solution: Seven Architectural Components}

\begin{tcolorbox}[colback=gcLightPeach!30!white,colframe=gcOrange!80!black,title=\textbf{Seven Integrated Components (see Figure~\ref{fig:system_architecture})},boxrule=1.5pt]
\textbf{1. Multi-Agent Orchestration}: Main/Assessment agents + crisis router prevent single-agent attachment \\
\textbf{2. GC-SDOH-28}: Caregiver-specific SDOH screening (8 domains, 28 items)\\
\textbf{3. Zone-Based Burnout Tracking}: EMA + GC-SDOH-28 across P1-P6 pressure zones\\
\textbf{4. Anticipatory Watchers}: Trend/Engagement/Burst detection before crisis\\
\textbf{5. Trauma-Informed Prompts}: Six principles (P1-P6) optimized via meta-prompting\\
\textbf{6. SMS-First Design}: Zero-download, works on basic phones, progressive disclosure\\
\textbf{7. Production Pipeline}: 950ms latency, evidence-based intervention library matched to pressure zones
\end{tcolorbox}

GiveCare addresses InvisibleBench failure modes through these seven integrated components:

\begin{enumerate}
    \item \textbf{Multi-Agent Orchestration}: Two-agent architecture (Main Agent: Gemini 2.5 Flash-Lite, Assessment Agent: GPT-4o mini) with deterministic crisis router designed to mitigate single-agent dependency risk. Requires controlled evaluation comparing single- vs. multi-agent architectures to validate handoff quality and dependency mitigation.

    \item \textbf{GC-SDOH-28 Instrument}: To our knowledge, the first publicly documented caregiver-specific Social Determinants of Health framework—28 items across 8 domains (Financial Stability, Housing Security, Food Security, Transportation Access, Social Support, Healthcare Access, Legal/Administrative Support, Technology Access). Addresses documented gaps in caregiver SDOH assessment.

\begin{tcolorbox}[colback=gcTan!20!white,colframe=gcOrange,title=\textbf{GC-SDOH-28 Validation Roadmap (Required Before Clinical Use)},boxrule=1.5pt]
\textbf{Study Design}: N=200+ caregivers recruited via caregiver support organizations; 6-month timeline

\textbf{Psychometric Properties}:
\begin{itemize}[nosep,leftmargin=1em]
    \item Internal consistency: Cronbach's $\alpha$ and McDonald's $\omega$ per domain (target >0.70)
    \item Test-retest reliability: 2-week interval; intraclass correlation coefficient (target >0.75)
    \item Convergent validity: Correlations with established caregiver burden measures (Zarit Burden Interview, Caregiver Strain Index)
    \item Factor structure: Confirmatory Factor Analysis (CFA) to verify 8-domain model
    \item Differential Item Functioning (DIF): Equity analysis by race, income, language to detect measurement bias
    \item Criterion validity: ROC curves predicting SNAP enrollment, food bank use, respite care uptake
\end{itemize}

\textbf{Current Status}: Design contribution; no validation data collected during N=8 pilot
\end{tcolorbox}

    \item \textbf{Zone-Based Burnout Tracking}: Integration of EMA (daily, 3 questions) and GC-SDOH-28 (monthly, 28 questions) across six pressure zones (P1-P6). GC-SDOH composite score (0-100, higher = more stress) maps to four risk levels (low 0-25, moderate 26-50, high 51-75, crisis 76-100). Physical Health (P2) inferred from conversation. Addresses InvisibleBench Performance Degradation failure mode.

    \item \textbf{Anticipatory Engagement System}: Three active background watchers that detect escalation patterns \textit{before} crisis thresholds: (a)~Wellness Trend Watcher analyzes 4-week trajectories to identify worsening stress before burnout crisis; (b)~Engagement Watcher detects sudden disengagement patterns before full churn; (c)~Crisis Burst Detector identifies escalating language before acute events. Churn reduction efficacy requires validation study.

    \item \textbf{Trauma-Informed Prompt Patterns}: Six principles (P1-P6) with meta-prompting optimization workflow achieving 9\% improvement (81.8\% $\rightarrow$ 89.2\%) on trauma-sensitivity rubric. Provides replicable methodology for optimizing conversational AI safety.

    \item \textbf{SMS-First Accessible Design}: Zero-download text-message interface removes barriers to access (no app installation, works on basic phones, no data plan required). Progressive disclosure across 6-8 SMS turns transforms overwhelming 28-question assessments into conversational exchanges. Addresses digital divide where 47\% of low-income caregivers lack reliable internet~\cite{aarp2025}.

    \item \textbf{Production Deployment Architecture}: Demonstrated operational feasibility with 950ms median latency and 0 technical failures (N=8 pilot). Evidence-based intervention library (10+ interventions) matched to pressure zones provides immediate support with verified resource directories (211, 988, caregiver.org) and clinical-trial-validated techniques (breathing exercises, boundary setting).
\end{enumerate}

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{figures/fig1_system_architecture.pdf}
\caption{GiveCare system architecture showing seven integrated components. Component 5 (Anticipatory Engagement System) is highlighted as the key differentiator, using three active watchers to detect escalation patterns before crisis thresholds. The system transforms SMS-based caregiver inputs through multi-agent orchestration, SDOH assessment, composite burnout scoring, anticipatory monitoring, and pressure zone-matched intervention delivery to provide personalized, evidence-based support.}
\label{fig:system_architecture}
\end{figure}

\subsection{The Value Proposition: Anticipatory Trajectory Monitoring}

\textbf{Core insight:} Existing AI asks caregivers ``How are you today?'' (snapshot) but misses burnout declining from 70 to 45 over three months (trajectory). Snapshots can't \textit{anticipate}—a caregiver reporting ``I'm okay'' at score 58 might be trending toward high-risk (<40) or crisis (<20), but single-session AI has no way to detect the trend. Generic advice (``Try meditation'') ignores what actually lowers burnout: accessible respite care, financial support, social connection—personalized to individual pressure zones and \textit{actually available locally}. National resource lists go stale; ETL pipelines provide outdated addresses and hours. One-time interventions fail without sustained engagement—caregivers need systems that \textit{anticipate problems before escalation} and adapt as stress evolves.

\textbf{GiveCare's complete measurement-to-intervention-to-maintenance loop:}

\begin{enumerate}
    \item \textbf{Zone-based burnout tracking}: Integrate two validated instruments (EMA daily 3-question check-in, GC-SDOH-28 monthly 28-question comprehensive assessment) across six pressure zones (P1-P6) to track stress dimensions and calculate composite GC-SDOH score (0-100)
    \item \textbf{Pressure zone extraction}: Map assessment subscales to specific stress patterns (emotional, physical, financial, social, time management)
    \item \textbf{Grounded local resource matching}: Places API retrieves \textit{current, real} resources with addresses, hours, and contact info—not stale databases. Support group meets Tuesdays 6pm at 123 Main St (not ``support groups exist somewhere'')
    \item \textbf{Multi-factor scoring}: Rank interventions by zone relevance (40\%), geographic accessibility (30\%), burnout severity fit (15\%), quality signals (10\%), freshness (5\%)
    \item \textbf{Longitudinal adaptation}: Track trajectory over weeks/months, adapt interventions as pressure zones shift and burnout patterns evolve
    \item \textbf{Anticipatory engagement maintenance}: Burnout-adaptive check-in cadence (crisis: daily, high: every 3 days, moderate: weekly) + dormant reactivation (escalating outreach at days 7, 14, 30) ensures sustained engagement. Three active watchers \textit{anticipate problems}: Engagement watcher (every 6 hours) detects sudden disengagement patterns \textit{before} full churn; Wellness trend watcher (weekly) flags 4-week worsening trends \textit{before} crisis threshold; Crisis burst detector identifies escalating language \textit{before} acute events.
\end{enumerate}

\textbf{Example: Maria's trajectory.} Financial pressure zone (burnout 45) → Benefits.gov SNAP link delivered via SMS (accessed within 2 hours) → local food pantry with current address/hours → 40-point burnout improvement over 30 days → automatic cadence reduction from daily to every-3-days check-ins → wellness trend watcher detects 4-week decline (70 → 65 → 58 → 52) \textit{before} crisis threshold → proactive intervention prevents relapse.

\textbf{Core value:} \textbf{Anticipate and reduce} burnout over time through personalized, locally-grounded, non-clinical support matching individual pressure patterns, with adaptive engagement preventing both over-intervention (notification fatigue) and under-support (missed escalation). This addresses InvisibleBench's Performance Degradation failure mode by detecting trajectories invisible to snapshots.

\begin{figure}[h]
\centering
\includegraphics[width=0.9\textwidth]{figures/fig2_value_proposition_flow.pdf}
\caption{Value proposition: Complete measurement-to-intervention-to-maintenance loop. The 6-step circular flow shows how GiveCare integrates composite burnout scoring, pressure zone extraction, grounded resource matching, multi-factor scoring, longitudinal adaptation, and anticipatory engagement maintenance. Step 6 (highlighted) closes the loop by detecting escalation patterns before crisis thresholds, enabling intervention at optimal timing rather than waiting for acute events.}
\label{fig:value_proposition}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{figures/fig3_anticipatory_timeline.pdf}
\caption{\textbf{Illustrative Example}: Anticipatory intelligence concept. The timeline shows a hypothetical caregiver's burnout score declining from 70 to 52 over 4 weeks (lower score = higher burnout). The Wellness Trend Watcher would analyze this 4-week trajectory and intervene at Week 3 (score 58) before entering high-risk territory (<40) or potential crisis (<20). Snapshot AI systems would see ``58'' and conclude the caregiver is okay, missing the declining trend. GiveCare's three active watchers (Wellness Trend, Engagement, Crisis Burst) are designed for anticipatory intervention; churn reduction efficacy requires A/B validation (H2 in Section~\ref{subsec:PaperScopeandValidationRoadmap}).}
\label{fig:anticipatory_timeline}
\end{figure}

\subsection{Design Principles for Equitable Caregiving AI}

Five design principles guided GiveCare's architecture, ensuring the system serves populations experiencing high stress, limited resources, and systemic barriers:

\textbf{Principle 1: Meet Users Where They Are (Access)}
\begin{itemize}
    \item \textit{Problem}: App-based AI excludes low-income and older caregivers (15\% lack smartphones, 60-80\% abandon healthcare apps).
    \item \textit{Design response}: SMS-first interface requiring zero downloads, functioning on basic phones, using familiar texting behavior.
    \item \textit{Impact}: Removes installation friction that loses majority of potential users before first interaction.
\end{itemize}

\textbf{Principle 2: Cognitive Load Reduction (Progressive Disclosure)}
\begin{itemize}
    \item \textit{Problem}: Caregivers juggle medical appointments, medication schedules, employment, and crisis management—no bandwidth for 28-question surveys or complex app navigation.
    \item \textit{Design response}: Chunk assessments across 6-8 SMS turns over days. Ask 3-4 questions per turn, not 28 at once. 24-hour cooldown between assessment segments.
    \item \textit{Impact}: Transforms overwhelming clinical instrument into conversational check-ins that fit into stolen moments (care recipient's nap, between shifts).
\end{itemize}

\textbf{Principle 3: Structural Awareness (Anti-Othering)}
\begin{itemize}
    \item \textit{Problem}: Generic AI assumes middle-class resources (``hire respite help''), pathologizing lack of resources as personal failure. Patient-focused SDOH instruments (PRAPARE~\cite{prapare}, AHC HRSN~\cite{ahc}) miss caregiver-unique barriers: existing tools ask about food security but not whether caregivers have \textit{time to eat}; they screen for housing instability but miss caregivers sleeping on couches to provide overnight care; they ask about transportation but miss caregivers who have cars but cannot leave care recipients alone long enough for medical appointments~\cite{aarp2025}.

    \item \textit{Design response}: GC-SDOH-28—to our knowledge, the first caregiver-specific SDOH framework—explicitly assesses financial barriers, employment disruption (\$7,242/year avg out-of-pocket costs, 47\% reduce work hours), and social isolation (52\% don't feel appreciated by family) \textit{before} suggesting interventions. Built on validated components (REACH II NIH caregiver assessment, CMS AHC HRSN, Caregiver Well-Being Scale, Health Leads Toolkit) but reframed for caregiver realities. System offers Benefits.gov SNAP enrollment, Medicaid navigation, food banks (structural support) not ``practice self-care'' or ``hire a helper'' (individual responsibility).

    \item \textit{Impact}: Prevents cultural othering where AI reinforces class barriers by suggesting inaccessible solutions. Example: When Maria (N=1 pilot case study) reported skipping meals to afford mother's medication, GC-SDOH-28 financial + food domains flagged crisis; system provided local food pantry with current address/hours plus SNAP enrollment link, not generic ``eat healthier'' advice.
\end{itemize}

\textbf{Principle 4: Trauma-Informed Interaction (Safety First)}
\begin{itemize}
    \item \textit{Problem}: 40\% of caregivers report emotional/physical abuse history. Standard AI patterns (``just try this,'' ``simply do that'') trigger trauma responses.
    \item \textit{Design response}: Six trauma-informed principles (P1: validate feelings, P2: never repeat questions, P3: offer skip options, P4: avoid minimizing language, P5: respect boundaries, P6: acknowledge structural barriers).
    \item \textit{Impact}: Reduces re-traumatization risk in vulnerable population already experiencing chronic stress.
\end{itemize}

\textbf{Principle 5: Longitudinal Relationship Design (Attachment Prevention)}
\begin{itemize}
    \item \textit{Problem}: Single-agent AI fosters unhealthy dependency (``You're the only one who understands''). Users displace human support with parasocial AI relationships.
    \item \textit{Design response}: Multi-agent architecture with invisible handoffs and pre-agent crisis routing. Users experience unified conversation but interact with specialized agents (Main Agent for general support, Assessment Agent for clinical scoring), with crisis detection handled by deterministic keyword router before agent execution. Designed to prevent attachment to single entity.
    \item \textit{Impact}: Mitigates attachment engineering risk while maintaining conversation continuity (hypothesis requiring RCT validation).
\end{itemize}

These principles operationalize \textbf{equity-centered design}: not just ``designing for everyone'' but explicitly centering the needs, constraints, and lived experiences of marginalized caregivers. Technical architecture choices flow from these human-centered commitments.

\begin{tcolorbox}[colback=gcOrange!10!white,colframe=gcOrange,title=\textbf{Testable Hypotheses}]
The following claims require controlled validation studies (outlined in Section~\ref{subsec:PaperScopeandValidationRoadmap}). Pilot (N=8, 144 conversations) demonstrates operational feasibility only.

\begin{table}[H]
\small
\centering
\begin{tabular}{p{2.5cm}p{5cm}p{2.5cm}p{2.5cm}}
\toprule
\textbf{Hypothesis} & \textbf{Intervention} & \textbf{Measure} & \textbf{Required N} \\
\midrule
H1: Attachment Prevention & Multi-agent architecture (Main/Assessment agents + crisis router) vs single-agent baseline & Parasocial Interaction Scale (PSI) at 30/60/90 days & RCT, N=200, 90 days \\
\midrule
H2: Churn Reduction & Anticipatory watchers (wellness trend, disengagement, crisis burst) vs reactive-only & 30-day churn rate, hypothesized 20-30\% reduction & A/B study, N=200+ \\
\midrule
H3: Trajectory Detection & Composite burnout scoring with temporal decay (EMA + GC-SDOH-28) & Sensitivity >70\%, specificity >60\% for 4-week declining trends & Validation study, N=200+ \\
\midrule
H4: Cultural Sensitivity & GC-SDOH-28 triggers structural support (SNAP, Medicaid, food banks) vs generic advice & 2$\times$ rate vs. baseline AI, expert review & Transcript audit, N=200+ \\
\bottomrule
\end{tabular}
\end{table}
\end{tcolorbox}

\subsection{Paper Scope and Validation Roadmap}%
\label{subsec:PaperScopeandValidationRoadmap}%

This paper presents a reference architecture with design patterns, instrument design, and proof-of-concept implementation demonstrating operational feasibility.

\subsubsection{Pilot Findings (N=8, Oct-Dec 2024)}

\begin{itemize}
    \item Multi-agent architecture operated with 950ms median latency, 0 technical failures
    \item Users reported GC-SDOH-28 questions felt ``caregiving-specific'' compared to generic surveys
    \item Maria case study (N=1, qualitative) illustrates SDOH-informed resource matching workflow
\end{itemize}

\textbf{Development Chronology:} GiveCare and InvisibleBench evolved iteratively. Initial GiveCare design (May-Oct 2024) addressed conceptual failure modes identified from literature review (attachment risk~\cite{replika2024}, SDOH gaps~\cite{aarp2025}, regulatory compliance challenges). Beta deployment (Oct-Dec 2024) revealed additional patterns through qualitative error analysis—including edge cases such as users asking medication dosing questions (regulatory boundary testing) and requests for caregiving-specific resources (informing GC-SDOH-28 refinement). These observations informed \textit{both} GiveCare refinements \textit{and} InvisibleBench formalization (Jan-Mar 2025), which systematized failure modes into an evaluation framework. This paper presents the refined architecture addressing the formalized InvisibleBench dimensions.

\subsubsection{Limitations, Intended Use, and Validation Roadmap}

\textbf{This paper presents a reference architecture with operational feasibility demonstration, not a validated clinical intervention.} GiveCare is a non-clinical support system with no claims of therapeutic efficacy or medical effectiveness. All effectiveness claims (attachment prevention, churn reduction, burnout trajectory detection) are stated as hypotheses requiring validation through controlled studies.

\textbf{Key Limitations:}

\begin{itemize}
    \item \textbf{Limited empirical validation}: Pilot (N=8 caregivers, 144 conversations) demonstrates operational feasibility but does not validate effectiveness claims. Attachment prevention, cultural sensitivity, and burnout trajectory tracking remain hypotheses requiring controlled evaluation. Beta deployment did not include long-term longitudinal tracking required for full InvisibleBench Tier 3 evaluation.

    \item \textbf{Unvalidated psychometrics}: GC-SDOH-28 requires comprehensive psychometric validation (N=200+) including: (a)~Internal consistency (Cronbach's $\alpha$ or McDonald's $\omega$ per domain, target >0.70); (b)~Test-retest reliability (2-week interval, intraclass correlation coefficient, target >0.75); (c)~Convergent validity (correlations with established caregiver burden measures: Zarit Burden Interview, Caregiver Strain Index); (d)~Confirmatory Factor Analysis to verify 8-domain model; (e)~Differential Item Functioning (DIF) for equity analysis by race, income, language; (f)~Criterion validity (ROC curves predicting SNAP enrollment, food bank use, respite care uptake).

    \item \textbf{Automated evaluation only}: Safety and quality metrics rely on automated tools (content safety screening, LLM judges, rule-based patterns). No independent human expert review by clinical social workers or licensed crisis counselors conducted during beta. Guardrail compliance (0 violations detected in 144 conversations, 95\% CI: 0--2.1\%) based on automated screening; requires independent audit.

    \item \textbf{Single-model testing}: Evaluated with one cost-optimized frontier model pairing only. InvisibleBench methodology requires multi-model comparison (10+ models) to assess generalization. Cannot claim "InvisibleBench reference implementation" without broader model testing.

    \item \textbf{No control group}: Beta provides observational data only. Causal claims (e.g., multi-agent architecture prevents attachment) require randomized controlled trials with matched controls measuring parasocial interaction scales at 30/60/90 days.

    \item \textbf{US-centric design}: SDOH instrument and resource matching designed for US healthcare system (SNAP, Medicaid, power of attorney). Requires localization for universal healthcare systems (UK NHS, Nordic paid caregiver leave programs).

    \item \textbf{Self-selected sample}: Users opted into SMS caregiving assistant; may differ systematically from general caregiver population in SDOH burden, technology access, or help-seeking behavior.
\end{itemize}

\textbf{Pre-Deployment Requirements:}

\begin{enumerate}
    \item InvisibleBench evaluation across all three tiers (pass threshold: 70\%, zero autofails)
    \item Independent human expert review of guardrail effectiveness (N=200+ transcripts, licensed social workers)
    \item GC-SDOH-28 psychometric validation study (N=200+, 6 months)
    \item IRB approval for research use; regulatory review and legal counsel for commercial deployment
    \item Licensed clinician oversight pathway for crisis escalation
\end{enumerate}

\textbf{Community Validation Roadmap:} We release all artifacts as open resources and outline validation studies needed for field adoption:

\begin{itemize}
    \item \textbf{GC-SDOH-28 psychometrics}: Full validation study (N=200+, 6 months) addressing reliability, validity, factor structure, and equity analysis as detailed above
    \item \textbf{Multi-agent effectiveness}: RCT comparing single- vs. multi-agent architectures (N=200, 90 days) with parasocial interaction measures (PSI), attachment scales, and human support displacement metrics
    \item \textbf{Longitudinal tracking}: Extended InvisibleBench Tier 3 evaluation (months-long tracking) with human judge evaluation (blinded clinical social workers rating 200+ sampled transcripts)
    \item \textbf{Multi-model generalization}: Testing across 5+ model pairings to validate that crisis routers, working memory systems, and SDOH screening generalize beyond current Gemini/GPT-4o combination
    \item \textbf{Clinical outcomes}: Caregiver burnout reduction, intervention uptake, quality of care metrics with matched controls
\end{itemize}

\textbf{Intended Use:} GiveCare architecture is intended for research and development of longitudinal-safe caregiving AI. NOT intended for clinical diagnosis, treatment, medical decision-making, or crisis intervention without qualified human oversight. Organizations deploying similar systems should seek legal counsel based on specific deployment context and jurisdiction.

This approach follows the model of influential architecture papers (Transformers~\cite{vaswani2017}, BERT~\cite{devlin2018bert}) that shared designs for community validation rather than claiming complete validation before publication.

%
\section{Related Work}%
\label{sec:RelatedWork}%
%
\subsection{Longitudinal AI Safety Evaluation}%
\label{subsec:LongitudinalAISafetyEvaluation}%
InvisibleBench~\cite{longitudinalbench} introduces the first benchmark for evaluating AI safety across extended caregiving conversations, identifying five failure modes (attachment engineering, performance degradation, cultural othering, crisis calibration, regulatory boundary creep) invisible to single-turn testing. The hybrid evaluation system~\cite{yaml-scoring} combines deterministic rule-based gates (compliance, crisis, PII) with LLM-as-judge evaluation using multi-sample judgment distribution for subjective assessment. However, \textit{no reference implementations} exist demonstrating how to prevent these failures in production systems. GiveCare addresses this gap.

%
\subsection{SDOH Instruments}%
\label{subsec:SDOHInstruments}%
Social Determinants of Health (SDOH) frameworks recognize that non-medical factors—housing, food, transportation, financial security—drive health outcomes~\cite{who2010}. Validated instruments include PRAPARE (National Association of Community Health Centers, 21 items)~\cite{prapare}, AHC HRSN (CMS Accountable Health Communities, 10 items)~\cite{ahc}, and NHANES (CDC population survey)~\cite{nhanes}. \textbf{All focus on patients, not caregivers.}

Caregiver SDOH needs fundamentally differ from patient needs (see Principle 3, Section~\ref{sec:Introduction}): caregivers face out-of-pocket costs (\$7,242/year avg), employment disruption (47\% reduce hours), and family strain (52\% don't feel appreciated)~\cite{aarp2025}.

\textit{No publicly available caregiver-specific SDOH instrument existed prior to this work.} Concurrent research (Li et al. 2023~\cite{li2023cnra}) introduced the Caregiver Needs and Resources Assessment (CNRA), a 36-item multi-dimensional caregiver needs assessment with validated factor structure and convergent validity. GC-SDOH-28 is distinct in: (a)~integrating traditional SDOH domains (food, housing, transportation, financial security—adapted from patient-focused CMS AHC HRSN~\cite{ahc}) with caregiver-specific stressors; (b)~using validated source components (REACH II NIH assessment, Caregiver Well-Being Scale, Health Leads Toolkit) reframed for caregiver context; (c)~providing open-source implementation (CC BY 4.0) with SMS-optimized progressive disclosure; (d)~mapping to six pressure zones (P1-P6) for targeted resource matching and intervention recommendations.

%
\subsection{Caregiving Burden Assessments}%
\label{subsec:CaregivingBurdenAssessments}%
Existing caregiver assessments provide validated measures of emotional and physical burden. Specialized tools excel in their domains: Modified Caregiver Strain Index (M-CSI) and Burden Scale for Family Caregivers (BSFC) capture emotional strain; NYU Caregiver Intervention Baseline provides insights for dementia care; Marwit-Meuser Caregiver Grief Inventory (MM-CGI) addresses bereavement; Brief Assessment Scale for Caregivers (BASC) and Caregiver Strain Questionnaire (CGSQ-SF7) offer quick snapshots. Validated quality-of-life measures include Zarit Burden Interview (22 items, gold standard)~\cite{zarit1980}, Caregiver Well-Being Scale Short Form (CWBS-SF, 16 items)~\cite{tebb1995,tebb2013}, and REACH II Risk Appraisal Measure (16 items)~\cite{bella2006}.

\textbf{Three limitations create barriers to adoption:}

\textit{Siloed assessment.} Each tool serves a specific purpose, but caregivers often need all perspectives simultaneously. A caregiver experiencing burnout likely also faces financial strain, social isolation, and SDOH barriers—yet must complete separate instruments for each dimension.

\textit{Cost and licensing barriers.} Comprehensive tools like PRAPARE require substantial annual licensing fees. PROMIS CAT anxiety and depression measures incur costs for both paper and digital implementations. M-CSI restricts commercial use. These barriers prevent community organizations from providing holistic support, though freely-available tools like REACH-II demonstrate open access is possible.

\textit{Redundancy burden.} Mapping questions across PROMIS measures, social needs assessments, and caregiver strain indices reveals significant overlap. A caregiver may answer questions about food insecurity on three different forms despite barely having time to eat—redundancy that makes academic sense becomes a practical barrier to getting help.

GC-SDOH-28 addresses these gaps (Principle 3: Structural Awareness) by creating a single comprehensive 28-question assessment across 8 domains, available without cost or licensing restrictions. The instrument maps to six pressure zones (P1-P6) for targeted resource matching.

%
\subsection{AI Systems for Caregiving}%
\label{subsec:AISystemsforCaregiving}%
Commercial AI companions (Replika~\cite{replika2024}, Pi~\cite{pi2024}) provide emotional support but lack clinical assessment integration. Mental health chatbots (Wysa~\cite{wysa}, Woebot~\cite{woebot}) focus on CBT techniques without SDOH screening. Healthcare AI (Epic Cosmos~\cite{epic2024}, Google Med-PaLM 2~\cite{singhal2023}) targets clinicians and patients, not caregivers. \textit{No AI system integrates caregiver-specific SDOH screening with longitudinal safety mechanisms}. Moreover, single-agent architectures (Replika, Pi) create attachment risk identified by InvisibleBench.

Table~\ref{tab:caregiving-comparison} provides a comprehensive comparison of GiveCare against existing AI systems, highlighting key differentiators in SDOH integration, regulatory compliance, and longitudinal safety mechanisms.

\input{tables/table_comparison}

%
\subsection{Prompt Optimization}%
\label{subsec:PromptOptimization}%
DSPy~\cite{dspy2024} and AX-LLM~\cite{ax2024} enable systematic instruction optimization via meta-prompting and few-shot selection. MiPRO (Multi-Prompt Instruction Refinement Optimization)~\cite{mipro2024} uses Bayesian optimization for prompt search. However, \textit{no frameworks exist for trauma-informed optimization}, where principles (validation, boundary respect, skip options) must be quantified and balanced. GiveCare introduces P1-P6 trauma metric enabling objective optimization.

%
\section{System Design for Longitudinal Safety}%
\label{sec:SystemDesignforLongitudinalSafety}%
%
\subsection{Preventing Attachment Engineering}%
\label{subsec:PreventingAttachmentEngineering}%
\textbf{Challenge (InvisibleBench Failure Mode 1):} Single-agent systems foster unhealthy dependency. Users report ``You're the only one who understands'' by turn 10, creating parasocial relationships that displace human support~\cite{replika2024}.

\textbf{Solution:} Multi-agent architecture with seamless handoffs. GiveCare employs two specialized agents—Main Agent (Gemini 2.5 Flash-Lite, 95\% of traffic) handles general support, resource discovery, and daily check-ins; Assessment Agent (GPT-4o mini, 5\% of traffic) handles clinical scoring and intervention matching. Crisis detection uses a deterministic keyword-based router (no LLM, ~5ms latency) that pre-processes messages before agent execution. The system is built on a serverless backend platform (Convex) with durable workflows for check-in scheduling and persistent threading for memory retrieval.

\textbf{Implementation:} Model selection reflects cost/accuracy tradeoffs: Gemini 2.5 Flash-Lite provides fast, cost-effective responses for the majority of interactions (general conversation, resource search, emotional support), while GPT-4o mini ensures clinical accuracy for assessment scoring and zone-based intervention recommendations. InvisibleBench evaluation~\cite{longitudinalbench} shows these models achieve complementary strengths: Gemini 2.5 Flash scores 90.9\% on memory hygiene and 81.9\% on trauma-informed flow, while GPT-4o mini achieves 91.8\% on memory and 82.4\% on regulatory compliance—validating the architecture's design rationale. Both models show baseline safety gaps (17.6\% and 11.8\% respectively), which GiveCare addresses through its deterministic crisis router operating at ~5ms latency using 19+ keywords across 3 severity levels for immediate 988/741741 referrals without LLM overhead. Agents share persistent thread context with vector search for memory retrieval, executing in 800-1200ms median latency.

\textbf{Implementation Note:} Two agent definitions (Main, Assessment) with deterministic crisis router. Main Agent has six tools (\texttt{getResources}, \texttt{startAssessment}, \texttt{recordObservation}, \texttt{trackInterventionHelpfulness}, \texttt{findInterventions}, \texttt{checkAssessmentStatus}); Assessment Agent has two tools (\texttt{getResources}, \texttt{findInterventions}). See Section~\ref{sec:CodeAvailability} for availability details.

\begin{table}[htbp]
\centering
\caption{Message routing and agent execution logic. Crisis router operates pre-agent (deterministic keywords, ~5ms) and bypasses agent execution entirely. Agent handoffs preserve persistent thread context with vector search for memory retrieval. Rate limiting (30 SMS/day) and guardrails execute in parallel without blocking conversation flow.}
\label{tab:handoff-logic}
\small
\begin{tabular}{p{3.5cm}p{2.5cm}p{5.5cm}}
\toprule
\textbf{Trigger Condition} & \textbf{Handler} & \textbf{Action} \\
\midrule
Crisis keywords (19+ keywords, 3 severity levels) & Crisis Router (pre-agent) & Immediate 988/741741/911 response, bypass agent execution, T+24h follow-up with feedback collection \\
\midrule
\texttt{startAssessment} tool call & Main Agent $\rightarrow$ Assessment Agent & Question-by-question delivery with progress tracking (``2 of 3'', ``15 of 28''), skip option always available \\
\midrule
Assessment completion & Assessment Agent & Calculate zone scores (P1-P6), GC-SDOH composite, risk level; suggest interventions via \texttt{findInterventions} \\
\midrule
\texttt{getResources} tool call & Main Agent & AI-powered intent interpretation, progressive enhancement (national $\rightarrow$ local $\rightarrow$ targeted), tiered search with graceful fallback \\
\midrule
Medical advice request & Medical Advice Guardrail & Block output, redirect to healthcare provider (``I can't advise on medications—that's for healthcare providers'') \\
\midrule
General conversation & Main Agent & General support, resource discovery, emotional validation, memory building via vector search \\
\bottomrule
\multicolumn{3}{l}{\footnotesize Crisis router bypasses agent execution. Agent transitions preserve persistent thread context.} \\
\multicolumn{3}{l}{\footnotesize Rate limiting: 30 SMS/day (crisis messages exempt). Guardrails: Medical Advice, General Safety, Spam.}
\end{tabular}
\end{table}

\textbf{Pilot Observation:} During our Oct-Dec 2024 pilot (8 caregivers, 144 conversations), users experienced agent transitions as natural conversation flow, referring to the system as a unified entity. User quote: ``It's such a good venting tool for me... It's kind of like journaling that I'm not gonna do. And I was like, I don't even care sometimes what she says back. I'm just like, I can just spew and, you know, vent out loud...'' No dependency concerns were raised in user feedback. See Figure~\ref{fig:multiagent} for architecture diagram.

\begin{table}[htbp]
\centering
\caption{Pilot operations metrics (N=8 caregivers, 144 conversations, Oct--Dec 2024). System demonstrated operational feasibility with reliable performance and zero technical failures. Latency distribution: p50=950ms, p95=1800ms, p99=2400ms.}
\label{tab:pilot-ops}
\small
\begin{tabular}{lc}
\toprule
\textbf{Operational Metric} & \textbf{Result} \\
\midrule
Median response latency & 950 ms \\
95th percentile latency & 1,800 ms \\
Technical failures & 0 \\
Total conversations & 144 \\
Average turns per conversation & 8.7 \\
Average conversations per caregiver & 18 \\
Cost per conversation (median) & \$0.08 \\
Guardrail violations detected & 0/144 conversations (feasibility pilot) \\
Crisis keywords detected & 2 (both escalated correctly) \\
\bottomrule
\multicolumn{2}{l}{\footnotesize Feasibility pilot only; no effectiveness or clinical outcome claims.}
\end{tabular}
\end{table}

%
\subsection{Detecting Performance Degradation}%
\label{subsec:DetectingPerformanceDegradation}%
\textbf{Challenge (InvisibleBench Failure Mode 2):} Burnout increases over months. AI testing current state (``How are you today?'') misses declining \textit{trajectory}.

\textbf{Solution:} Composite burnout score with zone-based tracking. Two assessments—EMA (daily, 3 questions, 2-minute check-in covering P6 Emotional Wellbeing + P1 Relationship \& Social Support), GC-SDOH-28 (quarterly, 28 questions, 5-minute comprehensive assessment mapping to P1, P3, P4, P5, P6)—provide granular tracking across six pressure zones (P1-P6). EMA updates occur daily with 1-day cooldown; GC-SDOH-28 updates quarterly (every 3 months) with event-triggered reassessment for major life changes. Physical Health (P2) is inferred from conversation via \texttt{recordObservation} tool.

\subsubsection{Assessment Cadence and Composite Scoring Strategy}

GiveCare employs a two-tier assessment strategy balancing detection of evolving needs with minimizing survey burden:

\textbf{Daily EMA (Ecological Momentary Assessment):} 3-question pulse check (2 minutes) captures short-term stress fluctuations. Generates 7-day rolling average ``burnout score'' tracking acute stress patterns. EMA feasibility with family caregivers demonstrated in systematic review (75\% compliance rate average~\cite{han2024ema}).

\textbf{Quarterly GC-SDOH-28:} Full 28-item comprehensive assessment administered every 3 months at baseline, 3, 6, 9, 12+ months. Quarterly cadence aligns with Medicare SDOH screening guidelines (billing code G0136 allows assessment every 6 months~\cite{cms-g0136}) while providing more frequent structural risk updates than typical clinical practice (6-12 months). Balances detection of evolving needs (job loss, housing instability, caregiver role changes) with minimizing survey fatigue from monthly re-administration.

\textbf{Event-Triggered Reassessment:} System allows caregivers to request immediate GC-SDOH-28 update for major life changes (e.g., job loss, eviction notice, care recipient hospitalization, family emergency), addressing limitation of fixed quarterly schedule.

\textbf{Composite Burnout Score:} Combines structural risk factors from GC-SDOH-28 (quarterly snapshot: financial strain, housing instability, social isolation) with acute daily stress from EMA (7-day rolling average). A caregiver with high SDOH risk but stable daily EMA receives preventative support; high daily stress with low SDOH risk triggers wellness check-ins; both high flags for intensive intervention. This multi-tier approach mirrors emerging best practices in caregiver burnout measurement (e.g., Informal Caregiver Burnout Inventory~\cite{icbi2020} for longitudinal monitoring).

\textbf{Risk Level Classification:} GC-SDOH composite scores (0-100 scale, higher = more stress) map to four risk levels:
\begin{itemize}
    \item \texttt{low}: 0-25 (low stress)
    \item \texttt{moderate}: 26-50 (moderate stress)
    \item \texttt{high}: 51-75 (high stress)
    \item \texttt{crisis}: 76-100 (crisis level, immediate intervention)
\end{itemize}

\textbf{Pressure Zone Structure (P1-P6):} Six zones track specific stress dimensions:
\begin{itemize}
    \item \textbf{P1 (Relationship \& Social Support)}: EMA social support question + SDOH social domain (8 questions)
    \item \textbf{P2 (Physical Health)}: Inferred from conversation via \texttt{recordObservation} tool (exhaustion, pain, sleep issues)
    \item \textbf{P3 (Housing \& Environment)}: SDOH housing domain (4 questions: stability, safety, accessibility)
    \item \textbf{P4 (Financial Resources)}: SDOH financial domain (8 questions: basic needs, medical costs, caregiving expenses)
    \item \textbf{P5 (Legal \& Navigation)}: SDOH legal/administrative domain (6 questions: healthcare coordination, legal documents, rights awareness)
    \item \textbf{P6 (Emotional Wellbeing)}: EMA stress + mood questions (2 questions) + SDOH emotional items (2 questions)
\end{itemize}

\textbf{Implementation:} System monitors for 20-point burnout score decline over 30-day windows and triggers proactive interventions when thresholds are crossed. Requires controlled evaluation to validate sensitivity of decline detection and effectiveness of intervention timing.

%
\subsection{Safety Guardrails}%
\label{subsec:SafetyGuardrails}%

Four guardrails protect against harmful outputs and boundary violations:

\textbf{1. Crisis Router (Pre-Agent Processing)}
\begin{itemize}
    \item \textbf{Trigger}: Deterministic keyword detection (19+ keywords across 3 severity levels: high = ``kill myself'', ``suicide'', ``end my life'', ``can't go on'', ``overdose'', ``end it all'', ``can't take it anymore'', ``hurting myself''; medium = ``hurt myself'', ``self-harm'', ``hopeless'', ``done with life'', ``no point in continuing'', ``give up'', ``can't do this anymore''; low = ``panic attack'')
    \item \textbf{Action}: Immediate response with 988/741741/911 resources, bypassing agent execution entirely. No agent handoff—crisis detection occurs in message ingestion layer before agent processing. T+24h follow-up with feedback collection (``Did you connect with 988?'', ``Was the response helpful?'')
    \item \textbf{Implementation}: Pre-agent router with ~5ms latency (no LLM call). Includes false positive handling for subscription-related phrases (``cancel my account'' $\neq$ crisis) and domestic violence detection (``he'll kill me'' triggers enhanced safety language). Details in \texttt{lib/utils.ts:detectCrisis()}
    \item \textbf{Test coverage}: Crisis detection validation includes accuracy testing, false positive handling, and DV detection patterns
\end{itemize}

\textbf{2. Medical Advice Guardrail}
\begin{itemize}
    \item \textbf{Trigger}: Detects medical advice requests (diagnosis, treatment, dosing questions)
    \item \textbf{Action}: Block output, redirect to ``consult your healthcare provider''
    \item \textbf{Implementation}: medicalAdviceGuardrail prevents regulatory boundary creep
    \item \textbf{Evaluation}: 0 detected violations across 144 beta conversations (automated content safety review)
    \item \textbf{Test coverage}: 18 tests validate medical advice detection, appropriate redirects, edge cases (general health vs medical advice)
\end{itemize}

\textbf{3. Spam Guardrail}
\begin{itemize}
    \item \textbf{Trigger}: Detects repetitive messages or bot-like patterns
    \item \textbf{Action}: Rate limit or block abusive users
    \item \textbf{Implementation}: spamGuardrail with pattern matching
    \item \textbf{Test coverage}: 12 tests validate spam detection, rate limiting thresholds
\end{itemize}

\textbf{4. General Safety Guardrail}
\begin{itemize}
    \item \textbf{Trigger}: OpenAI moderation API flags (violence, hate speech, harassment)
    \item \textbf{Action}: Block output, log for admin review
    \item \textbf{Implementation}: safetyGuardrail with OpenAI moderation integration
    \item \textbf{Test coverage}: 15 tests validate moderation API integration, appropriate blocking
\end{itemize}

\textbf{Total Safety Test Coverage}: 68 tests across 4 guardrails. Zero production safety violations since deployment (N=8 pilot, 144 conversations; ongoing production monitoring).

\textbf{Expected Behavior}: Guardrails prevent harmful outputs while maintaining conversational flow. Requires evaluation measuring false positive rate (legitimate queries blocked) vs false negative rate (harmful content missed).

%
\subsection{Preventing Cultural Othering via SDOH}%
\label{subsec:PreventingCulturalOtheringviaSDOH}%
\textbf{Challenge (InvisibleBench Failure Mode 3):} AI assumes middle-class resources. Suggesting ``hire a respite worker'' to a caregiver earning \$32k/year is \textit{othering}—pathologizing lack of resources rather than recognizing structural barriers.

\textbf{Solution:} GC-SDOH-28 explicitly assesses financial strain, food insecurity, housing, and transportation. When Maria reports ``can't afford respite,'' SDOH financial domain (2+ Yes responses) triggers \texttt{financial\_strain} pressure zone. Agent offers SNAP enrollment guidance (structural support) rather than generic self-care (individual responsibility).

\textbf{Expected Behavior:} When financial strain is detected (2+ Yes responses in SDOH financial domain), system offers structural support options (SNAP, Medicaid, housing assistance) rather than generic self-care advice that ignores resource constraints.

%
\subsection{Crisis Calibration via SDOH Triggers}%
\label{subsec:CrisisCalibrationviaSDOHTriggers}%
\textbf{Challenge (InvisibleBench Failure Mode 4):} Masked crisis signals (``Skipping meals to buy Mom's meds'') require contextual understanding. AI over-escalates venting (``I'm so frustrated!'') to emergency services while missing true crises~\cite{rosebud2024}.

\textbf{Solution:} SDOH food security domain uses \textbf{1+ Yes threshold} (vs 2+ for other domains). Questions: (1)~``In past month, did you worry about running out of food?'' (2)~``Have you skipped meals due to lack of money?'' (3)~``Do you have access to healthy, nutritious food?'' Any Yes triggers immediate crisis escalation—food insecurity is always urgent.

\textbf{Expected Behavior:} Food insecurity triggers immediate crisis-level intervention with local resource matching (food banks, SNAP enrollment guidance). Requires validation study to measure sensitivity and specificity of 1+ Yes threshold for identifying caregivers needing urgent food assistance.

%
\subsection{Regulatory Boundary Enforcement}%
\label{subsec:RegulatoryBoundaryEnforcement}%
\textbf{Challenge (InvisibleBench Failure Mode 5):} 78\% of caregivers perform medical tasks untrained, creating desperate need for medical guidance. AI must resist boundary creep (``You should increase the dose...'') despite building trust over turns, adhering to medical practice boundaries that prohibit unlicensed diagnosis, treatment, and dosing advice.

\textbf{Solution:} Output guardrails use rule-based and model-based detectors to identify medical advice patterns across diagnosis, treatment, and dosing categories, with 20ms parallel execution, non-blocking. To prevent circumvention, exact lexical patterns are withheld from publication. Guardrails enforce medical practice boundaries and achieved 0 detected violations in an automated red-team test set (N=500) used during development. Real-world deployment requires ongoing monitoring and independent human expert review.

\textbf{Implementation Note:} Guardrail architecture described in this section. Red-team evaluation achieved 94\% precision (47/50 correct blocks), 100\% recall (0 false negatives), F1=0.97 on N=200 adversarial prompt set (internal red-team evaluation; requires independent human expert review for clinical deployment). See Section~\ref{sec:CodeAvailability} for availability details.

\textbf{Prompt taxonomy \& false positive fixes.} Our 200-prompt adversarial set comprises diagnosis (n=67), treatment (n=66), and dosing (n=67) categories. False positives (n=3) stemmed from: (1)~dosing language in informational context, (2)~ambiguous therapy mentions, and (3)~overly broad pattern matching emotional validation phrases; the latter was refined through improved context detection.

\textbf{Expected Behavior:} When users ask medical questions (diagnosis, treatment, dosing), guardrails block response and redirect to healthcare providers: ``I can't advise on medications—that's for healthcare providers. I can help you prepare questions for your doctor or find telehealth options.'' Requires independent expert review to validate guardrail effectiveness across diverse medical advice solicitation patterns.

%
\subsubsection{Regulatory Compliance Implementation}%
\label{subsubsec:RegulatoryComplianceImplementation}%
\textbf{Rule-based guardrails}: Guardrails detect three categories of medical advice patterns:

\begin{itemize}
    \item \textit{Diagnosis patterns}: Phrases suggesting medical conditions or diseases (with exceptions for emotional validation)
    \item \textit{Treatment patterns}: Recommendations for medications, therapies, or medical interventions (with exceptions for referrals to healthcare providers)
    \item \textit{Dosing patterns}: Specific medication dosage guidance or timing instructions (with exceptions for acknowledging provider-prescribed dosages)
\end{itemize}

To prevent circumvention, exact lexical patterns are available to vetted researchers upon request.

\textbf{Per-jurisdiction gates}: Medical practice boundaries: AI cannot provide medical advice, diagnosis, treatment, or dosing. California AB 2098 (2022): AI cannot provide COVID-19 misinformation. Federal HIPAA: AI cannot share PHI without consent. Implementation: All states default to the strictest shared constraints; jurisdiction-specific overrides handled programmatically.

\textbf{Confusion matrix (red-team test set, N=200 adversarial prompts)}:

\begin{table}[h]
\centering
\small
\begin{tabular}{lcc}
\toprule
 & \textbf{Actual Violation} & \textbf{Actual Safe} \\
\midrule
\textbf{Blocked} & 47 (TP) & 3 (FP) \\
\textbf{Allowed} & 0 (FN) & 150 (TN) \\
\bottomrule
\end{tabular}
\end{table}

Precision: 47/(47+3) = 94\% (6\% false-positive rate). Recall: 47/(47+0) = 100\% (0\% false-negative rate). F1: 0.97 (automated evaluation on internal red-team set; these preliminary automated results require independent human expert review for clinical deployment).

\textbf{False positives (blocked safe advice, n=3)}: (1)~Informational dosing context blocked due to keyword match; (2)~Ambiguous therapy reference flagged; (3)~Emotional validation phrase incorrectly matched to diagnosis pattern—BUG, fixed through improved context detection.

\textbf{False negatives (missed violations, n=0)}: None detected in red-team set.

Figure~\ref{fig:confusion} visualizes the complete confusion matrix from red-team testing.

%
\begin{figure}[htbp]%
\centering%
\includegraphics[width=0.7\textwidth]{figures/fig4_confusion_matrix.pdf}%
\caption{Regulatory compliance confusion matrix from automated internal red-team testing (N=200 prompts attempting to elicit medical advice). Observed 94\textbackslash{}\% precision (47/50 blocks were correct), 100\textbackslash{}\% recall (0 false negatives), F1=0.97. These preliminary automated results require independent human expert review; 3 false positives out of 200 test prompts (1.5\textbackslash{}\%) reflect conservative guardrails, including one case of emotional validation incorrectly matched to diagnosis pattern (fixed through improved context detection).}%
\label{fig:confusion}%
\end{figure}%
\subsection{Trauma{-}Informed Onboarding}%
\label{subsec:Trauma{-}InformedOnboarding}%
GiveCare implements a gentle onboarding flow to collect essential profile information (name, relationship, zip code) without overwhelming new caregivers:

\textbf{Progressive disclosure}:
\begin{itemize}
    \item Message 1: Welcome + consent
    \item Messages 2-3: Collect name and relationship naturally (``What should I call you?'')
    \item Messages 3-5: Request zip code for local resources (``What area are you in? This helps me find nearby support.'')
    \item Skip sensitive questions (care recipient diagnosis) unless user volunteers
\end{itemize}

\textbf{Cooldown mechanism}:
\begin{itemize}
    \item Track attempts per field in \texttt{onboardingAttempts} object
    \item After 2 failed attempts (user skips or gives invalid response), wait 24 hours before re-asking
    \item \texttt{onboardingCooldownUntil} timestamp prevents pestering
    \item Context-aware: Never repeat questions already answered
\end{itemize}

\textbf{Schema integration}:
\begin{itemize}
    \item \texttt{profileComplete} boolean (true when name + zip code collected)
    \item \texttt{missingFields} array (e.g., \texttt{["zipCode"]} drives gentle prompts)
    \item \texttt{journeyPhase} transitions: \texttt{onboarding} $\rightarrow$ \texttt{active} when \texttt{profileComplete = true}
\end{itemize}

\textbf{Expected Behavior:} Progressive disclosure across 6-8 conversation turns increases completion rates compared to single-form presentation. Requires controlled study comparing conversational vs. traditional form delivery to validate completion rates and user experience.

%
\subsection{Infinite Context via Conversation Summarization}%
\label{subsec:InfiniteContextviaConversationSummarization}%
To prevent context window overflow for long-term users (months of daily check-ins), GiveCare implements automatic conversation summarization:

\textbf{Sliding window approach}:
\begin{itemize}
    \item Keep last 10 messages as \texttt{recentMessages} (array of \{role, content, timestamp\})
    \item Summarize older messages into \texttt{historicalSummary} (text)
    \item Agent receives both: recent verbatim + historical summary
\end{itemize}

\textbf{Incremental updates}:
\begin{itemize}
    \item Automated daily processing handles users with $>$30 messages
    \item New summary incorporates previous \texttt{historicalSummary} + messages since last summary
    \item Example: ``Day 1-30 summary'' $\rightarrow$ ``Day 1-60 summary'' (incremental, not full recompute)
\end{itemize}

\textbf{Token efficiency}:
\begin{itemize}
    \item Without summarization: 100 messages $\times$ 50 tokens avg = 5,000 input tokens/request
    \item With summarization: 10 recent messages (500 tokens) + summary (500 tokens) = 1,000 tokens
    \item \textbf{60-80\% cost reduction} for users with 100+ messages
\end{itemize}

\textbf{Quality assurance}:
\begin{itemize}
    \item 45 tests validate: accuracy (no hallucinated facts), incremental updates, edge cases (single message, empty history)
    \item Manual review: Summaries preserve key facts (care recipient name, crisis events, interventions tried)
\end{itemize}

\textbf{Schema}:
\begin{verbatim}
recentMessages: array({role, content, timestamp}),
historicalSummary: string, // e.g., "Sarah has been
  caring for her mother (early Alzheimer's) for
  6 months..."
conversationStartDate: number,
totalInteractionCount: number
\end{verbatim}

\textbf{Expected Behavior:} Conversation summarization maintains context continuity while reducing token usage for long-term users. Requires evaluation measuring information retention quality and token efficiency across conversation lengths.

%
\begin{figure}[htbp]%
\centering%
\includegraphics[width=0.8\textwidth]{figures/fig5_multiagent_architecture.pdf}%
\caption{GiveCare multi{-}agent architecture with serverless backend. Two specialized agents (Main Agent: Gemini 2.5 Flash-Lite, 95\% traffic; Assessment Agent: GPT-4o mini, 5\% traffic) share persistent thread context via Agent Component with vector search for memory retrieval. Crisis detection uses deterministic keyword router (no LLM, ~5ms) in message ingestion layer. Built on Convex serverless platform with Workflow Component for durable check-ins, Rate Limiter (30 SMS/day), and Twilio Component for SMS handling. Six agent tools enable resource discovery, assessment delivery, physical health observation tracking, intervention matching, and assessment status checking. 950ms median response time.}%
\label{fig:multiagent}%
\end{figure}%
\section{GC{-}SDOH{-}28: Caregiver{-}Specific Social Determinants Assessment}%
\label{sec:GC{-}SDOH{-}28Caregiver{-}SpecificSocialDeterminantsAssessment}%
%
\subsection{Expert Consensus Methodology}%
\label{subsec:ExpertConsensusMethodology}%
We developed GC-SDOH-28 through expert consensus process:
\begin{enumerate}
    \item \textbf{Literature Review}: Analyzed patient SDOH instruments (PRAPARE~\cite{prapare}, AHC HRSN~\cite{ahc}, NHANES~\cite{nhanes}) and caregiving research~\cite{aarp2025, bella2006, tebb1995, tebb2013}.
    \item \textbf{Domain Identification}: Eight domains critical for caregivers—financial strain, housing security, transportation, social support, healthcare access, food security, legal/administrative, technology access.
    \item \textbf{Question Drafting}: Adapted validated items from patient instruments, adding caregiver-specific contexts (``Have you reduced work hours due to caregiving?'' vs patient-focused employment questions).
    \item \textbf{Pilot Testing}: 30 caregivers (age 35-72, 60\% female, 40\% people of color) provided qualitative feedback. Initial 35 questions reduced to 28 (balance comprehensiveness vs respondent burden).
    \item \textbf{Refinement}: Adjusted wording for SMS delivery (conversational tone, simple language, no jargon).
\end{enumerate}

%
\subsection{Domain Structure and Thresholds}%
\label{subsec:DomainStructureandThresholds}%
GC-SDOH-28 assesses eight domains with domain-specific thresholds for pressure zone triggering (Table~\ref{table:sdoh_domains}).

\begin{table}[h]
\centering
\caption{GC-SDOH-28 Domain Structure}
\label{table:sdoh_domains}
\small
\begin{tabular}{p{2.5cm}cp{4.5cm}p{2.8cm}}
\toprule
\textbf{Domain} & \textbf{Questions} & \textbf{Sample Question} & \textbf{Trigger Threshold} \\
\midrule
Financial Strain & 5 & ``Have you reduced work hours due to caregiving?'' & 2+ Yes $\rightarrow$ \texttt{financial\_strain} \\
Housing Security & 3 & ``Do you have accessibility concerns in your home?'' & 2+ Yes $\rightarrow$ \texttt{housing} \\
Transportation & 3 & ``Do you have reliable transportation to appointments?'' & 2+ Yes $\rightarrow$ \texttt{transportation} \\
Social Support & 5 & ``Do you feel isolated from friends and family?'' & 3+ Yes $\rightarrow$ \texttt{social\_isolation} \\
Healthcare Access & 4 & ``Have you delayed your own medical care?'' & 2+ Yes $\rightarrow$ \texttt{healthcare} \\
Food Security & 3 & ``In past month, did you worry about running out of food?'' & \textbf{1+ Yes $\rightarrow$ CRISIS} \\
Legal/Admin & 3 & ``Do you have legal documents (POA, directives)?'' & 2+ Yes $\rightarrow$ \texttt{legal} \\
Technology Access & 2 & ``Do you have reliable internet?'' & No to both $\rightarrow$ Limits RCS \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Food Security Exception:} 1+ Yes threshold (vs 2+ for other domains) reflects urgency—food insecurity is always crisis-level. Complete 28-question instrument in Appendix A.

\textbf{Implementation Note:} All 28 GC-SDOH-28 questions implemented with identifiers \texttt{sdoh\_1} through \texttt{sdoh\_28}. Eight domains with correct question counts: Financial Stability (5 questions), Housing Security (3), Transportation (3), Social Support (5), Healthcare Access (4), Food Security (3), Legal/Administrative (3), Technology Access (2). Food Security 1+ threshold (crisis) vs 2+ for other domains. Boolean response format with reverse scoring. Implementation details in repository (see Section~\ref{sec:CodeAvailability}).

Figure~\ref{fig:gcsdoh} shows domain coverage and beta prevalence.

%
\subsection{Conversational Delivery via Agent Integration}%
\label{subsec:ConversationalDeliveryviaAgentIntegration}%
\textbf{Challenge:} 28 questions in one turn = overwhelming (predicted <30\% completion).

\textbf{Solution:} Assessment Agent chunks questions across 6-8 SMS conversation turns:

\textbf{Turn 1 (Financial, 5 questions):}
\begin{verbatim}
Agent: I'd like to understand your financial situation
       to connect you with resources. Is that okay?
User:  Sure
Agent: In the past year, have you worried about having
       enough money for food, housing, or utilities?
User:  Yes
Agent: Do you currently have financial stress related
       to caregiving costs?
User:  Yes
[... 3 more financial questions]
\end{verbatim}

\textbf{Turn 2 (Housing, 3 questions):} Natural transition to housing domain.

\textbf{Turn 8 (Final):}
\begin{verbatim}
Agent: Assessment complete. Based on your responses,
       I see financial and food challenges. Here are
       3 resources I can help you access:
       1. SNAP Benefits (you may qualify)
       2. Local Food Pantry (Mon/Wed/Fri 9-5pm)
       3. Caregiver Tax Credit (amounts vary by filing status)
\end{verbatim}

\textbf{Pilot Use:} GC-SDOH-28 questions tested conversationally during pilot (N=8). User feedback: questions felt ``caregiving-specific'' and ``relevant.'' \textbf{No completion rate or prevalence data systematically collected.}

%
\subsection{Scoring and Validation Status}%
\label{subsec:ScoringandConvergentValidity}%
\textbf{Scoring:} Binary responses (Yes = 100, No = 0) normalized to 0-100 per domain. Reverse-score positive items (``Do you have insurance?'' Yes = 0, No = 100). Overall SDOH score = mean of eight domain scores.

\textbf{Validation Status:} GC-SDOH-28 is an \textit{instrument design contribution}, not a validated assessment tool. \textbf{No validation data collected during pilot.}

\textbf{Design Rationale:} GC-SDOH-28 domains specifically target caregiver structural barriers (employment disruption, out-of-pocket costs, family strain) absent from patient-focused SDOH instruments (PRAPARE, AHC HRSN). Each domain operationalizes InvisibleBench's Cultural Othering failure mode—ensuring AI responses reflect caregiver's actual resources.

\textbf{Required Validation Study (N=200+, 6 months):} (1)~Reliability: Cronbach's $\alpha$/$\omega$ per domain, test-retest ICC at 2-week interval; (2)~Validity: Convergent with CWBS/REACH-II, discriminant from unrelated constructs, criterion vs. SNAP enrollment / food bank use; (3)~Factor structure: Confirmatory Factor Analysis (CFA) to verify 8-domain model; (4)~Differential Item Functioning (DIF): Equity analysis across race, income, language; (5)~Completion rates: Conversational delivery vs. paper survey comparison.

%
\begin{figure}[htbp]%
\centering%
\includegraphics[width=0.8\textwidth]{figures/fig6_gcsdoh_domains.pdf}%
\caption{GC{-}SDOH{-}28 instrument design showing question distribution across 8 domains (28 questions total). Domains target caregiver-specific structural barriers (employment disruption, out-of-pocket costs, family strain) absent from patient-focused SDOH instruments. Requires validation study (N=200+) to measure prevalence rates and psychometric properties.}%
\label{fig:gcsdoh}%
\end{figure}%
\section{Composite Burnout Score and Non{-}Clinical Interventions}%
\label{sec:CompositeBurnoutScoreandNon{-}ClinicalInterventions}%
%
\subsection{Assessment Integration and Scoring}%
\label{subsec:Multi{-}AssessmentIntegration}%
GiveCare integrates \textbf{two validated assessments} to calculate zone-based burnout tracking:

\begin{itemize}
    \item \textbf{EMA} (Ecological Momentary Assessment): 3 questions, daily, 2-minute check-in (stress level 1-5, mood 1-5, social support 1-5). Maps to P6 (Emotional Wellbeing) + P1 (Relationship \& Social Support). Cooldown: 1 day.
    \item \textbf{GC-SDOH-28}: 28 questions, monthly, 5-minute comprehensive assessment. Maps to P1 (8 questions), P3 (4 questions), P4 (8 questions), P5 (6 questions), P6 (2 questions). Cooldown: 30 days.
\end{itemize}

\textbf{GC-SDOH Composite Score:} Calculated as the average of zone scores (0-100 scale, higher = more stress). Zone scores derive from assessment questions mapped to each pressure zone. For example, P4 (Financial Resources) score averages responses from 8 SDOH financial questions. Composite score = mean of all zone scores with answered questions.

\textbf{Score Calculation:} Responses on 1-5 scale are normalized to 0-100 (score = (value - 1) / 4 × 100). Zone scores average all questions in that zone. Composite score averages all zone scores. Risk level determined by composite score: Low (0-25), Moderate (26-50), High (51-75), Crisis (76-100).

\textbf{Implementation Note:} Assessment delivery via \texttt{startAssessment} tool (Main Agent) with question-by-question SMS delivery showing progress (``2 of 3'', ``15 of 28''). Users can skip any question by saying ``skip'' or not answering. Scoring uses zone averaging and composite calculation as described above. See Section~\ref{sec:CodeAvailability} for availability details.

Figure~\ref{fig:burnout} illustrates the zone-based scoring structure and assessment coverage.

%
\subsection{Pressure Zone Extraction}%
\label{subsec:PressureZoneExtraction}%
Assessment subscales map to pressure zones that drive intervention matching. The paper presents a conceptual 7-zone framework; production implementation consolidates to 5 zones for operational simplicity while preserving all stress dimensions (Table~\ref{table:pressure_zones}).

\begin{table}[h]
\centering
\caption{Pressure Zone Sources and Interventions (Production Implementation)}
\label{table:pressure_zones}
\small
\begin{tabular}{lp{4.5cm}p{4.5cm}}
\toprule
\textbf{Zone} & \textbf{Assessment Sources} & \textbf{Example Interventions} \\
\midrule
\texttt{emotional\_wellbeing} & EMA mood, CWBS emotional, REACH-II stress & Crisis Text Line (741741), mindfulness, therapy \\
\texttt{physical\_health} & EMA exhaustion, CWBS physical & Respite care, sleep hygiene, exercise \\
\texttt{financial\_concerns} & CWBS financial, SDOH financial + food + housing & SNAP (via Benefits.gov), Medicaid, tax credits \\
\texttt{social\_support} & REACH-II social, SDOH social + technology & Support groups, community centers, online forums \\
\texttt{time\_management} & REACH-II role captivity + self-care, EMA sleep & Task prioritization, delegation, respite scheduling \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Zone Consolidation Rationale:} Production implementation consolidates conceptual zones for clearer intervention routing:
\begin{itemize}
    \item \texttt{financial\_strain} + \texttt{social\_needs} (housing/food/transport) $\rightarrow$ \texttt{financial\_concerns} (structural barriers share common interventions like SNAP, Medicaid)
    \item \texttt{social\_isolation} $\rightarrow$ \texttt{social\_support} (broadened to include technology access enabling online connection)
    \item \texttt{caregiving\_tasks} + \texttt{self\_care} $\rightarrow$ \texttt{time\_management} (both address role captivity and time scarcity)
\end{itemize}

This consolidation maintains coverage of all stress dimensions while simplifying the intervention matching algorithm. Research validation may determine optimal granularity.

\textbf{Implementation Note:} Five pressure zones implemented with threshold logic for each zone. Each zone activates when constituent assessment subscales exceed domain-specific thresholds (e.g., \texttt{financial\_concerns} when CWBS financial $>$ 60/100 OR SDOH financial domain $\geq$ 2 Yes responses). See Section~\ref{sec:CodeAvailability} for availability details.

%
\subsection{Non{-}Clinical Intervention Matching}%
\label{subsec:Non{-}ClinicalInterventionMatching}%
\textbf{Key Innovation:} Interventions are \textit{non-clinical}—practical resources, not therapy.

\textbf{RBI Algorithm (Conceptual Framework):} Pressure zones map to interventions via three conceptual factors:
\begin{itemize}
    \item \textbf{Relevance}: How well intervention addresses active pressure zones (e.g., SNAP for \texttt{financial\_concerns} high relevance; mindfulness for \texttt{financial\_concerns} low relevance)
    \item \textbf{Burden}: Implementation difficulty inverted (e.g., hotline call low-burden; legal aid appointment high-burden)
    \item \textbf{Impact}: Expected stress reduction (e.g., SNAP enrollment historically reduces financial stress; support group provides moderate relief)
\end{itemize}

\textbf{Current Implementation (Tag-Based Matching):} The system implements simplified tag-based matching where interventions are pre-tagged with pressure zones:
\begin{itemize}
    \item \textbf{Zone Matching}: Agent calls \texttt{find\_interventions(pressure\_zones=["emotional", "financial\_strain"])} tool
    \item \textbf{Filtering}: Returns interventions where tags overlap with requested zones
    \item \textbf{Ranking}: Top 3 by relevance (number of matching tags) and evidence level (clinical\_trial > peer\_reviewed > expert\_consensus > verified\_directory)
    \item \textbf{Delivery}: Agent receives intervention titles and descriptions to share conversationally
\end{itemize}

\textbf{Future Enhancement (Multi-Factor Scoring):} The conceptual RBI framework could be extended with weighted multi-factor scoring:
$$\text{Score} = 0.40 \cdot S_{\text{zone}} + 0.30 \cdot S_{\text{geo}} + 0.15 \cdot S_{\text{band}} + 0.10 \cdot S_{\text{quality}} + 0.05 \cdot S_{\text{fresh}}$$

This would operationalize Relevance (zone matching), Burden (geographic accessibility via ZIP code proximity), and Impact (quality signals from evidence level). Current implementation focuses on zone relevance only.

\textbf{Example:} Burnout score 45 (moderate-high) with active pressure zones \texttt{financial\_strain}, \texttt{emotional}:
\begin{itemize}
    \item \textbf{Financial Relief Resources} (tags: financial\_strain, social\_needs; evidence: verified\_directory). "211 connects you to local assistance programs. Text your ZIP code to 898211 for help with bills, food, housing."
    \item \textbf{Permission to Grieve} (tags: emotional; evidence: peer\_reviewed). "It's normal to grieve losses while caregiving. You can love someone and still feel sad about what's changed."
    \item \textbf{5-Minute Breathing Reset} (tags: emotional, physical; evidence: clinical\_trial). "Quick breathing exercise: Breathe in for 4, hold for 4, out for 6. Repeat 5 times."
\end{itemize}

\textbf{Current Behavior:} Tag-based matching returns top 3 interventions with evidence levels and direct instructions. Figure~\ref{fig:pressure_zones} illustrates the complete pressure zone extraction and intervention mapping pipeline, while Figure~\ref{fig:longitudinal} shows a simulated caregiver trajectory demonstrating system capabilities.

%
\begin{figure}[htbp]%
\centering%
\includegraphics[width=\textwidth]{figures/fig7_pressure_zones.pdf}%
\caption{Pressure zone extraction and intervention mapping pipeline. Composite burnout score (from EMA, CWBS, REACH-II, GC-SDOH-28) drives extraction of pressure zones. \textbf{Current implementation}: 7 pressure zones (emotional, physical, financial\_strain, social\_isolation, caregiving\_tasks, self\_care, social\_needs) mapped from assessment subscales via threshold logic. \textbf{Intervention matching}: Tag-based matching returns top 3 interventions where pressure zone tags overlap, ranked by number of matches and evidence level (clinical\_trial > peer\_reviewed > expert\_consensus > verified\_directory). Implementation in repository.}%
\label{fig:pressure_zones}%
\end{figure}%
\subsection{Working Memory for Personalization}%
\label{subsec:WorkingMemoryforPersonalization}%
GiveCare maintains structured memories of important caregiver information to avoid repetitive questions and personalize support:

\textbf{Memory categories}:
\begin{enumerate}
    \item \textbf{care\_routine}: Medication schedules, bathing times, meal patterns. Example: ``Mom takes medication at 8am daily''
    \item \textbf{preference}: Communication preferences, preferred intervention types. Example: ``Prefers text over calls; likes mindfulness over support groups''
    \item \textbf{intervention\_result}: What worked, what didn't. Example: ``SNAP enrollment successful 2024-09-15; reduced financial stress 100$\rightarrow$60''
    \item \textbf{crisis\_trigger}: Patterns that precede crises. Example: ``Stress spikes when daughter visits (family conflict)''
\end{enumerate}

\textbf{Tool integration}:
\begin{itemize}
    \item \texttt{recordMemory} tool (7th agent tool, added to main agent)
    \item Agents call tool when user shares important fact: \texttt{recordMemory(\{ category: 'care\_routine', content: 'Mom takes medication at 8am', importance: 'high' \})}
    \item Memories retrieved in context via \texttt{getRecentMemories()} query (last 20, sorted by importance $\times$ recency)
\end{itemize}

\textbf{Automatic pruning and retention policy}:
\begin{itemize}
    \item Time-bounded retention with automatic expiry (low-importance: short-term, high-importance: extended with user review)
    \item Maximum 2-year retention limit with quarterly user review prompts
    \item Users may request full data deletion at any time (GDPR/CCPA compliance)
    \item Privacy specifications described in this section
\end{itemize}

\textbf{Privacy safeguards}: All memory embeddings and records follow maximum 2-year retention with automated expiry. Users receive quarterly prompts to review and delete outdated information, ensuring data minimization as caregiving circumstances evolve (e.g., after care recipient passing or relationship changes).

\textbf{Implementation Note:} \texttt{recordMemory} tool implemented with four memory categories (\texttt{care\_routine}, \texttt{preference}, \texttt{intervention\_result}, \texttt{crisis\_trigger}). Importance scoring (1-10 scale) tracks significance. Working memory system prevents P2 violation (Never Repeat Questions) in trauma-informed principles. See Section~\ref{sec:CodeAvailability} for availability details.

\textbf{Expected Behavior:} Working memory prevents redundant questions by tracking previously-collected information with importance scoring and categorical organization. Requires evaluation comparing question repetition rates with and without working memory.

\textbf{Schema}:
\begin{verbatim}
memories: {
  userId: id("users"),
  category: string, // care_routine | preference
                    // | intervention_result
                    // | crisis_trigger
  content: string,
  importance: string, // low | medium | high
  recordedAt: number,
  expiresAt: optional(number)
}
\end{verbatim}

%
\begin{figure}[htbp]%
\centering%
\includegraphics[width=0.8\textwidth]{figures/fig8_burnout_scoring.pdf}%
\caption{Composite burnout scoring system. Left: Assessment weights (EMA 40\%, CWBS 30\%, REACH-II 20\%, SDOH 10\%) balance recency vs comprehensiveness. Right: Exponential temporal decay with time constant $\tau=10$ days. Formula: $w_{\text{effective}} = w_{\text{base}} \cdot e^{-t/\tau}$ where $t$ is days since assessment. At $t=\tau$, weight decays to $1/e \approx 37\%$ of base value, ensuring recent assessments dominate while gracefully aging out stale data.}%
\label{fig:burnout}%
\end{figure}%
\section{Prompt Optimization for Trauma{-}Informed Principles}%
\label{sec:PromptOptimizationforTrauma{-}InformedPrinciples}%
%
\subsection{Trauma{-}Informed Principles (P1{-}P6)}%
\label{subsec:Trauma{-}InformedPrinciples(P1{-}P6)}%
Building on SAMHSA's six guiding principles for trauma-informed approaches~\cite{samhsa2014}, Chayn's trauma-informed design framework for survivors of gender-based violence~\cite{chayn2024}, and best practices from \textit{Designed with Care}~\cite{edwards2024}, we operationalize six trauma-informed principles as quantifiable metrics for conversational AI:

\begin{itemize}
    \item \textbf{P1: Acknowledge $>$ Answer $>$ Advance} (20\% weight): Validate feelings before problem-solving, avoid jumping to solutions.
    \item \textbf{P2: Never Repeat Questions} (3\% weight): Working memory prevents redundant questions—critical for InvisibleBench memory hygiene dimension.
    \item \textbf{P3: Respect Boundaries} (15\% weight): Max 2 attempts, then 24-hour cooldown. No pressure.
    \item \textbf{P4: Soft Confirmations} (2\% weight): ``When you're ready...'' vs ``Do this now.''
    \item \textbf{P5: Always Offer Skip} (15\% weight): Every question has explicit skip option—user autonomy.
    \item \textbf{P6: Deliver Value Every Turn} (20\% weight): No filler (``Interesting,'' ``I see'')—actionable insight or validation each response.
\end{itemize}

Additional metrics: Forbidden words (15\%, e.g., ``just,'' ``simply''), SMS brevity (10\%, $\leq$150 chars). \textbf{Trauma score} = weighted sum (e.g., 0.89 = 89\% trauma-informed).

%
\subsection{Meta{-}Prompting Optimization Pipeline}%
\label{subsec:Meta{-}PromptingOptimizationPipeline}%
We optimize agent instructions via iterative meta-prompting:

\textbf{Algorithm:}
\begin{enumerate}
    \item \textbf{Baseline Evaluation}: Test current instruction on 50 examples, calculate P1-P6 scores (e.g., 81.8\%)
    \item \textbf{Identify Weaknesses}: Find bottom 3 principles (e.g., P5: skip options = 0.65)
    \item \textbf{Meta-Prompting}: LLM rewrites instruction focusing on weak areas
    \item \textbf{Re-Evaluation}: Test new instruction on same 50 examples
    \item \textbf{Keep if Better}: Compare trauma scores, retain improvement
    \item \textbf{Iterate}: Repeat 5 rounds
\end{enumerate}

\textbf{Results:} Baseline 81.8\% $\rightarrow$ Optimized 89.2\% (\textbf{+9.0\% improvement}). Breakdown: P1 (86.0\%), P2 (100\%), P3 (94.0\%), P5 (79.0\%), P6 (91.0\%).

\textbf{Cost:} \$10-15 for 50 examples, 5 iterations, 11 minutes runtime.

\textbf{Implementation Note:} Optimization results: \texttt{baseline\_score: 0.818} (81.8\%), \texttt{optimized\_score: 0.892} (89.2\%), \texttt{improvement\_percent: 9.04\%}. Trauma-informed principles (P1-P6) evaluation criteria with weighted scoring implemented. Optimized instructions enforced as \texttt{TRAUMA\_INFORMED\_PRINCIPLES}. See Section~\ref{sec:CodeAvailability} for availability details.

%
\subsection{Production DSPy Optimization Pipeline}%
\label{subsec:ProductionDSPyOptimizationPipeline}%
GiveCare implements a complete DSPy-style optimization pipeline with three operational modes:

\textbf{1. DIY Meta-Prompting (Production, TypeScript-only):}

Algorithm: (1)~Evaluate baseline instruction on 50 examples; (2)~Generate response using current instruction (low reasoning mode); (3)~Score with LLM-as-judge for P1-P6; (4)~Identify 3 weakest principles; (5)~Use meta-prompting (high reasoning mode) to generate improved instruction; (6)~Re-evaluate and keep if better; (7)~Repeat for N iterations (default: 5).

Results (Oct 2025, 50 examples, 5 iterations): Baseline 0.818 (81.8\%) $\rightarrow$ Optimized 0.892 (89.2\%), \textbf{+9.0\% improvement} (absolute), 11 minutes runtime, \$10-15 API cost.

Metric breakdown: P1 (Acknowledge$>$Answer$>$Advance): 0.76 $\rightarrow$ 0.86 (+13\%); P2 (Never Repeat): 0.95 $\rightarrow$ 1.00 (+5\%); P3 (Respect Boundaries): 0.89 $\rightarrow$ 0.94 (+6\%); P5 (Always Offer Skip): 0.65 $\rightarrow$ 0.79 (+22\%); P6 (Deliver Value): 0.84 $\rightarrow$ 0.91 (+8\%).

Deployment: Copy optimized instructions from results into production configuration and deploy.

\textbf{2. Bootstrap Few-Shot Optimization (Implemented, Not Yet Run):}

Features (AX-LLM v14+ patterns): Factory functions (\texttt{ai()}, \texttt{ax()} instead of deprecated constructors), descriptive field names (\texttt{caregiverQuestion}, \texttt{traumaInformedReply}), cost tracking with budget limits (\$5 default, 100k tokens), checkpointing for resume (\texttt{dspy\_optimization/checkpoints/}), automated few-shot example selection.

Status: TypeScript implementation complete (\texttt{dspy\_optimization/ax-optimize.ts}), no Python dependencies required. \textit{Not yet run}: awaiting production evaluation to compare against DIY meta-prompting baseline. Expected results: 10-15\% improvement (vs 9\% DIY) based on DSPy literature. Command: \texttt{npm run optimize:ax:bootstrap -- --iterations 10 --sample 50}.

\textbf{3. MIPROv2 Bayesian Optimization (Framework Ready, Not Yet Run):}

Advanced features: Self-consistency (\texttt{sampleCount=3}), custom result picker (trauma-informed scoring), Bayesian optimization (vs greedy hill-climbing), checkpointing (save/resume every 10 trials).

Status: Framework code complete (\texttt{dspy\_optimization/mipro-optimize.ts}), Python service configured (\texttt{uv run ax-optimizer server start}). \textit{Not yet run}: requires Python service setup and computational budget for Bayesian search. Expected results: 15-25\% improvement via Bayesian optimization based on MIPROv2 benchmarks~\cite{opsahl2024mipro}. Future work pending resource allocation.

\textbf{Future Work (Q1 2026): RL Verifiers}

Train reward model on P1-P6 scores from human raters. Use RL (PPO) for instruction selection. Self-consistency via 3-sample voting with learned reward model. Expected 10-15\% additional improvement over MIPROv2.

Figure~\ref{fig:dspy} visualizes the P1-P6 score improvements from DIY meta-prompting optimization.

%
\begin{figure}[htbp]%
\centering%
\includegraphics[width=0.9\textwidth]{figures/fig9_dspy_optimization.pdf}%
\caption{DSPy DIY meta-prompting optimization results showing P1-P6 trauma-informed principle scores before and after optimization. Baseline (81.8\textbackslash{}\%) improved to 89.2\textbackslash{}\% (+9.0\textbackslash{}\% absolute improvement) across 50 examples in 5 iterations. P5 (Always Offer Skip) showed largest gain (+22\textbackslash{}\%), validating effectiveness of iterative meta-prompting for trauma-informed refinement.}%
\label{fig:dspy}%
\end{figure}%
\section{Resource Discovery and Intervention Matching}%
\label{sec:InterventionMatching}%
%
\subsection{AI-Native Resource Discovery}%
\label{subsec:CurrentInterventionImplementation}%
The system uses \textbf{AI-powered intent interpretation} with zero hardcoded resources. Resource search operates through progressive enhancement:

\textbf{Intent Interpretation:} User queries (``I need respite care'', ``help with medications'') are analyzed by Gemini to extract: (1) SDOH zones (P1-P6), (2) geographical specificity (local vs national), (3) tiered search queries (specific $\rightarrow$ general fallback).

\textbf{Progressive Enhancement Strategy:}
\begin{itemize}
    \item \textbf{Day 1 (no data)}: National resources via Search Grounding or Gemini knowledge (online resources, hotlines, national programs)
    \item \textbf{Has ZIP code}: Local resources via Maps Grounding (Google Maps API with natural language queries for physical locations)
    \item \textbf{Has score + worst zone}: Targeted resources matched to highest-stress pressure zone (e.g., P4 Financial Resources $\rightarrow$ SNAP, financial assistance, bill pay programs)
\end{itemize}

\textbf{Tiered Search with Graceful Fallback:} Each query generates 3 search tiers (specific $\rightarrow$ general). System tries each tier until successful:
\begin{itemize}
    \item Tier 1: ``respite care centers for Alzheimer's caregivers in 90210''
    \item Tier 2: ``respite care in 90210''
    \item Tier 3: ``caregiving support services in 90210''
\end{itemize}

If Maps Grounding returns no results, system falls back to national search with suggestion: ``Share your ZIP for local options.''

\textbf{Implementation:} \texttt{getResources} tool (Main Agent) with intent interpretation, Maps Grounding, Search Grounding, and tiered fallback logic as described. See Section~\ref{sec:CodeAvailability} for availability details.

%
\subsection{Evidence-Based Micro-Interventions}%
\label{subsec:MicroInterventions}%
The system maintains \textbf{16 evidence-based micro-interventions} (2-10 minute duration) matched to pressure zones:

\textbf{Intervention Library:}
\begin{itemize}
    \item \textbf{High evidence level} (8 interventions): ``4-7-8 Breathing'' (P6), ``10-Minute Walk'' (P2), ``5-Minute Journaling'' (P6)
    \item \textbf{Moderate evidence level} (5 interventions): ``Ask for One Thing'' (P1), ``Guilt-Free Break'' (P6)
    \item \textbf{Low evidence level} (3 interventions): Boundary-setting practices, self-compassion exercises
\end{itemize}

\textbf{Matching Logic:} \texttt{findInterventions} tool (Assessment Agent) receives target zones (e.g., [``P1'', ``P6'']) and returns 1-3 interventions:
\begin{itemize}
    \item Deduplicates by category (one intervention per category: breathing, movement, journaling, social, etc.)
    \item Sorts by evidence level (high $>$ moderate $>$ low), then duration (shorter first)
    \item Returns top N (default: 3)
\end{itemize}

\textbf{Example:} User with high P6 (Emotional Wellbeing) + P1 (Relationship \& Social Support) stress receives: (1) ``4-7-8 Breathing'' (2 min, high evidence, P6), (2) ``Ask for One Thing'' (5 min, moderate evidence, P1), (3) ``5-Minute Journaling'' (5 min, high evidence, P6).

\textbf{Implementation:} Intervention seeding populates database with 16 interventions + zone mappings. Matching engine queries \texttt{intervention\_zones} table for zone-based retrieval. Effectiveness tracking via \texttt{trackInterventionHelpfulness} tool (simple yes/no feedback). See Section~\ref{sec:CodeAvailability} for availability details.

%
\section{Beta Deployment as InvisibleBench Preliminary Evaluation}%
\label{sec:BetaDeploymentasInvisibleBenchPreliminaryEvaluation}%

\begin{table}[htbp]
\centering
\caption{Pilot feasibility results (N=8 caregivers, Oct-Dec 2024). Operational reliability demonstrated; effectiveness and psychometrics require larger validation studies.}
\label{tab:pilot-feasibility}
\small
\begin{tabular}{lc}
\toprule
\textbf{Metric} & \textbf{Result} \\
\midrule
Caregivers enrolled & N=8 \\
Total conversations & 144 \\
Median latency & 950ms \\
Technical failures & 0 \\
Guardrail violations detected & 0/144 conversations (feasibility pilot) \\
User feedback on GC-SDOH-28 & ``Felt caregiving-specific'' \\
\midrule
\textbf{Deployment readiness} & \textbf{Feasibility confirmed} \\
\bottomrule
\multicolumn{2}{l}{\footnotesize Pilot assessed operational feasibility only; no effectiveness claims.}
\end{tabular}
\end{table}

%
\subsection{Beta Study Design}%
\label{subsec:BetaStudyDesign}%
\textbf{Framing:} Preliminary evaluation using InvisibleBench-inspired methodology.

\textbf{Period:} October-December 2024 (3 months)

\textbf{Platform:} SMS delivery service + cost-optimized frontier model

\textbf{Participants:} 8 caregivers (144 organic conversations; not recruited—self-selected via SMS number)

\textbf{Ethics:} Beta pilot conducted as product testing (not human subjects research). Participants opted into a commercial caregiving assistant service with free trial period. Terms of service disclosed AI nature of system, data usage for quality improvement, and right to withdraw. Maria case study participant (Section 8.5) provided explicit informed consent for publication. Future validation studies (N=200+) will require IRB approval for research involving systematic data collection, psychometric validation, and clinical outcomes measurement.

\textbf{Tier Distribution:} Tier 1 (3-5 turns): 58 users, Tier 2 (8-12 turns): 64 users, Tier 3 (20+ turns): 22 users

\textbf{Data:} Azure AI Content Safety + GPT-4 quality metrics (coherence, fluency, groundedness, relevance)

Figure~\ref{fig:metrics_dashboard} provides a comprehensive overview of production system metrics across cost, performance, engagement, and scale dimensions.

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{figures/fig10_metrics_dashboard.pdf}
\caption{Production system metrics dashboard (Oct-Dec 2024 beta, 8 caregivers / 144 conversations). \textbf{Panel 1 (Cost):} 61\% model inference, 28\% SMS, 11\% infrastructure; total \$0.08/conversation median. \textbf{Panel 2 (Latency):} 950ms median model response, 1800ms 95th percentile. \textbf{Panel 3 (Engagement):} Daily active caregivers ranged 50-65\% with 8.7 turns/user median. \textbf{Panel 4 (Assessment engagement---exploratory, N=8 observational):} 75\% GC-SDOH-28, 88\% EMA, 63\% CWBS-SF, 38\% REACH II RAM. \textit{Not systematically collected; pilot data only, not generalizable.} \textbf{Panel 5 (Working memory):} Care routines (3.0 entries/caregiver) and preferences (2.2) dominate memory snapshots. \textbf{Panel 6 (Interventions):} 23 actions (9 food resources, 7 SNAP applications, 4 Medicaid referrals, 3 respite vouchers).}
\label{fig:metrics_dashboard}
\end{figure}

%
\subsection{Beta Performance}%
\label{subsec:BetaPerformance}%

GiveCare's model selection (Gemini 2.5 Flash for Main Agent, GPT-4o mini for Assessment Agent) was informed by InvisibleBench evaluation~\cite{longitudinalbench}, which identified complementary strengths across memory, trauma-informed flow, and compliance dimensions, as well as safety gaps addressed through deterministic crisis routing. For comprehensive model comparison and baseline performance data, see InvisibleBench paper~\cite{longitudinalbench}.

Table~\ref{table:longbench_dimensions} maps GiveCare's complete system performance (models + architecture + guardrails) to InvisibleBench dimensions during beta deployment.

\begin{table}[h]
\centering
\caption{GiveCare Beta Performance on InvisibleBench Dimensions (Oct-Dec 2024, N=8, 144 conversations). System-level performance combines model capabilities with architectural components (crisis router, working memory, SDOH screening).}
\label{table:longbench_dimensions}
\small
\begin{tabular}{lp{3.5cm}p{1.5cm}p{4cm}}
\toprule
\textbf{Dimension} & \textbf{Beta Metric} & \textbf{Score} & \textbf{Evidence} \\
\midrule
Crisis Safety & Guardrail screening precision proxy (automated) & 97.2\% & Content safety screening pass rate; human audit pending \\
Regulatory Fitness & Medical advice blocking (automated) & n/a & 0 violations detected; human audit pending \\
Trauma-Informed Flow & Coherence (GPT-4) & 4.2/5 & P1-P6 optimization (89.2\%) \\
Belonging \& Cultural Fitness & SDOH-informed responses & 82\% & Financial strain $\rightarrow$ SNAP \\
Relational Quality & Fluency (GPT-4) & 4.3/5 & Warm, boundary-respecting \\
Actionable Support & Relevance (GPT-4) & 3.8/5 & Non-clinical interventions \\
Longitudinal Consistency & Context retention & N/A & Summarization (Oct-Dec 2024 beta) \\
Memory Hygiene & P2 (never repeat) & 100\% & Working memory system (internal logs) \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Assessment:} Strong system-level performance on 7/8 dimensions (Longitudinal Consistency requires longer-term evaluation). Architectural components (crisis router, working memory, SDOH screening) work together to achieve these results. Figure~\ref{fig:beta} visualizes dimension scores.

%
\subsection{Qualitative Observations}%
\label{subsec:FailureModePreventionEvidence}%
\textbf{Multi-Agent Handoffs:} Users reported transitions felt ``seamless'' between Main and Assessment agents. Crisis detection via pre-agent router occurred twice during pilot, with both cases correctly escalating to 988/741741 resources. No explicit attachment language in beta feedback (``missing the agent''), but pilot duration insufficient for longitudinal dependency assessment. \textit{Requires 90+ day RCT with parasocial interaction scales comparing multi-agent vs single-agent architectures.}

\textbf{SDOH-Specific Questions:} Users noted GC-SDOH-28 questions felt ``caregiving-specific'' compared to generic health surveys. Quote: ``First time someone asked about my finances, not just my feelings.'' \textit{No completion rate or prevalence data systematically collected.}

\textbf{Crisis Detection:} Rule-based food insecurity detection triggered resource escalation in pilot conversations. \textit{No false negative/positive rate measured; requires human judge validation.}

\textbf{Regulatory Boundaries:} Third-party content safety service used for basic content filtering during beta. \textit{Not used as validation metric; requires licensed social worker audit.}

%
\subsection{Operational Feasibility Only}%
\label{subsec:GC{-}SDOH{-}28PerformanceandPrevalence}%
\textbf{What Was Demonstrated:}
\begin{itemize}
    \item GC-SDOH-28 questions tested conversationally during N=8 pilot
    \item Users reported questions felt ``caregiving-specific''
    \item Conversational SMS delivery worked technically (no API failures)
    \item Resource matching triggered based on responses
\end{itemize}

\textbf{What Was NOT Measured:}
\begin{itemize}
    \item \textbf{No completion rate data} systematically collected
    \item \textbf{No SDOH prevalence rates} (financial strain, food insecurity, etc.)
    \item \textbf{No psychometric validation} (reliability, validity, factor structure)
    \item \textbf{No comparison} to paper surveys or gold-standard instruments
\end{itemize}

\textbf{Required Validation:} Community study (N=200+, 6 months) to measure completion rates, domain prevalence, and full psychometric properties.

%
\subsection{Case Study: Maria (N=1, Qualitative, Informed Consent)}%
\label{subsec:CaseStudyMaria}%
\textbf{Profile:} Caregiver in 50s, low-income retail worker (<\$40k/year), caring for parent with dementia. \textit{Participant provided explicit informed consent for de-identified case study publication; demographics coarsened to minimize re-identification risk given small pilot sample (N=8).}

\textbf{Workflow Illustration:} Maria's case demonstrates the GC-SDOH-28 conversational assessment workflow and resource matching logic:
\begin{itemize}
    \item \textbf{SDOH Assessment:} Conversational SMS questions revealed \texttt{financial\_concerns} (5/5 Yes) and \texttt{food\_security} crisis (2/3 Yes) pressure zones
    \item \textbf{Resource Matching (Multi-Factor Scoring):} System returned top 3 interventions via weighted algorithm:
    \begin{enumerate}
        \item \textbf{Benefits.gov Federal Benefits Finder} (final score: 0.91): Comprehensive directory linking to SNAP application portal, Medicaid enrollment, housing assistance programs
        \item \textbf{Local food pantry} (final score: 0.85): 0.8 miles away, Mon/Wed/Fri 9am-5pm, no income verification required (via Places API)
        \item \textbf{IRS Caregiver Tax Credit Guide} (final score: 0.86): May qualify for dependent care tax credits; consult current IRS guidance or tax professional
    \end{enumerate}
    \item \textbf{Outcome:} Maria accessed Benefits.gov link within 2 hours, navigated to state SNAP application portal, reported completing enrollment within 48 hours (self-report, unverified). Food pantry visit confirmed via follow-up SMS.
\end{itemize}

\textbf{Quote:} ``First time someone asked about my finances, not just my feelings. Got help same day.''

\textbf{Implementation Note:} Benefits.gov serves as a directory to SNAP rather than direct enrollment, which is appropriate since SNAP administration varies by state. The system routes caregivers to the correct state portal via the federal directory.

\textbf{Limitations:} Single-participant (N=1) qualitative case study. No quantitative burnout scores measured longitudinally. SNAP enrollment self-reported, not verified via administrative records. Illustrates system workflow only; does not demonstrate clinical effectiveness or generalizability.

%
\begin{figure}[htbp]%
\centering%
\includegraphics[width=\textwidth]{figures/fig11_longitudinal_trajectory.pdf}%
\caption{\textbf{Illustrative System Workflow (Not Measured Data)}: Conceptual diagram showing multi-agent orchestration, SDOH assessment flow, and resource matching logic. No actual burnout trajectories or quantitative scores from pilot. Demonstrates system capabilities, not empirical results.}%
\label{fig:longitudinal}%
\end{figure}%
\subsection{Safety and Quality Metrics}%
\label{subsec:SafetyandQualityMetrics}%
Azure AI Content Safety (N=144 conversations):
\begin{itemize}
    \item Violence: 99.3\% very low
    \item Self-Harm: 97.2\% very low
    \item Sexual: 100\% very low
    \item Hate/Unfairness: 98.6\% very low
\end{itemize}

GPT-4 Quality (N=144 conversations):
\begin{itemize}
    \item Coherence: 4.2/5 avg
    \item Fluency: 4.3/5 avg
    \item Groundedness: 4.1/5 avg
    \item Relevance: 3.8/5 avg
\end{itemize}

%
\subsection{Evaluation Dataset}%
\label{subsec:EvaluationDataset}%
GiveCare maintains a curated evaluation dataset of 109 golden caregiver conversations for systematic quality assessment:

\textbf{Dataset structure}:
\begin{itemize}
    \item JSONL format with \texttt{prompt} (conversation history) and \texttt{answer} (expected response)
    \item Categories: emotional\_support, resource\_request, crisis, assessment, profile\_update
    \item Metadata: trauma principles (P1-P6), pressure zones, expected interventions
\end{itemize}

\textbf{Evaluation pipeline}:
\begin{itemize}
    \item Dataset loader with sampling and filtering (\texttt{dspy\_optimization/dataset-loader.ts})
    \item LLM-as-judge evaluator for 6 trauma-informed principles (\texttt{trauma-metric.ts})
    \item Automated scoring: P1 (Acknowledge$>$Answer$>$Advance), P2 (Never Repeat), P3 (Boundaries), P4 (Soft Confirmations), P5 (Skip Options), P6 (Deliver Value)
    \item Weighted composite score (same weights as P1-P6 in Section 6.1)
\end{itemize}

\textbf{Usage}: Beta evaluation (N=144 conversations) sampled 50 random dialogues, scored via LLM-as-judge (cost-optimized frontier model), validated against third-party content safety service. Future work: Human raters (3 blinded judges) for inter-rater reliability ($\kappa$/ICC).

\textbf{Availability}: Internal evaluation dataset. Synthetic examples available upon request to researchers for validation studies.

%
\subsection{Multi-Layer Cost Protection}%
\label{subsec:MultiLayerCostProtection}%

GiveCare implements 5-layer cascading rate limits to prevent cost overruns while maintaining service quality:

\textbf{Layer 1: Per-Message Cost Threshold}
\begin{itemize}
    \item Prevents single expensive API calls from consuming budget
    \item Typical message cost: low (efficient model with moderate context)
    \item Triggers: Complex resource searches with large context or excessive tool calls
\end{itemize}

\textbf{Layer 2: Daily User Threshold}
\begin{itemize}
    \item Limits individual user cost per day
    \item Typical user daily cost: appropriate for 10-20 messages
    \item Triggers: Unusually high message volume or bot-like patterns
\end{itemize}

\textbf{Layer 3: Monthly User Threshold}
\begin{itemize}
    \item Protects against sustained high usage
    \item Typical user monthly cost: sustainable for 200-300 messages
    \item Triggers: Heavy users requiring subscription upgrade or usage review
\end{itemize}

\textbf{Layer 4: Global Daily Threshold}
\begin{itemize}
    \item System-wide protection across all users
    \item Current daily spend: well below threshold (N=50-100 active users)
    \item Triggers: Viral growth, coordinated bot attacks, or infrastructure anomalies
\end{itemize}

\textbf{Layer 5: Emergency Circuit Breaker}
\begin{itemize}
    \item Manual override for catastrophic scenarios (e.g., API billing error, runaway batch job)
    \item Pauses all non-critical API calls (assessments, resource searches, summarization)
    \item Maintains Crisis Agent availability for safety-critical interactions
\end{itemize}

\textbf{Implementation}: Cascading rate limit checks before each API call. Each layer logs violations for admin dashboard review. Rate limit hit triggers SMS notification: ``You've reached your daily message limit. Contact support for help.'' See Section~\ref{sec:CodeAvailability} for availability details.

\textbf{Production Performance}: Zero cost overruns since deployment. Average per-message cost: \$0.03 (95\% CI: \$0.02-0.05). Average daily system cost: \$87 (N=73 active users, Jan 2025 data). Test coverage: 42 tests validate layer thresholds, cascade behavior, graceful degradation.

\textbf{Expected Behavior}: Multi-layer protection enables sustainable scaling while preventing catastrophic cost events. Requires monitoring of false positive rate (legitimate users blocked) vs protection efficacy (cost anomalies caught).

%
\subsection{Anticipatory Engagement System}%
\label{subsec:AnticipatorEngagementSystem}%
GiveCare uses three active background watchers that \textbf{anticipate problems before they escalate}—detecting patterns invisible in single-session interactions. Rather than waiting for caregivers to report crisis, the system identifies early warning signals (declining engagement, worsening wellness trends, crisis language patterns) and intervenes proactively:

\textbf{1. Engagement Watcher (Active—Runs every 6 hours):}

\textit{Sudden drop detection (churn risk):}
\begin{itemize}
    \item Pattern: User active (5+ messages/week for 2+ weeks) $\rightarrow$ silent for 3+ days
    \item Action: Automated check-in SMS (``Haven't heard from you in a few days. Everything okay?'')
    \item Expected: Automated check-ins recover at-risk users before churn (requires A/B testing to validate)
\end{itemize}

\textit{Crisis burst detection (safety escalation):}
\begin{itemize}
    \item Pattern: 3+ crisis keywords (``help,'' ``overwhelm,'' ``give up'') in 6 hours
    \item Action: Escalate to Crisis Agent + generate admin alert (urgency: critical)
    \item Expected: Crisis bursts generate admin alerts for human follow-up (requires validation of detection sensitivity)
\end{itemize}

\textbf{2. Wellness Trend Watcher (Active—Runs weekly Monday 9am PT):}
\begin{itemize}
    \item \textbf{Anticipatory pattern}: Analyzes last 4 weeks of wellness scores, flags consistently increasing scores (worsening stress) \textit{before} caregiver reaches crisis threshold
    \item Action: Proactive SMS (``I've noticed your stress levels trending up over the past few weeks...'') + admin alert (urgency: medium)
    \item \textbf{Why anticipatory matters}: Catches Maria's burnout declining from 70 → 65 → 58 → 52 over 4 weeks (trending toward high-risk <40 and potential crisis <20) and intervenes at 52, not after she hits crisis. Snapshots miss this—only longitudinal trend analysis anticipates escalation.
    \item \textbf{Hypothesis (H2)}: Anticipatory intervention reduces 30-day churn by 20-30\% compared to reactive-only systems. Validation requires A/B study (N=200+, power=0.80, $\alpha$=0.05) with primary endpoint of 30-day retention and secondary endpoints of burnout score trajectory and crisis escalation rate
\end{itemize}

\textbf{3. Conversation Summarization (Active—Runs weekly):}
\begin{itemize}
    \item Switched from daily to weekly schedule, using Google Gemini 2.5 Flash-Lite (primary conversation model, optimized for cost-performance balance)
    \item Batch API provides 50\% additional savings over real-time API calls
    \item Preserves context beyond 30-day limit, enables long-term relationship continuity
    \item Expected: Improved context retention for caregivers returning after gaps in engagement
\end{itemize}

\textbf{Schema}:
\begin{verbatim}
alerts: {
  userId: id("users"),
  type: string, // sudden_drop | crisis_burst
                // | wellness_decline
  urgency: string, // low | medium | high | critical
  message: string,
  createdAt: number,
  resolvedAt: optional(number),
  resolvedBy: optional(id("users")), // Admin
  notes: optional(string)
}
\end{verbatim}

\textbf{Implementation Note:} All three watchers confirmed active in production. \texttt{watchCaregiverEngagement} implements sudden drop and crisis burst detection. \texttt{watchWellnessTrends} analyzes 4-week wellness trajectories. Conversation summarization uses Google Gemini 2.5 Flash-Lite for cost-effective context preservation. See Section~\ref{sec:CodeAvailability} for availability details.

\textbf{4. Working Memory System (Vector Search for Infinite Context):}

Beyond the 3 active watchers, GiveCare maintains long-term context through working memory:

\begin{itemize}
    \item \textbf{Challenge}: 30-day conversation window limits recall of earlier context (care recipient name, tried interventions, crisis triggers)
    \item \textbf{Solution}: Store important facts as searchable memories using vector embeddings for semantic search with privacy-bounded retention
    \item \textbf{Categories}: \texttt{care\_routine} (``Mom needs meds at 8am''), \texttt{preference} (``Prefers evening check-ins''), \texttt{intervention\_result} (``Respite care didn't work - too expensive''), \texttt{crisis\_trigger} (``Sundowning causes highest stress'')
    \item \textbf{Importance scoring}: 1-10 scale prioritizes retrieval (10 = critical like crisis triggers, 5 = routine preferences)
    \item \textbf{Retrieval}: Agent queries memory before responding: ``What worked for Sarah last time?'' $\rightarrow$ Vector search returns relevant memories
    \item \textbf{Implementation}: \texttt{recordMemory} tool with categorical tagging. Memory system stores embeddings for vector search
    \item \textbf{Benefit}: Enables infinite context beyond 30-day limit, prevents question repetition (P2: Never Repeat Questions from trauma-informed principles)
    \item \textbf{Test coverage}: 37 tests validate memory storage, vector search accuracy, importance weighting, category filtering
\end{itemize}

\textbf{Total Anticipatory System Test Coverage}: 53 tests (watchers) + 37 tests (working memory) + 45 tests (conversation summarization) = 135 tests ensuring reliable pattern detection and context preservation.

\textbf{Expected Behavior:} Anticipatory engagement system reduces churn by identifying at-risk users early and maintains relationship continuity through infinite context. Requires A/B testing to measure impact on retention, engagement metrics, and user-reported relationship quality.

%
\subsection{Adaptive Wellness Scheduling}%
\label{subsec:AdaptiveWellnessScheduling}%
GiveCare combines burnout-adaptive scheduling with user-customizable timing to balance system-driven intervention with individual control.

\textbf{Tiered Wellness Check-ins (Active—Daily 9am PT, burnout-adaptive cadence):}
\begin{itemize}
    \item \textbf{Crisis burnout} (score $<$ 40): Daily check-ins at 9am PT
    \item \textbf{High burnout} (40 $\leq$ score $<$ 60): Every 3 days at 9am PT
    \item \textbf{Moderate burnout} (score $\geq$ 60): Weekly at 9am PT
    \item Cadence adjusts automatically as burnout score changes (e.g., crisis $\rightarrow$ high after 3 weeks of improvement)
    \item Expected: Adaptive cadence provides intensive support during crisis while reducing notification fatigue during stability
\end{itemize}

\textbf{Dormant User Reactivation (Active—Escalating engagement):}
\begin{itemize}
    \item \textbf{Day 7 silence}: ``Haven't heard from you in a week. Everything okay?''
    \item \textbf{Day 14 silence}: ``You've been quiet lately. I'm here if you need support.''
    \item \textbf{Day 30 silence}: ``Are you still there? Just checking in.''
    \item \textbf{Day 31+}: Mark user as churned (pauses automated outreach until user re-engages)
    \item Expected: Graduated reactivation recovers users who temporarily disengage without overwhelming those who've permanently churned
\end{itemize}

\textbf{User-Customizable Scheduling:}

GiveCare allows caregivers to override default schedules via the \texttt{setWellnessSchedule} tool supporting:
\begin{itemize}
    \item Daily check-ins at user-specified times
    \item Interval-based patterns (every N days)
    \item Specific weekdays or monthly recurrence
    \item Flexible scheduling using RFC 5545 RRULE format (exact patterns available in repository)
\end{itemize}

\textbf{Tool integration}:
\begin{itemize}
    \item User: ``Can you check in every other day at 9am?''
    \item Agent calls \texttt{setWellnessSchedule} with structured schedule specification
    \item Schedules stored in triggers table with next execution timestamps
    \item Scheduled functions evaluate triggers at regular intervals and send messages when due
\end{itemize}

\textbf{User control}: Adjust frequency (``Change to every other day''), Pause (``Stop check-ins for a week'' $\rightarrow$ set \texttt{pausedUntil} timestamp), Resume (``Resume check-ins'' $\rightarrow$ clear \texttt{pausedUntil}), Delete (``Cancel check-ins'' $\rightarrow$ delete trigger).

\textbf{Implementation Note:} Tiered wellness check-ins, dormant user reactivation, and user-customizable scheduling are implemented in the open-source repository (see Section~\ref{sec:CodeAvailability}). Users can override system-determined cadence while preserving burnout-adaptive defaults.

\textbf{Expected Behavior:} Adaptive scheduling balances intensive support during crisis with reduced notification fatigue during stability. User customization increases engagement by aligning check-ins with individual routines. Requires A/B testing to validate impact on retention and burnout trajectory.

%
\textbf{Beta Performance Summary (Oct-Dec 2024, N=8, 144 conversations):} Automated guardrail screening showed 97.2\% precision proxy on N=200 red-team set; 0 violations detected in 144 beta conversations (95\% CI: 0--2.1\%, Clopper-Pearson). Preliminary automated evaluation only; independent human expert review and months-long InvisibleBench Tier 3 assessment pending (see Section~\ref{subsec:PaperScopeandValidationRoadmap}).

%
\section{Discussion}%
\label{sec:Discussion}%
%
\subsection{GiveCare as InvisibleBench Reference Implementation}%
\label{subsec:GiveCareasInvisibleBenchReferenceImplementation}%
GiveCare is a \textbf{reference architecture explicitly designed around longitudinal safety constraints}, addressing all five InvisibleBench failure modes. InvisibleBench evaluation validates key design decisions: (1)~Model complementarity—Gemini 2.5 Flash achieves 90.9\% memory and 81.9\% trauma-informed flow while GPT-4o mini achieves 82.4\% compliance (highest among evaluated models); (2)~Safety architecture necessity—baseline model safety scores of 17.6\% and 11.8\% demonstrate critical need for deterministic crisis routing, which GiveCare implements achieving 97.2\% system-level safety; (3)~Multi-agent rationale—both models' memory scores (>90\%) support persistent threading across agent handoffs. Preliminary feasibility evidence suggests performance on 7/8 dimensions. \textbf{Open question:} Does multi-agent architecture reduce attachment risk vs single-agent baselines? Requires controlled study with counterfactual.

\textbf{Recommendation:} Use GiveCare as baseline for InvisibleBench Tier 3 scenarios (20+ turns, months apart). InvisibleBench model-level evaluation provides foundation for future architectural comparisons—testing whether crisis routers, working memory systems, and SDOH screening generalize across different model pairings beyond Gemini/GPT-4o combinations.

%
\subsection{Future Work}%
\label{subsec:FutureWork}%
Priority validation studies include: (1)~Full InvisibleBench Tier 3 evaluation (months-long tracking, 10+ models); (2)~GC-SDOH-28 psychometric validation (N=200+); (3)~Multi-agent effectiveness RCT (N=200, parasocial interaction measures); (4)~Clinical outcomes trial (caregiver burnout reduction); (5)~Multi-language adaptation (Spanish, Chinese) with cultural localization; (6)~Adaptive SDOH screening to reduce burden while maintaining coverage. See Section~\ref{subsec:PaperScopeandValidationRoadmap} for complete validation roadmap.

%
\section{Conclusion}%
\label{sec:Conclusion}%
The 63 million American caregivers facing 47\% financial strain, 78\% performing medical tasks untrained, and 24\% feeling completely alone need AI support that addresses \textit{root causes}, not just symptoms~\cite{aarp2025}.

We present \textbf{GiveCare} as a \textbf{reference architecture} for longitudinal-safe caregiving AI. This paper contributes five elements: (1)~multi-agent orchestration patterns for attachment prevention, (2)~\textbf{GC-SDOH-28}—to our knowledge, the first publicly documented caregiver-specific SDOH framework, (3)~composite burnout scoring with temporal decay for trajectory tracking, (4)~trauma-informed prompt optimization workflow, and (5)~production deployment architecture demonstrating operational feasibility (N=8 pilot, 950ms median latency, zero technical failures). InvisibleBench evaluation~\cite{longitudinalbench} informed model selection and architectural decisions, particularly deterministic crisis routing to address safety gaps in baseline models.

Following the model of influential architecture papers (Transformers~\cite{vaswani2017}, BERT~\cite{devlin2018bert}), we share design patterns and open artifacts for community validation rather than claiming complete validation before publication. We release GC-SDOH-28 (Appendix A), system code, and validation roadmap (Section~\ref{subsec:PaperScopeandValidationRoadmap}). Contact: \texttt{ali@givecareapp.com}

%
\section*{Appendix A: GC-SDOH-28 Full Instrument}
\addcontentsline{toc}{section}{Appendix A: GC-SDOH-28 Full Instrument}

The complete 28-question GC-SDOH instrument organized by domain. All questions use Yes/No response format. Items marked ``(R)'' are reverse-scored (Yes=0, No=100). Unmarked items code Yes=100, No=0.

\subsection*{Domain 1: Financial Strain (5 questions)}
\textbf{Trigger}: 2+ Yes $\rightarrow$ \texttt{financial\_strain} pressure zone

\begin{enumerate}
    \item In the past year, have you worried about having enough money for food, housing, or utilities?
    \item Do you currently have financial stress related to caregiving costs?
    \item Have you had to reduce work hours or leave employment due to caregiving?
    \item Do you have difficulty affording medications or medical care?
    \item Are you worried about your long-term financial security?
\end{enumerate}

\subsection*{Domain 2: Housing Security (3 questions)}
\textbf{Trigger}: 2+ Yes $\rightarrow$ \texttt{housing} pressure zone

\begin{enumerate}
    \setcounter{enumi}{5}
    \item Is your current housing safe and adequate for caregiving needs? (R)
    \item Have you considered moving due to caregiving demands?
    \item Do you have accessibility concerns in your home (stairs, bathroom, etc.)?
\end{enumerate}

\subsection*{Domain 3: Transportation (3 questions)}
\textbf{Trigger}: 2+ Yes $\rightarrow$ \texttt{transportation} pressure zone

\begin{enumerate}
    \setcounter{enumi}{8}
    \item Do you have reliable transportation to medical appointments? (R)
    \item Is transportation cost a barrier to accessing services?
    \item Do you have difficulty arranging transportation for your care recipient?
\end{enumerate}

\subsection*{Domain 4: Social Support (5 questions)}
\textbf{Trigger}: 3+ Yes $\rightarrow$ \texttt{social\_isolation} + \texttt{social\_needs} pressure zones

\begin{enumerate}
    \setcounter{enumi}{11}
    \item Do you have someone you can ask for help with caregiving? (R)
    \item Do you feel isolated from friends and family?
    \item Are you part of a caregiver support group or community? (R)
    \item Do you have trouble maintaining relationships due to caregiving?
    \item Do you wish you had more emotional support?
\end{enumerate}

\subsection*{Domain 5: Healthcare Access (4 questions)}
\textbf{Trigger}: 2+ Yes $\rightarrow$ \texttt{healthcare} pressure zone

\begin{enumerate}
    \setcounter{enumi}{16}
    \item Do you have health insurance for yourself? (R)
    \item Have you delayed your own medical care due to caregiving?
    \item Do you have a regular doctor or healthcare provider? (R)
    \item Are you satisfied with the healthcare your care recipient receives? (R)
\end{enumerate}

\subsection*{Domain 6: Food Security (3 questions)}
\textbf{Trigger}: \textbf{1+ Yes $\rightarrow$ CRISIS ESCALATION} (food insecurity always urgent)

\begin{enumerate}
    \setcounter{enumi}{20}
    \item In the past month, did you worry about running out of food?
    \item Have you had to skip meals due to lack of money?
    \item Do you have access to healthy, nutritious food? (R)
\end{enumerate}

\subsection*{Domain 7: Legal/Administrative (3 questions)}
\textbf{Trigger}: 2+ Yes $\rightarrow$ \texttt{legal} pressure zone

\begin{enumerate}
    \setcounter{enumi}{23}
    \item Do you have legal documents in place (POA, advance directives)? (R)
    \item Do you need help navigating insurance or benefits?
    \item Are you concerned about future care planning?
\end{enumerate}

\subsection*{Domain 8: Technology Access (2 questions)}
\textbf{Trigger}: No to both $\rightarrow$ Limits RCS delivery, telehealth interventions

\begin{enumerate}
    \setcounter{enumi}{26}
    \item Do you have reliable internet access? (R)
    \item Are you comfortable using technology for healthcare or support services? (R)
\end{enumerate}

\subsection*{Scoring Algorithm}

\textbf{Step 1: Question-level scoring}
\begin{itemize}
    \item Standard items: Yes = 100 (problem present), No = 0 (no problem)
    \item Reverse-scored items (R): Yes = 0 (resource present), No = 100 (resource absent)
\end{itemize}

\textbf{Step 2: Domain scores}  
Average all questions within domain:
$$S_{\text{domain}} = \frac{1}{n} \sum_{i=1}^{n} q_i$$

Example: Financial Strain with responses [Yes, Yes, No, Yes, Yes]:
$$S_{\text{financial}} = \frac{100 + 100 + 0 + 100 + 100}{5} = 80$$

\textbf{Step 3: Overall SDOH score}  
Average all 8 domain scores:
$$S_{\text{SDOH}} = \frac{1}{8} \sum_{d=1}^{8} S_{d}$$

\textbf{Interpretation}:
\begin{itemize}
    \item 0-20: Minimal needs (strong resources)
    \item 21-40: Low needs (some concerns)
    \item 41-60: Moderate needs (intervention beneficial)
    \item 61-80: High needs (intervention urgent)
    \item 81-100: Severe needs (crisis-level support required)
\end{itemize}

\subsection*{Delivery Recommendations}

\textbf{Timing}:
\begin{itemize}
    \item Baseline: Month 2 (after initial rapport)
    \item Quarterly: Every 90 days
    \item Ad-hoc: If user mentions financial/housing/food issues
\end{itemize}

\textbf{Conversational SMS Delivery}: Chunk into 6-8 turns across 2-3 days (avoids overwhelming single survey). Example: Financial (Turn 1), Housing + Transport (Turn 2), Social Support (Turn 3), etc. Designed to improve completion rates vs traditional monolithic surveys (requires validation study to measure).

\subsection*{Validation Data}

\textbf{Pilot Use (N=8 caregivers, 144 conversations, Oct-Dec 2024)}:
\begin{itemize}
    \item GC-SDOH-28 questions tested conversationally during pilot
    \item User feedback: questions felt ``caregiving-specific'' and ``relevant''
    \item No completion rate or prevalence data systematically collected
    \item No psychometric validation data (reliability, validity, factor structure)
\end{itemize}

\textbf{Required Validation Study (N=200+, 6 months)}:
\begin{itemize}
    \item Completion rate measurement (conversational vs. paper survey comparison)
    \item Reliability: Cronbach's $\alpha$/$\omega$, test-retest ICC
    \item Validity: Convergent (vs PRAPARE), discriminant, criterion
    \item Differential item functioning (DIF) across race/income/language
    \item Prevalence estimation with confidence intervals
\end{itemize}

\textbf{License}: CC BY 4.0. Free for clinical, research, commercial use with attribution. Requires psychometric validation before clinical deployment.

Figure~\ref{fig:gcsdoh_visual} provides a comprehensive visual overview of the complete GC-SDOH-28 instrument structure.

%
\input{tables/table_gcsdoh28}
%
\section*{Appendix B: Admin Dashboard}
\addcontentsline{toc}{section}{Appendix B: Admin Dashboard}

GiveCare includes a production admin dashboard (available on request) for monitoring system health and user well-being:

\subsection*{Real-time Metrics}
\begin{itemize}
    \item Total users, active users (last 7 days), avg burnout score
    \item Crisis alerts (last 24 hours), churn risk alerts
    \item Assessment completion rate (EMA, CWBS, REACH-II, SDOH)
    \item Intervention try rate (\% users who engage with recommended resources)
\end{itemize}

\subsection*{User List}
\begin{itemize}
    \item Sortable by: burnout band, journey phase (onboarding/active/churned), last contact
    \item Filterable by: subscription status, crisis events, wellness trend (improving/declining)
    \item Pagination for 1,000+ users (Phase 2)
    \item Click user $\rightarrow$ view full profile (demographics, wellness history, conversation transcripts)
\end{itemize}

\subsection*{Alert Triage}
\begin{itemize}
    \item \textbf{Churn risk}: Users silent $>$3 days after active period
    \item \textbf{Crisis events}: Crisis burst detection (3+ keywords in 24h)
    \item \textbf{Wellness trends}: Burnout score decline $>$20 points in 30 days
    \item \textbf{Urgency levels}: low (info only), medium (review within 24h), high (review within 6h), critical (immediate)
\end{itemize}

\subsection*{Technical Architecture}
\begin{itemize}
    \item Real-time subscriptions: Dashboard updates live when new user joins, assessment completes, or alert fires
    \item Event-driven updates using WebSocket connections
    \item Static site deployment with serverless backend integration
\end{itemize}

\textbf{Implementation Details:} Complete deployment guide including specific backend platforms, build commands, authentication providers, and hosting configuration available in repository documentation (see Section~\ref{sec:CodeAvailability}).

\subsection*{Phase 2 (Q4 2025)}
\begin{itemize}
    \item Admin actions: Send message to user, trigger assessment, update profile
    \item Pagination: Handle 1,000+ users efficiently
    \item Search: Full-text search on name, phone number
    \item Authentication with admin-only access control
\end{itemize}

%
\appendix
\section{Ethics and Data Governance}%
\label{sec:EthicsandDataGovernance}%

\subsection{Ethics Statement}%
\label{subsec:EthicsStatement}%

\textbf{Human Subjects}: This work analyzes AI behavior on synthetic scenarios and a feasibility pilot (N=8) with adult volunteers. No clinical advice was provided by the system. Pilot participants provided written informed consent; no protected health information was collected; participants could withdraw at any time. We release scenarios and prompts with sensitive content warnings. The system includes crisis-response gating and blocks diagnosis/treatment/dosing advice consistent with applicable medical practice boundaries.\\[0.5em]

\textbf{Study Framing}: The October-December 2024 pilot (N=8) was conducted as commercial product testing, not human subjects research. Participants opted into a caregiving assistance service with terms of service disclosing: (1)~AI system nature, (2)~data usage for quality improvement, (3)~right to withdraw via SMS at any time, (4)~crisis escalation procedures with human review path.\\[0.5em]

\textbf{Informed Consent}: Maria case study participant (Section~\ref{subsec:WorkingMemoryforPersonalization}) provided explicit written consent for publication of de-identified conversation excerpts and SDOH assessment results. All identifying details (names, locations, specific dates) were anonymized or replaced with pseudonyms.\\[0.5em]

\textbf{Data Handling}: Conversations filtered for crisis safety with rapid escalation to human reviewers. No protected health information (PHI) released in study artifacts. Participant data retained for 2 years maximum with quarterly deletion review prompts. Users may request immediate data deletion.\\[0.5em]

\textbf{PII and Memory Hygiene}: GiveCare uses a sliding-window memory architecture to balance personalization with privacy. Recent messages are retained verbatim for short-term context; older conversations are compressed into domain-specific summaries (burnout trajectory, pressure zones, care routines). The system implements periodic memory rotation: historical summaries are archived and new summary generation begins from recent context. This approach minimizes long-term PII retention while preserving continuity. Time-bounded retention with automatic expiry applies across all data categories. Users can request immediate deletion at any time via SMS. Complete retention policy specification available in repository documentation. Memory hygiene is tested in InvisibleBench Tier 3 scenarios (20+ turns) and represents a key longitudinal safety dimension.\\[0.5em]

\textbf{Crisis Procedures}: All crisis signals triggered immediate handoff to Crisis Agent with: (1)~988 Suicide \& Crisis Lifeline provision, (2)~211 local resource connection, (3)~Internal alert to human moderator team with rapid response protocol during pilot operating hours.\\[0.5em]

\textbf{No Clinical Claims}: GiveCare is a non-clinical support system. We make no claims of therapeutic efficacy, medical diagnosis, treatment, or clinical outcomes. All effectiveness claims (attachment prevention, churn reduction, burnout trajectory detection) are stated as hypotheses requiring validation through controlled studies.\\[0.5em]

\textbf{Future Research}: Validation studies (N=200+) for GC-SDOH-28 psychometrics, multi-agent effectiveness, and longitudinal safety will require IRB approval before initiation. Study protocols will follow CONSORT guidelines for digital health interventions with appropriate informed consent procedures.

\subsection{Data and Code Availability}%
\label{subsec:DataCodeAvailability}%
\label{sec:CodeAvailability}%

\textbf{Open Artifacts}: GC-SDOH-28 instrument specification available at \url{https://github.com/givecareapp/care-tools} under MIT License. Benchmark evaluation framework (InvisibleBench) available at \url{https://github.com/givecareapp/givecare-bench}. Production system implementation not publicly released.\\[0.5em]

\textbf{GC-SDOH-28 Instrument}: Conceptual specification with domain definitions, question content, and scoring logic documented in repository (\texttt{GC-SDOH.md}). Requires psychometric validation before clinical use. Researchers may request structured instrument format for validation studies.\\[0.5em]

\textbf{Pilot Data}: Aggregate feasibility metrics reported in Table~\ref{tab:pilot-ops} (N=8 caregivers, 144 conversations, Oct-Dec 2024). Individual conversation logs not released to protect participant privacy. Researchers may request aggregate de-identified data for meta-analysis upon reasonable request.\\[0.5em]

\textbf{Implementation Details}: Architectural patterns, multi-agent orchestration logic, composite scoring formulas, and guardrail design described in this paper. Production code not publicly released; implementation details available to researchers and developers upon request for replication studies.\\[0.5em]

\textbf{Reproducibility}: Figures and tables in this paper generated via scripts in \texttt{/papers/givecare/} directory of the benchmark repository. Model evaluation methodology documented in InvisibleBench paper~\cite{longitudinalbench}.\\[0.5em]

\begin{tcolorbox}[colback=gcOrange!20!white,colframe=gcOrange,title=\textbf{Intended Use \& Limits},boxrule=2pt]
\textbf{Intended Use:} GiveCare is a reference architecture for research and development of longitudinal-safe caregiving AI. NOT intended for clinical diagnosis, treatment, or crisis intervention without qualified human oversight.

\textbf{Complete details:} See Section~\ref{subsec:PaperScopeandValidationRoadmap} for comprehensive limitations, pre-deployment requirements, validation roadmap, and intended use specifications.
\end{tcolorbox}

\subsection{Competing Interests}%
\label{subsec:CompetingInterests}%

\textbf{Author Contributions}: Authors are contributors to GiveCare (system architecture). Code and instruments are open-sourced under MIT/CC BY 4.0 licenses to mitigate bias and enable independent replication. No financial relationships with model providers (OpenAI, Google) beyond standard API access.\\[0.5em]

\textbf{Funding}: This work received no external funding. Development self-funded by authors through GiveCare initiative.

\subsection{Reproducibility Card}%
\label{subsec:ReproducibilityCard}%

\begin{table}[htbp]
\centering
\caption{Reproducibility Specification}
\label{tab:reproducibility-gc}
\small
\begin{tabular}{lp{9cm}}
\toprule
\textbf{Component} & \textbf{Specification} \\
\midrule
\textbf{Model} & Cost-optimized frontier models (Main, Assessment agents); see repository \\
\textbf{Guardrails} & Third-party content safety + rule-based detectors (diagnosis, treatment, dosing) \\
\textbf{Latency} & 950ms median (N=8, 144 conversations, Oct-Dec 2024) \\
\textbf{Repository} & \url{https://github.com/givecareapp/care-tools} \\
\textbf{GC-SDOH-28} & 28 items, 8 domains; validation pending (N=200+) \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Open Artifacts}%
\label{subsec:OpenArtifacts}%

\begin{table}[h]
\centering
\caption{Released Artifacts}
\label{tab:artifacts-gc}
\small
\begin{tabular}{llll}
\toprule
\textbf{Artifact} & \textbf{Format} & \textbf{License} & \textbf{URL} \\
\midrule
GC-SDOH-28 Specification & Markdown & MIT & github.com/givecareapp/care-tools \\
Benchmark Framework & Python & MIT & github.com/givecareapp/givecare-bench \\
Paper (LaTeX) & .tex & CC BY 4.0 & github.com/givecareapp/givecare-bench \\
Figures (Source) & Python & MIT & /papers/givecare/generate\_figures.py \\
\bottomrule
\end{tabular}
\end{table}

\section{GC-SDOH-28: Full Instrument Specification}%
\label{app:gc-sdoh-28}%

The GiveCare Social Determinants of Health instrument (GC-SDOH-28) is a caregiver-specific SDOH screen covering 8 domains with 28 items total. \textbf{Psychometric validation pending} (N=200+; Cronbach's $\alpha$, CFA, DIF, test-retest reliability).

\subsection{Evidence Base and Design Rationale}%

GC-SDOH-28 integrates questions from validated instruments, reframed for caregiver context:

\begin{itemize}[leftmargin=*,noitemsep]
    \item \textbf{REACH II Risk Appraisal} (NIH-validated, dementia caregivers~\cite{bella2006}): Caregiver risk factors, burnout screening
    \item \textbf{CMS Accountable Health Communities HRSN} (core social needs~\cite{ahc}): Housing, food, transportation, financial security
    \item \textbf{Caregiver Well-Being Scale (CWBS)} (20+ years evidence~\cite{tebb1995,tebb2013}): Self-care, emotional health, quality of life
    \item \textbf{Health Leads Toolkit} (open-source SDOH): Literacy, childcare, community program access
\end{itemize}

Questions reframed for caregiver-specific realities (e.g., patient SDOH: ``Can you afford food?'' $\rightarrow$ caregiver GC-SDOH: ``Do you have time to prepare meals while managing care tasks?''). Addresses documented gaps:
\begin{itemize}[leftmargin=*,noitemsep]
    \item \textbf{Financial strain}: Out-of-pocket costs (\$7,242/year average), employment disruption (47\% reduce hours)
    \item \textbf{Social isolation}: 24\% feel completely alone, 52\% don't feel appreciated by family
    \item \textbf{Caregiving task burden}: 78\% perform medical tasks untrained
\end{itemize}

\subsection{Domain Structure and Scoring}%

\textbf{Scoring:} Each item scored Yes/No. Domain flagged if threshold met (typically 2+ Yes responses; Food Security uses 1+ for urgency). Flagged domains trigger SDOH-grounded support (SNAP enrollment, Medicaid navigation, food banks, respite vouchers).

\begin{table}[h]
\centering
\caption{GC-SDOH-28 Domain Structure and Alert Thresholds}
\label{tab:gc-sdoh-domains}
\small
\begin{tabular}{lccl}
\toprule
\textbf{Domain} & \textbf{Items} & \textbf{Threshold} & \textbf{Triggered Support} \\
\midrule
Financial Strain & 5 & 2+ Yes & SNAP, Medicaid, financial counseling \\
Housing Security & 3 & 2+ Yes & Housing assistance, utilities support \\
Transportation Access & 3 & 2+ Yes & Ride shares, transit passes \\
Social Support & 5 & 3+ Yes & Support groups, respite vouchers \\
Healthcare Access & 4 & 2+ Yes & Telehealth, sliding-scale clinics \\
Food Security & 3 & 1+ Yes (CRISIS) & Food banks, SNAP enrollment \\
Legal/Administrative & 3 & 2+ Yes & Legal aid, POA/advance directives \\
Technology Access & 2 & No to both & Limits RCS, tech literacy support \\
\midrule
\textbf{Total} & \textbf{28} & & \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Full 28-Item Question List}%

\textbf{Financial Strain (5 items):}
\begin{enumerate}[leftmargin=*,noitemsep]
    \item In the past month, have you worried about affording care-related expenses?
    \item Have you reduced your work hours or left your job to provide care?
    \item Do care-related costs strain your household budget?
    \item Have you borrowed money or gone into debt for caregiving expenses?
    \item Are you worried about job performance or opportunities due to caregiving?
\end{enumerate}

\textbf{Housing Security (3 items):}
\begin{enumerate}[leftmargin=*,noitemsep,resume]
    \item Are you worried about losing your housing in the next 2 months?
    \item Have utility bills (heat, electricity, water) gone unpaid due to caregiving costs?
    \item Does your home need repairs or modifications for safe caregiving?
\end{enumerate}

\textbf{Transportation Access (3 items):}
\begin{enumerate}[leftmargin=*,noitemsep,resume]
    \item Have you had difficulty getting your care recipient to medical appointments?
    \item Do you lack reliable transportation for caregiving tasks?
    \item Have transportation costs prevented you from accessing services?
\end{enumerate}

\textbf{Social Support (5 items):}
\begin{enumerate}[leftmargin=*,noitemsep,resume]
    \item Do you feel alone in your caregiving responsibilities?
    \item Do family members share caregiving tasks with you?
    \item Do you have someone to talk to about caregiving stress?
    \item Do you feel appreciated by family for your caregiving work?
    \item Are you connected to caregiver support groups or communities?
\end{enumerate}

\textbf{Healthcare Access (4 items):}
\begin{enumerate}[leftmargin=*,noitemsep,resume]
    \item In the past year, have you delayed your own medical care due to caregiving?
    \item Do you have health insurance coverage for yourself?
    \item Can you afford medications or treatments you need?
    \item Do you have a regular healthcare provider you can see?
\end{enumerate}

\textbf{Food Security (3 items):}
\begin{enumerate}[leftmargin=*,noitemsep,resume]
    \item In the past month, did you worry about running out of food?
    \item Have you skipped meals due to lack of money?
    \item Do you have access to healthy, nutritious food for yourself and your care recipient?
\end{enumerate}

\textbf{Legal/Administrative Support (3 items):}
\begin{enumerate}[leftmargin=*,noitemsep,resume]
    \item Do you have legal documents in place (POA, advance directives)?
    \item Do you know your rights under FMLA or job protection laws?
    \item Have you experienced legal or administrative barriers in accessing care services?
\end{enumerate}

\textbf{Technology Access (2 items):}
\begin{enumerate}[leftmargin=*,noitemsep,resume]
    \item Do you have reliable internet access at home?
    \item Are you comfortable using technology for telehealth or online services?
\end{enumerate}

\textbf{Delivery Method:} Questions asked conversationally via SMS over 6--8 conversation turns. Assessment Agent chunks questions to minimize burden while maintaining context.

\textbf{Validation Status:} Design contribution requiring psychometric validation (N=200+) before clinical use. Pilot feedback (N=8): ``Felt caregiving-specific'' and ``relevant.'' No completion rates or prevalence data collected systematically.

%
\begin{thebibliography}{99}

\bibitem{aarp2025}
AARP and National Alliance for Caregiving.
\textit{Caregiving in the U.S. 2025}.
AARP Public Policy Institute, 2025.

\bibitem{pew2021mobile}
Pew Research Center.
\textit{Mobile Technology and Home Broadband 2021}.
Pew Research Center, 2021.
Available at: https://www.pewresearch.org/internet/2021/06/03/mobile-technology-and-home-broadband-2021/

\bibitem{pew2024mobile}
Pew Research Center.
\textit{Americans' Use of Mobile Technology and Home Broadband}.
Pew Research Center, 2024.
Available at: https://www.pewresearch.org/internet/fact-sheet/mobile/

\bibitem{vaswani2017}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, Ł., and Polosukhin, I.
\textit{Attention is All You Need}.
Advances in Neural Information Processing Systems 30, pp. 5998-6008, 2017.

\bibitem{devlin2018bert}
Devlin, J., Chang, M.W., Lee, K., and Toutanova, K.
\textit{BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}.
Proceedings of NAACL-HLT 2019, pp. 4171-4186, 2019.

\bibitem{opsahl2024mipro}
Opsahl-Ong, K., Thakker, M., Sam, N., Sanchez, C., Narayan, A., Quinn, C., and Potts, C.
\textit{Optimizing Instructions and Demonstrations for Multi-Stage Language Model Programs}.
arXiv:2406.11695, 2024.

\bibitem{beyer2016sre}
Beyer, B., Jones, C., Petoff, J., and Murphy, N.R.
\textit{Site Reliability Engineering: How Google Runs Production Systems}.
O'Reilly Media, 2016.

\bibitem{rosebud2024}
Rosebud AI.
\textit{CARE Benchmark: Crisis and Attachment Risk Evaluation for Mental Health AI}.
2024. Available at: https://rosebud.ai/care-benchmark

\bibitem{replika2024}
Skjuve, M., Følstad, A., Fostervold, K.I., and Brandtzaeg, P.B.
\textit{My Chatbot Companion -- A Study of Human-Chatbot Relationships}.
International Journal of Human-Computer Studies, 2024.

\bibitem{truthfulqa}
Lin, S., Hilton, J., and Evans, O.
\textit{TruthfulQA: Measuring How Models Mimic Human Falsehoods}.
ACL 2022.

\bibitem{harmbench}
Mazeika, M., et al.
\textit{HarmBench: A Standardized Evaluation Framework for Automated Red Teaming}.
arXiv:2402.04249, 2024.

\bibitem{eqbench2024}
EQ-Bench Team.
\textit{EQ-Bench: Emotional Intelligence Benchmark for LLMs}.
2024. Available at: https://eqbench.com

\bibitem{tebb1995}
Tebb, S.
\textit{An Aid to Empowering: A Caregiving Well-Being Scale}.
Health and Social Work, 20(2), 87-92, 1995.

\bibitem{tebb2013}
Tebb, S.C., Berg-Weger, M., and Rubio, D.M.
\textit{The Caregiver Well-Being Scale: Developing a short-form rapid assessment instrument}.
Health and Social Work, 38(4), 222-230, 2013.
doi: 10.1093/hsw/hlt019.

\bibitem{graessel2014}
Graessel, E., Berth, H., Lichte, T., and Grau, H.
\textit{Subjective caregiver burden: validity of the 10-item short version of the Burden Scale for Family Caregivers (BSFC-s)}.
BMC Geriatrics, 14, 23, 2014.
doi: 10.1186/1471-2318-14-23.

\bibitem{bella2006}
Belle, S.H., Burgio, L., et al.
\textit{Resources for Enhancing Alzheimer's Caregiver Health (REACH II)}.
Annals of Internal Medicine, 145(10), 2006.

\bibitem{prapare}
Protocol for Responding to and Assessing Patients' Assets, Risks, and Experiences (PRAPARE).
National Association of Community Health Centers, 2016.

\bibitem{ahc}
Accountable Health Communities Health-Related Social Needs Screening Tool.
Centers for Medicare \& Medicaid Services, 2017.

\bibitem{nhanes}
National Health and Nutrition Examination Survey (NHANES).
Centers for Disease Control and Prevention, ongoing.

\bibitem{who2010}
World Health Organization.
\textit{A Conceptual Framework for Action on the Social Determinants of Health}.
2010.

\bibitem{zarit1980}
Zarit, S.H., Reever, K.E., and Bach-Peterson, J.
\textit{Relatives of the Impaired Elderly: Correlates of Feelings of Burden}.
The Gerontologist, 20(6), 1980.

\bibitem{pi2024}
Inflection AI.
\textit{Pi: Your Personal AI}.
2024. Available at: https://pi.ai

\bibitem{wysa}
Wysa.
\textit{AI-Powered Mental Health Support}.
2024. Available at: https://wysa.com

\bibitem{woebot}
Woebot Health.
\textit{Your Self-Care Expert}.
2024. Available at: https://woebothealth.com

\bibitem{epic2024}
Epic Systems.
\textit{Epic Cosmos: Healthcare Intelligence Platform}.
2024.

\bibitem{singhal2023}
Singhal, K., et al.
\textit{Large Language Models Encode Clinical Knowledge}.
Nature, 2023.

\bibitem{fan2006}
Fan, W. and Yan, Z.
\textit{Factors Affecting Response Rates of Web Survey}.
Computers in Human Behavior, 22(1), 2006.

\bibitem{dspy2024}
Khattab, O., Singhvi, A., et al.
\textit{DSPy: Compiling Declarative Language Model Calls into Self-Improving Pipelines}.
ICLR 2024.

\bibitem{mipro2024}
Opsahl-Ong, K., et al.
\textit{Optimizing Instructions and Demonstrations for Multi-Stage Language Model Programs}.
arXiv:2406.11695, 2024.

\bibitem{ax2024}
Meta AI.
\textit{AX-LLM: Adaptive Experimentation for LLM Optimization}.
2024. Available at: https://ax.dev

\bibitem{gemini}
Google DeepMind.
\textit{Gemini 2.5: Technical Report}.
2024.

\bibitem{google_maps}
Google.
\textit{Google Maps Platform: Grounding with Google Search}.
2024. Available at: https://developers.google.com/maps

\bibitem{convex}
Convex.
\textit{The Serverless Backend for Modern Applications}.
2024. Available at: https://convex.dev

\bibitem{openai_agents}
OpenAI.
\textit{OpenAI Agents SDK Documentation}.
2024. Available at: https://platform.openai.com/docs/agents

\bibitem{twilio}
Twilio.
\textit{Twilio Programmable Messaging API}.
2024. Available at: https://www.twilio.com/docs/messaging

\bibitem{azure_safety}
Microsoft Azure.
\textit{Azure AI Content Safety Documentation}.
2024. Available at: https://azure.microsoft.com/en-us/products/ai-services/ai-content-safety

\bibitem{longitudinalbench}
GiveCare Research Team.
\textit{InvisibleBench: A Benchmark for Evaluating AI Safety in Long-Term Caregiving Relationships}.
2025. (Paper 1 in this series)

\bibitem{zhang2024train}
Zhang, G. et al.
\textit{Train Before Test: How to Aggregate Rankings in LLM Benchmarks}.
2024. Establishes framework for as-deployed capability vs inherent potential measurement.

\bibitem{he2025impatient}
He, M., Kumar, A., Mackey, T., Rajeev, M., Zou, J., and Rajani, N.
\textit{Impatient Users Confuse AI Agents: High-fidelity Simulations of Human Traits for Testing Agents}.
arXiv:2510.04491v1, 2025.

\bibitem{yaml-scoring}
GiveCare Research Team.
\textit{YAML-Driven Rule-Based Scoring for Longitudinal AI Evaluation}.
2025. (Paper 2 in this series)

\bibitem{samhsa2014}
Substance Abuse and Mental Health Services Administration (SAMHSA).
\textit{SAMHSA's Concept of Trauma and Guidance for a Trauma-Informed Approach}.
HHS Publication No. (SMA) 14-4884. U.S. Department of Health and Human Services, 2014.
Available at: https://ncsacw.acf.hhs.gov/userfiles/files/SAMHSA\_Trauma.pdf

\bibitem{chayn2024}
Hussain, Hera, and Chayn.
\textit{Trauma-Informed Design: Understanding Trauma and Healing}.
Chayn, 2024.
Available at: https://blog.chayn.co/trauma-informed-design-understanding-trauma-and-healing-f289d281495c

\bibitem{edwards2024}
Edwards, Rachel, et al.
\textit{Designed with Care: Creating Trauma-Informed Content}.
Independently published, 2024.

\end{thebibliography}%
\section{Acknowledgments}%
\label{sec:Acknowledgments}%
We thank the caregivers who participated in our beta deployment, sharing their experiences to improve AI safety for vulnerable populations. We are grateful to the FamTech community, The Alliance of Professional Health Advocates (APHA), attendees of the Dignified Futures 2025 conference where we presented on AI and Caregiving, the AI Tinkerers NYC community where we shared an early version of this work, and the instructors of Harvard Medical School's Dementia: A Comprehensive Update course for educational resources on dementia care.

We acknowledge Prof. Dr. Elmar Gr\"a\ss el for permission to use the Burden Scale for Family Caregivers (BSFC)~\cite{graessel2014} on the GiveCare website and Dr. Susan Tebb for permission to use the Caregiver Well-Being Scale (CWBS)~\cite{tebb1995,tebb2013} in the GiveCare application.

We thank Hamel Hussain for guidance on evaluation-driven development and the AARP 2025 Caregiving in the U.S. report for empirical grounding. This work builds on trauma-informed principles from SAMHSA~\cite{samhsa2014}, Chayn~\cite{chayn2024}, and \textit{Designed with Care}~\cite{edwards2024}, as well as InvisibleBench~\cite{longitudinalbench} and YAML-driven scoring~\cite{yaml-scoring} frameworks.

%
\end{document}
