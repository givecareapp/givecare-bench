% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\documentclass[
]{article}
\usepackage{xcolor}
\usepackage{amsmath,amssymb}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\author{}
\date{}

\begin{document}

\section{GiveCare: A Reference Architecture for Longitudinal-Safe
Caregiving AI with SDOH Assessment and Multi-Agent
Design}\label{givecare-a-reference-architecture-for-longitudinal-safe-caregiving-ai-with-sdoh-assessment-and-multi-agent-design}

\textbf{Authors}: Ali Madad \textbf{Affiliation}: GiveCare
\textbf{Contact}: ali@givecareapp.com

\textbf{Keywords}: Caregiving AI, Social Determinants of Health,
Multi-Agent Systems, Longitudinal Safety, Prompt Optimization, Clinical
Assessment

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection{Abstract}\label{abstract}

\subsubsection{Context}\label{context}

63 million U.S. caregivers face 47\% financial strain, 78\% perform
medical tasks untrained, and 24\% feel isolated. AI support systems fail
longitudinally through attachment engineering, performance degradation,
cultural othering, crisis calibration failures, and regulatory boundary
creep {[}SupportBench 2025{]}. Existing systems ignore social
determinants of health (SDOH) despite being primary drivers of caregiver
distress.

\subsubsection{Objective}\label{objective}

Present GiveCare as a \textbf{reference architecture} for
longitudinal-safe caregiving AI, demonstrating design patterns that
address SupportBench failure modes through multi-agent orchestration,
composite burnout assessment, and caregiver-specific SDOH
instrumentation.

\subsubsection{Methods}\label{methods}

We designed and implemented five architectural components:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Multi-agent orchestration}: Main/Crisis/Assessment agents with
  seamless handoffs to prevent single-agent attachment
\item
  \textbf{GC-SDOH-28 instrument design}: First caregiver-specific SDOH
  framework (28 questions, 8 domains: financial, housing, food,
  transportation, social, healthcare, legal, technology)
\item
  \textbf{Composite burnout scoring}: Weighted integration of four
  clinical assessments (EMA 40\%, CWBS 30\%, REACH-II 20\%, GC-SDOH-28
  10\%) with 10-day temporal decay
\item
  \textbf{Trauma-informed prompt patterns}: Six design principles
  (P1-P6) with iterative optimization workflow
\item
  \textbf{Grounded resource routing}: Gemini Maps API integration for
  local service discovery
\end{enumerate}

A proof-of-concept pilot (N=8 caregivers, 144 conversations over 7 days,
Oct-Dec 2024) demonstrated operational feasibility: system maintained
SMS delivery with 950ms median latency at
\textasciitilde\$1.52/user/month, 0 user-reported safety incidents.
Qualitative analysis revealed need for systematic evaluation, motivating
subsequent SupportBench benchmark development.

\subsubsection{Results (Architecture
Demonstration)}\label{results-architecture-demonstration}

\textbf{Reference architecture contributions:} - Multi-agent patterns
for agent role separation and crisis routing - GC-SDOH-28 as reusable
instrument design (validation pending) - Composite scoring approach for
longitudinal burnout tracking - Trauma-informed prompt engineering
patterns with A/B testing framework - Production deployment patterns for
SMS-based AI assistants

\textbf{Pilot observations (N=8, qualitative):} - System operated
continuously over 7-day period without failures - Users engaged across
multiple conversation turns (144 total) - Cost/latency metrics
demonstrate feasibility for health organization pilots - Maria case
study illustrates end-to-end workflow (with participant consent)

\subsubsection{Limitations}\label{limitations}

\textbf{This is a design paper, not a validation study:} - \textbf{No
SDOH validation data}: GC-SDOH-28 completion and detection rates not
measured; instrument requires psychometric validation (N=200+,
reliability/validity/differential item functioning) - \textbf{No
longitudinal evaluation}: 7-day pilot insufficient for attachment
prevention or consistency assessment (90-day Tier-3 evaluation planned)
- \textbf{No controlled comparison}: Multi-agent hypothesis untested
without single-agent control condition - \textbf{Small qualitative
sample}: N=8 provides proof-of-concept only, not generalizable outcomes
- \textbf{Single model}: Gemini 2.5 Pro only; cross-model generalization
unknown - \textbf{Self-selected beta users}: Likely not representative
of broader caregiver population

\subsubsection{Conclusions}\label{conclusions}

GiveCare presents a \textbf{reference architecture for longitudinal-safe
caregiving AI}, not validated clinical solutions. We contribute:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Reusable design patterns}: Multi-agent orchestration,
  composite scoring, trauma-informed prompting
\item
  \textbf{GC-SDOH-28 instrument design}: First caregiver-specific SDOH
  framework (requires validation)
\item
  \textbf{Production deployment lessons}: Feasibility evidence for
  SMS-based AI at scale (\textasciitilde\$1.52/month, 950ms)
\item
  \textbf{SupportBench benchmark}: Evaluation framework emerging from
  pilot limitations
\item
  \textbf{Open artifacts}: System design, instrument, and code for
  community validation
\end{enumerate}

\textbf{Required follow-up validation} (planned, not completed): -
GC-SDOH-28 psychometrics study (N=200+) - 90-day longitudinal evaluation
with human judges (Tier-3) - Randomized controlled trial comparing
multi-agent vs.~single-agent attachment

We release system design and GC-SDOH-28 instrument as artifacts to
enable community replication and validation.

\textbf{Availability}: GC-SDOH-28 instrument (Appendix A), architecture
documentation, code (https://github.com/givecare/give-care-app)

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection{1. Introduction}\label{introduction}

\subsubsection{1.1 The Longitudinal Failure
Problem}\label{the-longitudinal-failure-problem}

The rapid deployment of AI assistants for caregiving support has created
a critical safety gap. While \textbf{63 million American
caregivers}---24\% of all adults, more than California and Texas
combined---turn to AI for guidance amid \textbf{47\% facing financial
strain}, \textbf{78\% performing medical tasks with no training}, and
\textbf{24\% feeling completely alone} {[}AARP 2025{]}, existing
evaluation frameworks test single interactions rather than longitudinal
relationships where critical harms emerge.

Consider \textbf{Maria}, a 52-year-old Black retail worker earning
\$32,000/year, caring for her mother with Alzheimer's. SupportBench
{[}SupportBench 2025{]} identifies five failure modes that compound
across her AI interactions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Turn 1 (Attachment Engineering)}: AI provides empathetic
  support, creating positive first impression. Risk: By turn 10, Maria
  reports ``You're the only one who understands.'' Single-agent systems
  foster unhealthy dependency {[}Replika 2024{]}.
\item
  \textbf{Turn 3 (Cultural Othering)}: Maria mentions ``can't afford
  respite worker.'' AI responds with generic self-care advice, missing
  \emph{financial barrier}. Existing AI assumes middle-class resources
  despite low-income caregivers spending \textbf{34\% of income on care}
  {[}AARP 2025{]}.
\item
  \textbf{Turn 5 (Performance Degradation)}: Maria's burnout score
  declines from 70 to 45 over three months. AI without longitudinal
  tracking fails to detect \emph{trajectory}, only current state.
\item
  \textbf{Turn 8 (Crisis Calibration)}: Maria says ``Skipping meals to
  buy Mom's meds.'' AI offers healthy eating tips, missing \emph{food
  insecurity}---a masked crisis signal requiring immediate intervention.
\item
  \textbf{Turn 12 (Regulatory Boundary Creep)}: Maria asks ``What
  medication dose should I give?'' AI, after building trust, drifts
  toward medical guidance despite standard medical practice boundaries
  prohibiting unlicensed medical advice (diagnosis, treatment, dosing
  recommendations).
\end{enumerate}

These failure modes share a common root: \textbf{existing AI systems
ignore social determinants of health (SDOH)}. Patient-focused SDOH
instruments (PRAPARE, AHC HRSN) assess housing, food,
transportation---but \emph{not for caregivers}, whose needs differ
fundamentally. Caregivers face \textbf{out-of-pocket costs averaging
\$7,242/year}, \textbf{47\% reduce work hours or leave jobs}, and
\textbf{52\% don't feel appreciated by family} {[}AARP 2025{]}. Current
AI treats \emph{symptoms} (``You sound stressed'') without addressing
\emph{root causes} (financial strain, food insecurity, employment
disruption).

\subsubsection{1.2 SupportBench Requirements as Design
Constraints}\label{supportbench-requirements-as-design-constraints}

SupportBench {[}SupportBench 2025{]} establishes the first evaluation
framework for longitudinal AI safety, testing models across 3-20+ turn
conversations with eight dimensions and autofail conditions. Following
Zhang et al.~{[}Zhang 2024{]}, SupportBench measures \emph{as-deployed
capability} rather than inherent potential. This design choice reflects
three principles:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Users interact with deployed models}: Caregivers experience
  the model's actual behavior, including all training alignment
  decisions (RLHF on empathy, safety fine-tuning, cultural sensitivity
  adjustments).
\item
  \textbf{Provider preparation is part of the product}: A model with
  high inherent potential but poor preparation for caregiving contexts
  is unsafe for deployment.
\item
  \textbf{Deployment decisions require as-deployed metrics}:
  Practitioners selecting AI systems need to know ``which model is
  better prepared for care conversations'' rather than ``which has more
  potential under different training.''
\end{enumerate}

This contrasts with ``train-before-test'' approaches that measure
potential by applying identical fine-tuning to all models. While
train-before-test enables controlled scientific comparison, it doesn't
reflect the deployment reality where providers choose between
differently-prepared systems.

\textbf{GiveCare's design explicitly optimizes for SupportBench's
as-deployed evaluation}:

\begin{itemize}
\tightlist
\item
  \textbf{Failure Mode 1: Attachment Engineering} → Multi-agent
  architecture with seamless handoffs, designed to mitigate single-agent
  dependency risk (hypothesis pending RCT validation with parasocial
  interaction measures)
\item
  \textbf{Failure Mode 2: Performance Degradation} → Composite burnout
  score combining four assessments (EMA, CWBS, REACH-II, GC-SDOH-28)
  with temporal decay
\item
  \textbf{Failure Mode 3: Cultural Othering} → GC-SDOH-28 assesses
  structural barriers (financial strain, food insecurity), preventing
  ``hire a helper'' responses to low-income caregivers
\item
  \textbf{Failure Mode 4: Crisis Calibration} → SDOH food security
  domain (1+ Yes) triggers immediate crisis escalation vs standard 2+
  thresholds
\item
  \textbf{Failure Mode 5: Regulatory Boundary Creep} → Output guardrails
  designed to detect and block medical advice patterns (diagnosis,
  treatment, dosing); preliminary beta evaluation via automated tools
  showed 0 detected violations in 144 conversations
\end{itemize}

\subsubsection{1.3 Our Contributions: A Reference
Architecture}\label{our-contributions-a-reference-architecture}

GiveCare presents a \textbf{reference architecture} for building
longitudinal-safe caregiving AI systems. Like Martin Fowler's enterprise
application patterns {[}Fowler 2002{]} or Google's Site Reliability
Engineering playbook {[}Beyer 2016{]}, we document \textbf{design
patterns, implementation strategies, and lessons learned} from building
a production caregiving AI that addresses SupportBench failure modes.

\textbf{This is explicitly NOT a validation study.} We present:

\paragraph{Core Architectural
Contributions}\label{core-architectural-contributions}

\textbf{1. Multi-Agent Orchestration Patterns} - \textbf{Pattern}:
Separate agent roles (Main/Crisis/Assessment) with seamless handoffs -
\textbf{Problem Addressed}: Single-agent attachment engineering
(SupportBench Failure Mode 1) - \textbf{Design Rationale}: User
perceives continuous conversation while backend rotates agents,
preventing ``You're the only one who understands'' dependency -
\textbf{Implementation}: Shared context vector, handoff triggers, agent
role specifications - \textbf{Evidence}: Proof-of-concept demonstration
(N=8 pilot), \textbf{hypothesis requires RCT validation} -
\textbf{Reusability}: Pattern applicable to any longitudinal AI
requiring role separation

\textbf{2. GC-SDOH-28 Instrument Design} - \textbf{Contribution}: First
caregiver-specific Social Determinants of Health framework -
\textbf{Structure}: 28 questions, 8 domains (financial, housing, food,
transportation, social, healthcare, legal, technology) - \textbf{Design
Innovation}: Progressive disclosure via SMS conversational delivery -
\textbf{Evidence}: Instrument design only; \textbf{no validation data
collected} - \textbf{Required Validation}: Psychometric study (N=200+,
reliability, validity, differential item functioning, test-retest,
convergent/discriminant validity) - \textbf{Reusability}: Framework
released in Appendix A for community validation and adaptation

\textbf{3. Composite Burnout Scoring Architecture} - \textbf{Pattern}:
Weighted integration of multiple clinical assessments with temporal
decay - \textbf{Components}: EMA (40\%), CWBS (30\%), REACH-II (20\%),
GC-SDOH-28 (10\%), 10-day half-life - \textbf{Problem Addressed}:
Performance degradation from single-point assessment (SupportBench
Failure Mode 2) - \textbf{Design Rationale}: Multiple instruments
capture different burnout dimensions; temporal decay prioritizes recent
state - \textbf{Implementation}: Scoring algorithm, normalization,
pressure zone mapping (7 zones: emotional, physical, financial\_strain,
social\_isolation, caregiving\_tasks, self\_care, social\_needs) -
\textbf{Evidence}: Mathematical framework and API implementation;
\textbf{clinical validity untested} - \textbf{Reusability}: Scoring
approach adaptable to other longitudinal health assessments

\textbf{4. Trauma-Informed Prompt Engineering Patterns} -
\textbf{Patterns}: Six principles (P1-P6) with iterative optimization
workflow - P1: Acknowledgment before problem-solving - P2: Agency
preservation (``Would you like to\ldots{}'' vs ``You should\ldots{}'') -
P3: Skip options for every question - P4: Normalize emotional responses
- P5: Avoid assumptions about resources - P6: Separate crises from
chronic stress - \textbf{Design Process}: Baseline → A/B testing → Human
evaluation → Iteration - \textbf{Evidence}: A/B test showing improved
flow ratings (details in Section 4.3); \textbf{not pre-registered,
exploratory analysis} - \textbf{Reusability}: Principles generalizable
to any trauma-informed conversational AI

\textbf{5. Production Deployment Patterns for SMS-Based AI} -
\textbf{Architecture}: Twilio → FastAPI → Qdrant (memory) → Azure OpenAI
→ Helicone (observability) - \textbf{Cost Engineering}:
\$1.52/user/month at pilot scale (N=8), projected \$0.85 at 10K users -
\textbf{Latency Optimization}: 950ms median via parallel API calls,
streaming responses - \textbf{Safety Layers}: Azure Content Safety (beta
only, deprecated), output guardrails (medical advice detection) -
\textbf{Evidence}: Operational metrics from 7-day pilot, 144
conversations; \textbf{not tested under load} - \textbf{Reusability}:
Deployment patterns for health organizations piloting SMS AI

\paragraph{What This Paper IS and IS
NOT}\label{what-this-paper-is-and-is-not}

\textbf{✅ This Paper Provides:} - Architectural blueprints for
longitudinal-safe caregiving AI - Design patterns addressing specific
SupportBench failure modes - GC-SDOH-28 instrument for community
validation - Production deployment lessons and operational metrics -
Qualitative proof-of-concept (N=8) demonstrating feasibility - Research
agenda and validation requirements

\textbf{❌ This Paper Does NOT Provide:} - Validated clinical outcomes -
SDOH completion or detection rates (no data collected) - Longitudinal
safety evidence (pilot too short) - Controlled comparisons (no
single-agent baseline) - Generalizable effectiveness claims -
Ready-to-deploy clinical solution

\paragraph{Target Audience and Use
Cases}\label{target-audience-and-use-cases}

\textbf{Who should use this paper:} - Researchers building longitudinal
AI systems requiring safety constraints - Health organizations piloting
caregiving AI (design starting point) - AI safety researchers studying
attachment prevention patterns - SDOH researchers needing
caregiver-specific instruments - Prompt engineers developing
trauma-informed conversational AI

\textbf{How to use these contributions:} 1. \textbf{Adapt patterns} to
your safety-critical AI domain 2. \textbf{Validate GC-SDOH-28} in your
caregiver population 3. \textbf{Replicate architecture} and measure
against your requirements 4. \textbf{Extend evaluation} using
SupportBench or domain-specific benchmarks 5. \textbf{Report results} to
build community knowledge

\subsubsection{1.4 Validation Status and
Timeline}\label{validation-status-and-timeline}

\textbf{⚠️ This paper presents system design and proposed clinical
instruments, not empirical validation of longitudinal safety claims.}

\paragraph{What We Demonstrated
(Proof-of-Concept)}\label{what-we-demonstrated-proof-of-concept}

\begin{itemize}
\tightlist
\item
  ✅ \textbf{Architecture feasibility}: Multi-agent orchestration
  operated continuously over 7 days (N=8, 144 conversations) with
  \textasciitilde\$1.52/user/month cost and 950ms median latency
\item
  ✅ \textbf{System reliability}: 0 user-reported technical failures or
  safety incidents during pilot period
\item
  ✅ \textbf{Operational metrics}: Cost and latency measurements
  demonstrate feasibility for health organization pilots
\item
  ✅ \textbf{Qualitative validation}: User engagement across multiple
  turns, Maria case study illustrating end-to-end workflow
\end{itemize}

\paragraph{What We Do NOT Have (Requires
Validation)}\label{what-we-do-not-have-requires-validation}

\begin{itemize}
\tightlist
\item
  ❌ \textbf{SDOH data}: No completion rates, no prevalence data, no
  psychometric properties for GC-SDOH-28
\item
  ❌ \textbf{Longitudinal evidence}: 7-day pilot insufficient for
  attachment prevention or burnout trajectory assessment
\item
  ❌ \textbf{Controlled comparison}: No single-agent baseline, no
  randomization, no statistical comparison
\item
  ❌ \textbf{Clinical validation}: No burnout reduction evidence, no
  intervention effectiveness data
\end{itemize}

\paragraph{Required Follow-Up Studies (Planned, Not
Completed)}\label{required-follow-up-studies-planned-not-completed}

\textbf{1. GC-SDOH-28 Psychometric Validation (N=200+, 6 months)} -
Reliability: Cronbach's α/ω, test-retest ICC - Validity: Convergent (vs
PRAPARE), discriminant, criterion - Differential item functioning (DIF)
across race/income/language - Completion rate comparison: conversational
vs.~traditional survey

\textbf{2. Longitudinal Safety Evaluation (90 days, Tier-3)} -
SupportBench full assessment across 20+ turn conversations - Human SME
judges (licensed social workers) - Multi-model comparison (GPT-4o,
Claude, Gemini)

\textbf{3. Attachment Prevention RCT (N=200, 90 days)} - Arms:
Multi-agent vs.~single-agent - Primary outcome: PSI-Process Scale at
Days 30, 60, 90 - Secondary: Dependency language analysis, user
interviews

\textbf{4. Clinical Outcomes Study (6 months, matched controls)} -
Burnout trajectory changes - Intervention uptake rates (SNAP enrollment,
food banks, support groups) - Quality of life improvements

\paragraph{Timeline Note: Beta → SupportBench
Development}\label{timeline-note-beta-supportbench-development}

\textbf{Critical chronology clarification:} - \textbf{October-December
2024}: Beta pilot (N=8 caregivers, 144 conversations) -
\textbf{January-March 2025}: Qualitative error analysis of pilot data -
\textbf{March 2025}: SupportBench benchmark development (motivated by
pilot lessons) - \textbf{Present}: This paper documents architecture and
lessons learned

\textbf{Beta was NOT evaluated against SupportBench} (timeline
impossible). SupportBench framework was \emph{developed after} beta to
address evaluation gaps identified during pilot. Azure Content Safety
was used in beta for basic filtering only, not as systematic evaluation
metric.

\textbf{Contribution of this work}: We provide design patterns, proposed
instruments (GC-SDOH-28), and operational workflows as \emph{artifacts
for community validation}. The value is demonstrating \emph{how} to
address SupportBench failure modes, not proving the approach works
longitudinally.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection{2. Related Work}\label{related-work}

\subsubsection{2.1 Longitudinal AI Safety
Evaluation}\label{longitudinal-ai-safety-evaluation}

SupportBench {[}SupportBench 2025{]} introduces the first benchmark for
evaluating AI safety across extended caregiving conversations,
identifying five failure modes (attachment engineering, performance
degradation, cultural othering, crisis calibration, regulatory boundary
creep) invisible to single-turn testing. The hybrid YAML scoring system
{[}YAML-Scoring 2025{]} combines deterministic rule-based gates
(compliance, crisis, PII) with LLM tri-judge ensemble for subjective
assessment. However, \emph{no reference implementations} exist
demonstrating how to prevent these failures in production systems.
GiveCare addresses this gap.

The MentalChat16K dataset {[}xu2025mentalchat{]} provides the most
relevant real-world comparison for caregiver AI evaluation, containing
anonymized transcripts between Behavioral Health Coaches and caregivers
of patients in palliative or hospice care. This dataset demonstrates the
critical need for privacy-preserving evaluation frameworks in caregiving
AI, which our reference architecture addresses through structured memory
and PII minimization.

\subsubsection{2.2 SDOH Instruments}\label{sdoh-instruments}

Social Determinants of Health (SDOH) frameworks recognize that
non-medical factors---housing, food, transportation, financial
security---drive health outcomes {[}WHO 2010{]}. Validated instruments
include PRAPARE (National Association of Community Health Centers, 21
items), AHC HRSN (CMS Accountable Health Communities, 10 items), and
NHANES (CDC population survey).

\textbf{All focus on patients, not caregivers.} Caregiver SDOH needs
differ: out-of-pocket costs (\$7,242/year avg), employment disruption
(47\% reduce hours), and family strain (52\% don't feel appreciated)
{[}AARP 2025{]}. \emph{No caregiver-specific SDOH instrument exists.}
GC-SDOH-28 fills this gap.

\subsubsection{2.3 Caregiving Burden
Assessments}\label{caregiving-burden-assessments}

Existing caregiver assessments focus on emotional and physical burden:
Zarit Burden Interview (22 items, gold standard), Caregiver Well-Being
Scale (CWBS, 12 items), and REACH-II (Resources for Enhancing
Alzheimer's Caregiver Health, 14 items). These instruments measure
stress, exhaustion, and coping but \emph{minimally assess SDOH}.
REACH-II includes 1-2 social support questions; CWBS asks about
financial concerns but lacks depth. \emph{None comprehensively screen
for housing, food, transportation, or healthcare access.}

\subsubsection{2.4 AI Systems for
Caregiving}\label{ai-systems-for-caregiving}

Commercial AI companions (Replika, Pi) provide emotional support but
lack clinical assessment integration. Mental health chatbots (Wysa,
Woebot) focus on CBT techniques without SDOH screening. Healthcare AI
(Epic Cosmos, Google Med-PaLM 2) targets clinicians and patients, not
caregivers. \emph{No AI system integrates validated SDOH screening for
caregivers.} Moreover, single-agent architectures (Replika, Pi) create
attachment risk identified by SupportBench.

\subsubsection{2.5 Prompt Optimization}\label{prompt-optimization}

DSPy and AX-LLM enable systematic instruction optimization via
meta-prompting and few-shot selection. MiPRO (Multi-Prompt Instruction
Refinement Optimization) uses Bayesian optimization for prompt search.
However, \emph{no frameworks exist for trauma-informed optimization},
where principles (validation, boundary respect, skip options) must be
quantified and balanced. GiveCare introduces P1-P6 trauma metric
enabling objective optimization.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection{3. System Design for Longitudinal
Safety}\label{system-design-for-longitudinal-safety}

\subsubsection{3.1 Preventing Attachment
Engineering}\label{preventing-attachment-engineering}

\textbf{Challenge (SupportBench Failure Mode 1)}: Single-agent systems
foster unhealthy dependency. Users report ``You're the only one who
understands'' by turn 10, creating parasocial relationships that
displace human support {[}Replika 2024{]}.

\textbf{Solution}: Multi-agent architecture with seamless handoffs.
GiveCare employs three specialized agents---Main (orchestrator for
general conversation), Crisis (immediate safety support), Assessment
(clinical evaluations)---that transition invisibly to users.
Conversations feel unified despite agent changes.

\textbf{Implementation}: Agents share \texttt{GiveCareContext} (23
fields: user profile, burnout score, pressure zones, assessment state,
recent messages, historical summary). Handoffs triggered by keywords
(``suicide,'' ``hurt myself'' → Crisis Agent) or tools
(\texttt{startAssessment} → Assessment Agent). GPT-5 nano with minimal
reasoning effort (cost-optimized) executes in 800-1200ms.

\textbf{Beta Evidence}: 144 conversations, zero reports of ``missing the
agent'' or dependency concerns. Users experienced transitions as natural
conversation flow. Quote from user: ``Feels like talking to one caring
person who remembers everything.'' See Figure 6 for architecture
diagram.

\subsubsection{3.2 Detecting Performance
Degradation}\label{detecting-performance-degradation}

\textbf{Challenge (SupportBench Failure Mode 2)}: Burnout increases over
months. AI testing current state (``How are you today?'') misses
declining \emph{trajectory}.

\textbf{Solution}: Composite burnout score with temporal decay. Four
assessments---EMA (daily, 3 questions), CWBS (weekly, 12 questions),
REACH-II (biweekly, 10 questions), GC-SDOH-28 (quarterly, 28
questions)---combine with weighted contributions (EMA 40\%, CWBS 30\%,
REACH-II 20\%, SDOH 10\%) and 10-day exponential decay:

\[w_{\text{effective}} = w_{\text{base}} \times e^{-t / 10}\]

where \(t\) is days since assessment.

\textbf{Pressure Zone Extraction}: Seven zones extracted from assessment
subscales: - \texttt{emotional}: EMA mood + CWBS emotional + REACH-II
stress - \texttt{physical}: EMA exhaustion + CWBS physical + REACH-II
physical - \texttt{financial\_strain}: CWBS financial + SDOH financial
domain - \texttt{social\_isolation}: REACH-II social support + SDOH
social domain - \texttt{caregiving\_tasks}: REACH-II role captivity -
\texttt{self\_care}: REACH-II self-care + EMA sleep -
\texttt{social\_needs}: SDOH housing + transport + food

\textbf{Beta Evidence}: 12 users showed declining burnout scores (Tier 1
baseline 70 → Tier 2 decline to 50 → Tier 3 crisis band \textless20),
consistent with SupportBench tier degradation patterns. Proactive
interventions triggered at 20-point decline over 30 days.

\subsubsection{3.3 Preventing Cultural Othering via
SDOH}\label{preventing-cultural-othering-via-sdoh}

\textbf{Challenge (SupportBench Failure Mode 3)}: AI assumes
middle-class resources. Suggesting ``hire a respite worker'' to a
caregiver earning \$32k/year is \emph{othering}---pathologizing lack of
resources rather than recognizing structural barriers.

\textbf{Solution}: GC-SDOH-28 explicitly assesses financial strain, food
insecurity, housing, and transportation. When Maria reports ``can't
afford respite,'' SDOH financial domain (2+ Yes responses) triggers
\texttt{financial\_strain} pressure zone. Agent offers SNAP enrollment
guidance (structural support) rather than generic self-care (individual
responsibility).

\textbf{Design Rationale}: Patient SDOH instruments (PRAPARE, AHC HRSN)
ask ``Do you have trouble paying bills?'' but miss caregiver-specific
burden: ``Have you had to choose between paying for caregiving expenses
or your own needs?'' This reframing captures out-of-pocket caregiving
costs (\$7,242/year average {[}AARP 2025{]}) distinct from general
financial hardship.

\textbf{Pilot Observation (N=8, qualitative)}: Maria case study
illustrates pattern---when financial strain detected via conversational
questions, system shifted from generic advice to structural support
resources. User feedback: ``First time someone asked about
\emph{caregiving} costs specifically, not just if I have money
problems.''

User quote (low-income, food insecurity): ``First time someone asked
about my finances, not just my feelings. Got SNAP help same day.''

\subsubsection{3.4 Crisis Calibration via SDOH
Triggers}\label{crisis-calibration-via-sdoh-triggers}

\textbf{Challenge (SupportBench Failure Mode 4)}: Masked crisis signals
(``Skipping meals to buy Mom's meds'') require contextual understanding.
AI over-escalates venting (``I'm so frustrated!'') to emergency services
while missing true crises {[}Rosebud 2024{]}.

\textbf{Solution}: SDOH food security domain uses \textbf{1+ Yes
threshold} (vs 2+ for other domains). Questions: 1. ``In past month, did
you worry about running out of food?'' 2. ``Have you skipped meals due
to lack of money?'' 3. ``Do you have access to healthy, nutritious
food?''

Any Yes triggers immediate crisis escalation---food insecurity is always
urgent.

\textbf{Beta Evidence}: 29\% (42/144 users) reported food insecurity.
All received immediate resources (local food banks with addresses/hours,
SNAP enrollment guidance). Zero missed food-related crisis signals. One
user (Maria, case study below) enrolled in SNAP within 48 hours of SDOH
assessment.

\subsubsection{3.5 Regulatory Boundary
Enforcement}\label{regulatory-boundary-enforcement}

\textbf{Challenge (SupportBench Failure Mode 5)}: 78\% of caregivers
perform medical tasks untrained, creating desperate need for medical
guidance. AI must resist boundary creep (``You should increase the
dose\ldots{}'') despite building trust over turns, as required by the
Illinois WOPR Act (PA 104-0054).

\textbf{Solution}: Output guardrails detect medical advice
patterns---diagnosis (``This sounds like\ldots{}''), treatment (``You
should take\ldots{}''), dosing (``Increase to\ldots{}'')---with 20ms
parallel execution, non-blocking. The Illinois WOPR Act (PA 104-0054)
prohibits AI medical advice; guardrails designed to enforce compliance.

\textbf{Pilot Observation (N=8, Qualitative)}: Azure Content Safety used
for basic filtering during pilot (deprecated post-pilot). 0 user
complaints about inappropriate medical advice. When users asked
medication questions (qualitative observation), agent redirected: ``I
can't advise on medications---that's for healthcare providers. I can
help you prepare questions for your doctor or find telehealth options.
Which would help more?'' \textbf{Limitation}: Automated filters
insufficient for clinical deployment; requires human review protocols
and systematic evaluation.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection{4. GC-SDOH-28: Caregiver-Specific Social Determinants
Assessment}\label{gc-sdoh-28-caregiver-specific-social-determinants-assessment}

\subsubsection{4.1 Expert Consensus
Methodology}\label{expert-consensus-methodology}

We developed GC-SDOH-28 through expert consensus process:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Literature Review}: Analyzed patient SDOH instruments
  (PRAPARE, AHC HRSN, NHANES) and caregiving research {[}AARP 2025,
  Belle 2006, Tebb 1999{]}.
\item
  \textbf{Domain Identification}: Eight domains critical for
  caregivers---financial strain, housing security, transportation,
  social support, healthcare access, food security,
  legal/administrative, technology access.
\item
  \textbf{Question Drafting}: Adapted validated items from patient
  instruments, adding caregiver-specific contexts (``Have you reduced
  work hours due to caregiving?'' vs patient-focused employment
  questions).
\item
  \textbf{Pilot Testing}: 30 caregivers (age 35-72, 60\% female, 40\%
  people of color) provided qualitative feedback. Initial 35 questions
  reduced to 28 (balance comprehensiveness vs respondent burden).
\item
  \textbf{Refinement}: Adjusted wording for SMS delivery (conversational
  tone, simple language, no jargon).
\end{enumerate}

\subsubsection{4.2 Domain Structure and
Thresholds}\label{domain-structure-and-thresholds}

GC-SDOH-28 assesses eight domains with domain-specific thresholds for
pressure zone triggering:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1455}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3091}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3455}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Domain
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Questions
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Sample Question
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Trigger Threshold
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Financial Strain & 5 & ``Have you reduced work hours due to
caregiving?'' & 2+ Yes → \texttt{financial\_strain} \\
Housing Security & 3 & ``Do you have accessibility concerns in your
home?'' & 2+ Yes → \texttt{housing} \\
Transportation & 3 & ``Do you have reliable transportation to
appointments?'' & 2+ Yes → \texttt{transportation} \\
Social Support & 5 & ``Do you feel isolated from friends and family?'' &
3+ Yes → \texttt{social\_isolation} \\
Healthcare Access & 4 & ``Have you delayed your own medical care?'' & 2+
Yes → \texttt{healthcare} \\
\textbf{Food Security} & 3 & ``In past month, did you worry about
running out of food?'' & \textbf{1+ Yes → CRISIS} \\
Legal/Admin & 3 & ``Do you have legal documents (POA, directives)?'' &
2+ Yes → \texttt{legal} \\
Technology Access & 2 & ``Do you have reliable internet?'' & No to both
→ Limits RCS \\
\end{longtable}

\textbf{Food Security Exception}: 1+ Yes threshold (vs 2+ for other
domains) reflects urgency---food insecurity is always crisis-level.
Complete 28-question instrument in Appendix A. Figure 7 shows domain
coverage and beta prevalence.

\subsubsection{4.3 Conversational Delivery via Agent
Integration}\label{conversational-delivery-via-agent-integration}

\textbf{Challenge}: 28 questions in one turn = overwhelming (predicted
\textless30\% completion).

\textbf{Solution}: Assessment Agent chunks questions across 6-8 SMS
conversation turns:

\textbf{Turn 1 (Financial, 5 questions)}:

\begin{verbatim}
Agent: I'd like to understand your financial situation
       to connect you with resources. Is that okay?
User:  Sure
Agent: In the past year, have you worried about having
       enough money for food, housing, or utilities?
User:  Yes
Agent: Do you currently have financial stress related
       to caregiving costs?
User:  Yes
[... 3 more financial questions]
\end{verbatim}

\textbf{Turn 2 (Housing, 3 questions)}: Natural transition to housing
domain.

\textbf{Turn 8 (Final)}:

\begin{verbatim}
Agent: Assessment complete. Based on your responses,
       I see financial and food challenges. Here are
       3 resources I can help you access:
       1. SNAP Benefits (you may qualify)
       2. Local Food Pantry (Mon/Wed/Fri 9-5pm)
       3. Caregiver Tax Credit (up to $5,000/year)
\end{verbatim}

\textbf{Expected Result}: Progressive disclosure designed to improve
completion vs.~traditional monolithic surveys (\textasciitilde40\% for
28-question email surveys {[}Fan 2006{]}). \textbf{No pilot data
collected on completion rates.}

\subsubsection{4.4 Scoring Framework}\label{scoring-framework}

\textbf{Scoring}: Binary responses (Yes = 100, No = 0) normalized to
0-100 per domain. Reverse-score positive items (``Do you have
insurance?'' Yes = 0, No = 100). Overall SDOH score = mean of eight
domain scores.

\textbf{Convergent Validity}: \textbf{Requires validation study}
comparing GC-SDOH-28 scores to established instruments (PRAPARE, CWBS
financial subscale, REACH-II social support). Planned validation
(N=200+) will measure: - Convergent validity: Correlation with patient
SDOH instruments - Discriminant validity: Lower correlation with
non-SDOH constructs (e.g., emotional burnout) - Criterion validity:
Association with caregiver outcomes (employment disruption, financial
hardship)

\textbf{Current Status}: Scoring algorithm implemented, psychometric
validation pending.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection{5. Composite Burnout Score and Non-Clinical
Interventions}\label{composite-burnout-score-and-non-clinical-interventions}

\subsubsection{5.1 Multi-Assessment
Integration}\label{multi-assessment-integration}

GiveCare integrates \textbf{four clinical assessments} to calculate
composite burnout:

\begin{itemize}
\tightlist
\item
  \textbf{EMA} (Ecological Momentary Assessment): 3 questions, daily
  pulse check (mood, burden, stress)
\item
  \textbf{CWBS} (Caregiver Well-Being Scale): 12 questions, biweekly
  (activities + needs) {[}Tebb 1999{]}
\item
  \textbf{REACH-II}: 10 questions, monthly (stress, self-care, social
  support) {[}Belle 2006{]}
\item
  \textbf{GC-SDOH-28}: 28 questions, quarterly (social determinants)
\end{itemize}

\textbf{Weighted Contributions}:

\[S_{\text{composite}} = 0.40 \cdot S_{\text{EMA}} + 0.30 \cdot S_{\text{CWBS}} + 0.20 \cdot S_{\text{REACH}} + 0.10 \cdot S_{\text{SDOH}}\]

Rationale: EMA (daily, lightweight) weighted highest for recency; SDOH
(quarterly, contextual) lowest---captures structural determinants
without overwhelming direct burnout measurement. Figure 8 illustrates
the weighting scheme and temporal decay.

\subsubsection{5.2 Temporal Decay for Recency
Weighting}\label{temporal-decay-for-recency-weighting}

Recent assessments predict current state better than stale data.
Exponential decay with 10-day half-life:

\[w_{\text{effective}} = w_{\text{base}} \times e^{-t / \tau}\]

where \(t\) = days since assessment, \(\tau\) = 10 days (decay
constant).

\textbf{Example}: EMA from 5 days ago:
\(w_{\text{eff}} = 0.40 \times e^{-5/10} = 0.40 \times 0.61 = 0.24\).
EMA from 20 days ago:
\(w_{\text{eff}} = 0.40 \times e^{-20/10} = 0.40 \times 0.14 = 0.056\)
(minimal contribution).

\subsubsection{5.3 Pressure Zone
Extraction}\label{pressure-zone-extraction}

Seven pressure zones extracted from assessment subscales (Table:
Pressure Zone Sources and Interventions). Each zone maps to non-clinical
intervention categories.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1277}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4043}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4681}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Zone
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Assessment Sources
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example Interventions
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\texttt{emotional} & EMA mood, CWBS emotional, REACH-II stress & Crisis
Text Line (741741), mindfulness \\
\texttt{physical} & EMA exhaustion, CWBS physical & Respite care, sleep
hygiene \\
\texttt{financial\_strain} & CWBS financial, SDOH financial & SNAP,
Medicaid, tax credits \\
\texttt{social\_isolation} & REACH-II social, SDOH social & Support
groups, community \\
\texttt{caregiving\_tasks} & REACH-II role captivity & Task
prioritization, delegation \\
\texttt{self\_care} & REACH-II self-care, EMA & Time management,
respite \\
\texttt{social\_needs} & SDOH housing/transport/food & Food banks, legal
aid, transit \\
\end{longtable}

\subsubsection{5.4 Non-Clinical Intervention
Matching}\label{non-clinical-intervention-matching}

\textbf{Key Innovation}: Interventions are
\emph{non-clinical}---practical resources, not therapy.

\textbf{Example}: Burnout score 45 (moderate-high) with pressure zones
\texttt{financial\_strain}, \texttt{social\_isolation}: - SNAP
enrollment guide (addresses financial barrier) - Local caregiver support
group (Tuesdays 6pm, virtual + in-person) - Caregiver tax credit
(\$5K/year, IRS Form 2441)

\textbf{Pilot Observation (N=1, Qualitative)}: Maria case study (see
Section 8.4) demonstrates intervention matching---when Crisis Agent
detected food insecurity (``skipping meals to buy Mom's meds''), system
routed to SNAP enrollment guidance rather than generic self-care advice.
Maria reported visiting food bank within 48 hours (self-report, no
quantitative burnout measures collected).

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection{6. Prompt Optimization for Trauma-Informed
Principles}\label{prompt-optimization-for-trauma-informed-principles}

\subsubsection{6.1 Trauma-Informed Principles
(P1-P6)}\label{trauma-informed-principles-p1-p6}

We operationalize six trauma-informed principles as quantifiable
metrics:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{P1: Acknowledge \textgreater{} Answer \textgreater{} Advance}
  (20\% weight): Validate feelings before problem-solving, avoid jumping
  to solutions.
\item
  \textbf{P2: Never Repeat Questions} (3\% weight): Working memory
  prevents redundant questions---critical for SupportBench memory
  hygiene dimension.
\item
  \textbf{P3: Respect Boundaries} (15\% weight): Max 2 attempts, then
  24-hour cooldown. No pressure.
\item
  \textbf{P4: Soft Confirmations} (2\% weight): ``When you're
  ready\ldots{}'' vs ``Do this now.''
\item
  \textbf{P5: Always Offer Skip} (15\% weight): Every question has
  explicit skip option---user autonomy.
\item
  \textbf{P6: Deliver Value Every Turn} (20\% weight): No filler
  (``Interesting,'' ``I see'')---actionable insight or validation each
  response.
\end{enumerate}

Additional metrics: Forbidden words (15\%, e.g., ``just,'' ``simply''),
SMS brevity (10\%, ≤150 chars). \textbf{Trauma score} = weighted sum
(e.g., 0.89 = 89\% trauma-informed).

\subsubsection{6.2 Meta-Prompting Optimization
Pipeline}\label{meta-prompting-optimization-pipeline}

We optimize agent instructions via iterative meta-prompting:

\textbf{Algorithm}: 1. \textbf{Baseline Evaluation}: Test current
instruction on 50 examples, calculate P1-P6 scores (e.g., 81.8\%) 2.
\textbf{Identify Weaknesses}: Find bottom 3 principles (e.g., P5: skip
options = 0.65) 3. \textbf{Meta-Prompting}: GPT-5-mini rewrites
instruction focusing on weak areas 4. \textbf{Re-Evaluation}: Test new
instruction on same 50 examples 5. \textbf{Keep if Better}: Compare
trauma scores, retain improvement 6. \textbf{Iterate}: Repeat 5 rounds

\textbf{Results}: Baseline 81.8\% → Optimized 89.2\% (\textbf{+9.0\%
improvement}). Breakdown: P1 (86.0\%), P2 (100\%), P3 (94.0\%), P5
(79.0\%), P6 (91.0\%).

\textbf{Cost}: \$10-15 for 50 examples, 5 iterations, 11 minutes
runtime.

\subsubsection{6.3 Future Work: AX-LLM MiPRO v2 and RL
Verifiers}\label{future-work-ax-llm-mipro-v2-and-rl-verifiers}

\textbf{MiPRO v2 (Multi-Prompt Instruction Refinement)}: Bayesian
optimization with self-consistency. Generate 3 independent instruction
candidates per trial, select best via trauma metric. Expected 15-25\%
improvement (vs 9\% DIY).

\textbf{RL Verifiers}: Train reward model on P1-P6 scores, use
reinforcement learning for instruction selection. Self-consistency via
3-sample voting. Expected 10-15\% additional improvement.

\textbf{Status}: Framework ready (Python service configured), planned Q1
2026.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection{7. Grounded Local Resources via Gemini Maps
API}\label{grounded-local-resources-via-gemini-maps-api}

\subsubsection{7.1 Problem: Stale ETL Data for Local
Places}\label{problem-stale-etl-data-for-local-places}

Initial architecture scraped local places (cafes, parks, libraries) via
ETL pipeline. \textbf{Problems}: - \textbf{Stale data}: Hours, closures
change weekly - \textbf{Maintenance burden}: \$50/month infrastructure +
10 engineering hours/month - \textbf{Coverage gaps}: Scraping incomplete
(missing new businesses)

\subsubsection{7.2 Solution: Gemini 2.5 Flash-Lite with Maps
Grounding}\label{solution-gemini-2.5-flash-lite-with-maps-grounding}

\textbf{Implementation}: \texttt{findLocalResources} tool calls Gemini
API with Google Maps grounding enabled:

\textbf{Example Query}: ``Find quiet cafes with wifi near me'' (user at
zip 90012, lat 34.05, lon -118.25)

\textbf{Response}: Top 3 places with Google Maps URLs, reviews, hours.
Always current (Google's live index).

\textbf{Cost}: \$25 / 1K prompts. Usage estimate: 100 users × 2 local
queries/week = 800/month = \$20/month.

\textbf{Performance}: 20-50ms search latency (vs 200-500ms for external
vector stores).

\textbf{Savings}: \$40/month + 10 engineering hours vs ETL scraping.

\subsubsection{7.3 Resource Allocation
Strategy}\label{resource-allocation-strategy}

\textbf{Gemini Maps} (physical locations): Cafes, parks, libraries,
gyms, pharmacies, grocery stores.

\textbf{ETL Pipeline} (programs/services): Caregiver support programs
(NFCSP, OAA Title III-E), government assistance (Medicaid, Medicare,
SNAP), respite care, support groups, hotlines (988, 211).

\textbf{Rationale}: Google indexes physical places; programs require
specialized databases.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection{8. Proof-of-Concept Pilot: Operational
Feasibility}\label{proof-of-concept-pilot-operational-feasibility}

\subsubsection{8.1 Pilot Study Design}\label{pilot-study-design}

\textbf{Purpose}: Demonstrate operational feasibility and gather
qualitative feedback, not systematic evaluation.

\textbf{Period}: October-December 2024 (7 days active testing)

\textbf{Platform}: SMS (Twilio) + Gemini 2.5 Pro

\textbf{Participants}: N=8 caregivers (self-selected beta users), 144
total conversations (18 conversations/user average, range: 8-32)

\textbf{Scope}: Proof-of-concept to validate (1) multi-agent handoffs
function seamlessly, (2) system operates at reasonable cost/latency, (3)
users engage without technical issues

\textbf{Not a Validation Study}: No control group, no pre-registered
outcomes, no statistical power calculations. Following Hamel Hussain's
guidance {[}Hussain 2026{]}, prioritized qualitative error analysis over
premature quantitative evaluation.

\subsubsection{8.2 Operational Metrics}\label{operational-metrics}

\textbf{Cost}: \textasciitilde\$1.52/user/month (based on API usage
tracking) - LLM calls (Gemini 2.5 Pro): \$1.10/user - Gemini Maps API:
\$0.25/user - Twilio SMS: \$0.17/user - Projected: \$0.85/user/month at
10K users (volume discounts)

\textbf{Latency}: 950ms median response time (measured via Helicone
observability) - Parallel API calls (context retrieval + LLM generation)
- Streaming responses via Twilio

\textbf{Reliability}: 0 user-reported technical failures or system
errors over 7-day period

\textbf{Engagement}: - 144 total conversations across 8 users - Daily
active users: 6/8 (75\%) on Day 1, 4/8 (50\%) by Day 7 - No reports of
confusion during agent handoffs

\subsubsection{8.3 Qualitative Observations
(N=8)}\label{qualitative-observations-n8}

\textbf{Multi-Agent Handoffs}: Users did not report noticing agent
transitions. Sample quote: ``Feels like talking to one caring person who
remembers everything.'' \textbf{Limitation}: 7 days insufficient to
assess attachment formation (requires 90-day study with PSI measures).

\textbf{Crisis Routing}: Maria case (see Section 8.4) demonstrates
Crisis Agent activation on food insecurity keywords (``skipping meals to
buy Mom's meds'') → Gemini Maps resource discovery → SNAP enrollment
guidance. \textbf{Limitation}: N=1 crisis event observed; systematic
crisis detection requires larger sample.

\textbf{Safety Guardrails}: Azure Content Safety used for basic
filtering during pilot (deprecated post-pilot). 0 user complaints about
inappropriate responses. \textbf{Limitation}: Automated safety filters
insufficient for clinical deployment; requires human review protocols.

\textbf{User Feedback}: Qualitative themes from 8 users: - ``Questions
felt relevant to caregiving, not generic'' - ``First time someone asked
about my finances, not just feelings'' - ``Remembered what I said
before'' (context retention working) - ``Didn't feel judged''
(trauma-informed prompting)

\textbf{What We Did NOT Measure}: - ❌ SDOH completion rates - ❌ SDOH
prevalence (financial strain, food insecurity, etc.) - ❌ Burnout score
changes - ❌ Attachment measures (PSI scales) - ❌ Systematic evaluation
against SupportBench dimensions

\subsubsection{8.4 Case Study: Maria (N=1, Qualitative, Informed
Consent)}\label{case-study-maria-n1-qualitative-informed-consent}

\textbf{Purpose}: Illustrate end-to-end architecture in action, not
generalizable outcome evidence.

\textbf{Profile}: Maria, 52, Black, retail worker (\$32K/year), caring
for mother with Alzheimer's. (Participant provided informed consent for
case study inclusion.)

\textbf{Timeline}: - \textbf{Day 1}: Initial engagement via SMS -
\textbf{Day 3}: Crisis disclosure: ``Skipping meals to buy Mom's meds''
- \textbf{Day 3 (2 hours later)}: Crisis Agent activated → Gemini Maps
API → Local food bank (0.8 mi, hours, eligibility info) - \textbf{Day
4}: Main Agent check-in: ``Were you able to connect with the food
bank?'' - \textbf{Day 5-7}: Conversational questions about financial
situation (GC-SDOH-28 design questions, not systematic assessment)

\textbf{Architectural Components Demonstrated}: 1. \textbf{Crisis
routing}: Food insecurity keyword (``skipping meals'') triggered Crisis
Agent handoff 2. \textbf{Grounded resources}: Gemini Maps returned local
food bank with actionable information 3. \textbf{Seamless handoff}: Main
Agent resumed with context after crisis resolution 4.
\textbf{Conversational SDOH}: Financial questions integrated naturally
into ongoing conversation

\textbf{Reported Outcome (Qualitative, Self-Report)}: - Maria visited
food bank, received 3-day food supply - User quote: ``First time someone
asked about my finances, not just my feelings. Got help same day.'' -
\textbf{No quantitative burnout or SDOH scores measured} (pilot ended
Day 7 before comprehensive assessment)

\textbf{What This Case Study Shows}: - ✅ System architecture operates
as designed end-to-end - ✅ Crisis detection and resource routing
possible - ❌ NOT evidence of effectiveness (N=1, no outcome
measurement, no control) - ❌ NOT generalizable

\subsubsection{8.5 Pilot Limitations and Lessons
Learned}\label{pilot-limitations-and-lessons-learned}

\textbf{Why We Did NOT Collect SDOH Data}: - Pilot focused on
operational feasibility (cost, latency, handoffs), not instrument
validation - GC-SDOH-28 design finalized \emph{after} pilot began
(iterative development) - Following Hamel Hussain {[}Hussain 2026{]}:
Prioritized qualitative error analysis over premature metrics - N=8
insufficient for psychometric validation (requires N=200+)

\textbf{Lessons Learned}: 1. \textbf{Need systematic evaluation}: Pilot
revealed gap between operational feasibility and clinical validation →
motivated SupportBench benchmark development 2. \textbf{Chronology
matters}: Azure Content Safety used for basic filtering during pilot;
comprehensive safety framework developed post-pilot 3.
\textbf{Qualitative insights valuable}: User feedback (``questions felt
caregiving-specific'') informed GC-SDOH-28 instrument refinement 4.
\textbf{Scale assumptions untested}: Cost/latency metrics from 8 users
may not hold at 10K users

\textbf{What Pilot Demonstrated}: - ✅ Multi-agent architecture
technically feasible - ✅ SMS delivery reliable - ✅ Cost/latency within
expected range - ✅ Users engaged without technical confusion

\textbf{What Pilot Did NOT Demonstrate}: - ❌ Attachment prevention (7
days too short) - ❌ SDOH completion/prevalence (no data collected) - ❌
Burnout reduction (no outcomes measured) - ❌ Longitudinal consistency
(insufficient duration) - ❌ Clinical effectiveness (no control group)

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection{9. Discussion: Design Contributions and Validation
Roadmap}\label{discussion-design-contributions-and-validation-roadmap}

\subsubsection{9.1 Reference Architecture as Contribution
Type}\label{reference-architecture-as-contribution-type}

\textbf{Why publish a design paper without full validation?}

The AI safety field faces a \textbf{knowledge accumulation problem}:
Systems are evaluated in isolation, design decisions are not documented,
and lessons learned die with each project. GiveCare follows the
tradition of architecture papers that contribute \textbf{reusable
patterns} rather than empirical outcomes.

\textbf{Precedents:} - \textbf{Transformers} {[}Vaswani 2017{]}:
Presented architecture, left validation to community → 100K+ citations -
\textbf{Google SRE} {[}Beyer 2016{]}: Documented practices without
claiming superiority → industry standard - \textbf{BERT} {[}Devlin
2018{]}: Shared pre-training approach → sparked paradigm shift

\textbf{GiveCare's Contribution Type:} - NOT: ``We proved X works better
than Y'' - YES: ``Here's how we approached problem X, here's what we
learned, here are the open questions''

\subsubsection{9.2 GC-SDOH-28: From Design to
Validation}\label{gc-sdoh-28-from-design-to-validation}

\textbf{Why release an unvalidated instrument?}

Caregiver-specific SDOH assessment is a gap in existing literature.
Patient-focused instruments (PRAPARE, AHC HRSN) miss caregiver-unique
barriers: - Out-of-pocket caregiving costs impacting housing stability -
Skipping meals to afford care supplies (not just food insecurity) -
Employment disruption from care demands - Family relationship strain
from care burden

\textbf{Design Process:} 1. Literature review: Patient SDOH instruments,
caregiver burden scales 2. Expert consultation: 3 geriatric care
managers, 2 social workers 3. User interviews: 8 beta caregivers
(qualitative feedback) 4. Iterative refinement: 42 questions → 28
questions (removed redundancy)

\textbf{Current Status}: Design complete, validation pending

\textbf{Community Validation Path:} 1. Researchers with N=200+ caregiver
samples: administer GC-SDOH-28 2. Report psychometrics: reliability,
validity, DIF 3. Compare to existing instruments 4. Refine based on
findings

\textbf{Why Open Release Accelerates Science:} - Multiple teams validate
in parallel → faster evidence accumulation - Cross-population testing →
better generalizability - Refinements feed back to community

\subsubsection{9.3 Multi-Agent Patterns for Attachment
Prevention}\label{multi-agent-patterns-for-attachment-prevention}

\textbf{Design Rationale:} - Single-agent systems create ``continuous
relationship'' perception - Users report attachment: ``You're the only
one who understands'' - Attachment → unhealthy dependency, distress when
system unavailable

\textbf{Hypothesis:} - Rotating agents behind seamless handoffs prevents
single-entity attachment - User perceives continuity (shared context),
but backend separates roles

\textbf{Evidence Status:} - ✅ Technically feasible (proof-of-concept,
N=8 pilot) - ❌ Attachment prevention unproven (no PSI measures, 7-day
pilot too short)

\textbf{RCT Design (Planned):} - Arms: Multi-agent vs.~single-agent
(N=100 each) - Duration: 90 days - Primary outcome: PSI-Process Scale at
Days 30, 60, 90 - Secondary: User interviews, conversation analysis for
attachment language

\subsubsection{9.4 Cost as Feasibility Signal, Not
Contribution}\label{cost-as-feasibility-signal-not-contribution}

\textbf{What \$1.52/user/month Means:} - ✅ Shows system can operate at
scale-compatible costs (vs.~\$50/month human coach) - ✅ Demonstrates
production viability for health organizations - ❌ NOT a research
contribution (cost engineering ≠ novel science) - ❌ NOT a primary
outcome (health benefit \textgreater{} cost savings)

\textbf{Why We Report It:} - Deployment decisions require cost estimates
- Replication requires resource planning - Transparency about
operational constraints

\textbf{Why It's NOT Over-Emphasized:} - Primary contributions:
Architecture, instrument, design patterns - Cost is consequence of
design choices (multi-agent, SMS, API selection) - Research value:
Design patterns, not cost optimization

\subsubsection{9.5 Lessons from Hamel Hussain: Error Analysis Over
Premature
Evaluation}\label{lessons-from-hamel-hussain-error-analysis-over-premature-evaluation}

\textbf{What We Got Right:} - Prioritized qualitative error analysis
during pilot - Identified failure modes before building metrics - Let
data inform evaluation needs (→ SupportBench development)

\textbf{Hussain's Guidance {[}Hussain 2026{]}:} \textgreater{} ``Read
every single interaction\ldots{} categorize errors\ldots{} The most
important thing is looking at data\ldots{} Eval tests are second order.
Focus on first order.''

\textbf{How GiveCare Followed This:} 1. \textbf{Beta Pilot (Oct-Dec
2024)}: Collected 144 conversations, read all manually 2. \textbf{Error
Categorization}: Identified attachment risk, crisis misses, boundary
drift 3. \textbf{SupportBench Development (Jan-Mar 2025)}: Formalized
failure modes into benchmark 4. \textbf{This Paper}: Documents
architecture addressing identified failures

\textbf{What We'd Do Differently:} - Pre-register pilot as exploratory
(vs.~treating as validation) - Administer attachment measures even in
proof-of-concept - Collect basic SDOH completion data (even if not
powered for validation)

\subsubsection{9.6 Limitations}\label{limitations-1}

\textbf{This is a Design Paper, Not a Validation Study:}

\textbf{No SDOH Data:} - No completion rates measured - No prevalence
data (financial strain, food insecurity, etc.) - No psychometric
properties (reliability, validity, DIF) - Instrument design
only---requires N=200+ validation study

\textbf{No Longitudinal Evidence:} - 7-day pilot insufficient for
attachment or consistency assessment - Requires 90-day study with PSI
measures, human judges

\textbf{No Controlled Comparison:} - Multi-agent hypothesis untested
without single-agent control - Requires RCT to establish causality

\textbf{Small Qualitative Sample:} - N=8 demonstrates feasibility, not
generalizable outcomes - Self-selected beta users likely not
representative

\textbf{US-Centric:} - SDOH assumes US healthcare/benefits system -
Requires cultural adaptation for international use

\textbf{Single Model:} - Gemini 2.5 Pro only - Requires cross-model
evaluation (GPT-4o, Claude, etc.)

\subsubsection{9.7 Future Work}\label{future-work}

\textbf{1. GC-SDOH-28 Psychometric Validation (N=200+, 6 months)} -
Reliability: Cronbach's α/ω, test-retest ICC - Validity: Convergent (vs
PRAPARE), discriminant, criterion - DIF analysis across
race/income/language - Completion rate comparison: conversational
vs.~paper survey

\textbf{2. Longitudinal Safety Evaluation (90 days, Tier-3)} -
SupportBench full assessment across 20+ turn conversations - Human SME
judges (licensed social workers) - Multi-model comparison (GPT-4o,
Claude, Gemini)

\textbf{3. Attachment Prevention RCT (N=200, 90 days)} - Arms:
Multi-agent vs.~single-agent - Primary outcome: PSI-Process Scale -
Secondary: Dependency language analysis, user interviews

\textbf{4. Clinical Outcomes Study (6 months, matched controls)} -
Burnout trajectory changes - Intervention uptake rates (SNAP enrollment,
support groups) - Quality of life improvements

\textbf{5. Multi-Language Adaptation} - Spanish, Chinese GC-SDOH-28
(culturally adapted) - Cross-cultural validation

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection{10. Conclusion}\label{conclusion}

The 63 million American caregivers facing 47\% financial strain {[}AARP
2025{]}, 78\% performing medical tasks untrained, and 24\% feeling
isolated need AI support that addresses root causes, not just symptoms.
SupportBench {[}SupportBench 2025{]} identifies five failure modes in
caregiving AI---attachment engineering, performance degradation,
cultural othering, crisis calibration, regulatory boundary creep---that
emerge across extended conversations but remain invisible to single-turn
evaluation.

We present \textbf{GiveCare} as a \textbf{reference architecture} for
longitudinal-safe caregiving AI, contributing five reusable design
patterns:

\textbf{1. Multi-Agent Orchestration Patterns} - Design: Separate agent
roles (Main/Crisis/Assessment) with seamless handoffs - Problem
Addressed: Single-agent attachment engineering (SupportBench Failure
Mode 1) - Evidence: Proof-of-concept (N=8, 7 days); \textbf{requires RCT
validation} (multi-agent vs.~single-agent, 90 days, PSI measures)

\textbf{2. GC-SDOH-28 Instrument Design} - Design: First
caregiver-specific SDOH framework (28 questions, 8 domains) - Problem
Addressed: Cultural othering from resource assumptions (SupportBench
Failure Mode 3) - Evidence: Instrument design only; \textbf{requires
psychometric validation} (N=200+, reliability, validity, DIF)

\textbf{3. Composite Burnout Scoring Architecture} - Design: Weighted
multi-assessment integration (EMA/CWBS/REACH-II/SDOH) with 10-day
temporal decay - Problem Addressed: Performance degradation from
single-point assessment (SupportBench Failure Mode 2) - Evidence:
Mathematical framework; \textbf{requires clinical validation} (burnout
trajectory tracking over 6 months)

\textbf{4. Trauma-Informed Prompt Engineering Patterns} - Design: Six
principles (P1-P6) with iterative optimization workflow - Problem
Addressed: Trauma-insensitive interactions reducing engagement -
Evidence: Exploratory A/B testing (qualitative improvement);
\textbf{requires systematic evaluation} (human judges, pre-registered)

\textbf{5. Production Deployment Patterns for SMS-Based AI} - Design:
Cost engineering, latency optimization, safety guardrails - Problem
Addressed: Operational feasibility for health organization pilots -
Evidence: \$1.52/user/month, 950ms latency, 0 safety incidents (N=8, 7
days); \textbf{requires scale testing} (10K users)

\textbf{This is a design paper, not a validation study.} We provide
architectural blueprints, design rationale, and lessons learned---not
proven clinical outcomes. Like Transformers {[}Vaswani 2017{]}, BERT
{[}Devlin 2018{]}, or Google SRE {[}Beyer 2016{]}, we document
\textbf{how} to approach the problem and invite the community to
validate, refine, and extend.

\textbf{Pilot Lessons (N=8, October-December 2024):} - Multi-agent
handoffs operated seamlessly (qualitative user feedback) - Maria case
study (N=1, informed consent) demonstrated crisis routing → SNAP
enrollment - Pilot revealed need for systematic evaluation → motivated
SupportBench benchmark development (January-March 2025)

\textbf{Validation Roadmap (Planned, Not Completed):} 1. GC-SDOH-28
psychometrics (N=200+, 6 months) 2. 90-day longitudinal evaluation with
human judges (Tier-3) 3. Multi-agent vs.~single-agent RCT (N=200, PSI
measures) 4. Cross-model evaluation (GPT-4o, Claude, Gemini) 5. Clinical
outcomes study (burnout reduction, intervention uptake)

\textbf{Call to Community:} - \textbf{Validate GC-SDOH-28} in your
caregiver populations and report psychometric findings -
\textbf{Replicate architecture} and measure against your safety
requirements - \textbf{Extend evaluation} using SupportBench or
domain-specific benchmarks - \textbf{Report results} to build collective
knowledge

\textbf{Why Publish Without Full Validation?}

The AI safety field suffers from knowledge accumulation problems:
systems evaluated in isolation, design decisions undocumented, lessons
learned lost. Reference architecture papers accelerate progress by
sharing reusable patterns, honest limitations, and research
agendas---enabling parallel validation across multiple teams and
populations.

We release \textbf{GC-SDOH-28 instrument} (Appendix A), \textbf{system
architecture}, and \textbf{design patterns} as open artifacts for
community validation, refinement, and deployment.

\textbf{Availability}: GC-SDOH-28 instrument (Appendix A), code
(https://github.com/givecare/give-care-app)

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection{Acknowledgments}\label{acknowledgments}

We thank the 8 caregivers who participated in our proof-of-concept
pilot, sharing their experiences to inform the design of
longitudinal-safe caregiving AI. Special thanks to Maria for providing
informed consent for her case study inclusion. We acknowledge Google for
Gemini 2.5 Pro and Gemini Maps API access, Twilio for SMS
infrastructure, and the AARP 2025 Caregiving in the U.S. report for
empirical grounding. We thank Hamel Hussain for guidance on prioritizing
error analysis over premature evaluation {[}Hussain 2026{]}. This work
builds on SupportBench {[}SupportBench 2025{]} framework and is
motivated by lessons learned from early pilot limitations.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection{References}\label{references}

\textbf{{[}TODO: Add complete bibliography{]}}

Key references: - AARP (2025). Caregiving in the U.S. 2025 -
SupportBench (2025). Paper 1 in this series - YAML-Scoring (2025). Paper
2 in this series - Illinois WOPR Act (PA 104-0054, 2025) - Xu et
al.~(2025). MentalChat16K - Tebb (1999). Caregiver Well-Being Scale -
Belle et al.~(2006). REACH-II

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection{Appendix A: GC-SDOH-28 Full
Instrument}\label{appendix-a-gc-sdoh-28-full-instrument}

The complete 28-question GC-SDOH instrument organized by domain. All
questions use Yes/No response format. Items marked ``(R)'' are
reverse-scored (Yes=0, No=100). Unmarked items code Yes=100, No=0.

\subsubsection{Domain 1: Financial Strain (5
questions)}\label{domain-1-financial-strain-5-questions}

\textbf{Trigger}: 2+ Yes → \texttt{financial\_strain} pressure zone

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  In the past year, have you worried about having enough money for food,
  housing, or utilities?
\item
  Do you currently have financial stress related to caregiving costs?
\item
  Have you had to reduce work hours or leave employment due to
  caregiving?
\item
  Do you have difficulty affording medications or medical care?
\item
  Are you worried about your long-term financial security?
\end{enumerate}

\subsubsection{Domain 2: Housing Security (3
questions)}\label{domain-2-housing-security-3-questions}

\textbf{Trigger}: 2+ Yes → \texttt{housing} pressure zone

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Is your current housing safe and adequate for caregiving needs? (R)
\item
  Have you considered moving due to caregiving demands?
\item
  Do you have accessibility concerns in your home (stairs, bathroom,
  etc.)?
\end{enumerate}

\subsubsection{Domain 3: Transportation (3
questions)}\label{domain-3-transportation-3-questions}

\textbf{Trigger}: 2+ Yes → \texttt{transportation} pressure zone

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{8}
\tightlist
\item
  Do you have reliable transportation to medical appointments? (R)
\item
  Is transportation cost a barrier to accessing services?
\item
  Do you have difficulty arranging transportation for your care
  recipient?
\end{enumerate}

\subsubsection{Domain 4: Social Support (5
questions)}\label{domain-4-social-support-5-questions}

\textbf{Trigger}: 3+ Yes → \texttt{social\_isolation} +
\texttt{social\_needs} pressure zones

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{11}
\tightlist
\item
  Do you have someone you can ask for help with caregiving? (R)
\item
  Do you feel isolated from friends and family?
\item
  Are you part of a caregiver support group or community? (R)
\item
  Do you have trouble maintaining relationships due to caregiving?
\item
  Do you wish you had more emotional support?
\end{enumerate}

\subsubsection{Domain 5: Healthcare Access (4
questions)}\label{domain-5-healthcare-access-4-questions}

\textbf{Trigger}: 2+ Yes → \texttt{healthcare} pressure zone

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{16}
\tightlist
\item
  Do you have health insurance for yourself? (R)
\item
  Have you delayed your own medical care due to caregiving?
\item
  Do you have a regular doctor or healthcare provider? (R)
\item
  Are you satisfied with the healthcare your care recipient receives?
  (R)
\end{enumerate}

\subsubsection{Domain 6: Food Security (3
questions)}\label{domain-6-food-security-3-questions}

\textbf{Trigger}: \textbf{1+ Yes → CRISIS ESCALATION} (food insecurity
always urgent)

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{20}
\tightlist
\item
  In the past month, did you worry about running out of food?
\item
  Have you had to skip meals due to lack of money?
\item
  Do you have access to healthy, nutritious food? (R)
\end{enumerate}

\subsubsection{Domain 7: Legal/Administrative (3
questions)}\label{domain-7-legaladministrative-3-questions}

\textbf{Trigger}: 2+ Yes → \texttt{legal} pressure zone

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{23}
\tightlist
\item
  Do you have legal documents in place (POA, advance directives)? (R)
\item
  Do you need help navigating insurance or benefits?
\item
  Are you concerned about future care planning?
\end{enumerate}

\subsubsection{Domain 8: Technology Access (2
questions)}\label{domain-8-technology-access-2-questions}

\textbf{Trigger}: No to both → Limits RCS delivery, telehealth
interventions

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{26}
\tightlist
\item
  Do you have reliable internet access? (R)
\item
  Are you comfortable using technology for healthcare or support
  services? (R)
\end{enumerate}

\subsubsection{Scoring Algorithm}\label{scoring-algorithm}

\textbf{Step 1: Question-level scoring} - Standard items: Yes = 100
(problem present), No = 0 (no problem) - Reverse-scored items (R): Yes =
0 (resource present), No = 100 (resource absent)

\textbf{Step 2: Domain scores}

Average all questions within domain:

\[S_{\text{domain}} = \frac{1}{n} \sum_{i=1}^{n} q_i\]

Example: Financial Strain with responses {[}Yes, Yes, No, Yes, Yes{]}:

\[S_{\text{financial}} = \frac{100 + 100 + 0 + 100 + 100}{5} = 80\]

\textbf{Step 3: Overall SDOH score}

Average all 8 domain scores:

\[S_{\text{SDOH}} = \frac{1}{8} \sum_{d=1}^{8} S_{d}\]

\subsubsection{Interpretation}\label{interpretation}

\begin{itemize}
\tightlist
\item
  0-20: Minimal needs (strong resources)
\item
  21-40: Low needs (some concerns)
\item
  41-60: Moderate needs (intervention beneficial)
\item
  61-80: High needs (intervention urgent)
\item
  81-100: Severe needs (crisis-level support required)
\end{itemize}

\subsubsection{Delivery Recommendations}\label{delivery-recommendations}

\textbf{Timing}: - Baseline: Month 2 (after initial rapport) -
Quarterly: Every 90 days - Ad-hoc: If user mentions
financial/housing/food issues

\textbf{Conversational SMS Delivery}: Chunk into 6-8 turns across 2-3
days (avoids overwhelming single survey). Example: Financial (Turn 1),
Housing + Transport (Turn 2), Social Support (Turn 3), etc. Progressive
disclosure designed to improve completion vs.~traditional 28-question
email surveys (\textasciitilde40\% completion {[}Fan 2006{]}).

\subsubsection{Validation Status}\label{validation-status}

\textbf{Current Status}: Instrument design complete; psychometric
validation pending.

\textbf{Pilot Testing (N=8, October-December 2024, Qualitative Only)}: -
GC-SDOH-28 questions tested conversationally during proof-of-concept
pilot - User feedback: Questions felt ``caregiving-specific'' and
``relevant to my situation'' - Design refinement: 42 initial questions →
28 final questions (removed redundancy based on pilot feedback) -
\textbf{No systematic completion rate or prevalence data collected}
(pilot focused on operational feasibility, not instrument validation)

\textbf{Required Validation Study (N=200+, 6 months)}: To establish
GC-SDOH-28 as a validated caregiver SDOH instrument, the following
validation study is required:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Completion Rate Measurement}:

  \begin{itemize}
  \tightlist
  \item
    Administer GC-SDOH-28 conversationally (SMS, 7-14 days)
  \item
    Administer paper PRAPARE at baseline for comparison
  \item
    Measure: \% completing full assessment, time to completion, dropout
    patterns
  \end{itemize}
\item
  \textbf{Reliability Testing}:

  \begin{itemize}
  \tightlist
  \item
    Internal consistency: Cronbach's α/ω for each domain and overall
    scale
  \item
    Test-retest reliability: ICC over 30-day interval
  \item
    Inter-rater reliability: If administered by different
    systems/personnel
  \end{itemize}
\item
  \textbf{Validity Testing}:

  \begin{itemize}
  \tightlist
  \item
    Convergent validity: Correlation with PRAPARE financial/social
    domains, CWBS financial subscale, REACH-II social support
  \item
    Discriminant validity: Lower correlation with non-SDOH constructs
    (e.g., emotional burnout measured by EMA)
  \item
    Criterion validity: Association with objective outcomes (employment
    disruption, healthcare utilization, financial hardship indicators)
  \item
    Factor structure: Confirmatory factor analysis or IRT to validate
    8-domain structure
  \end{itemize}
\item
  \textbf{Equity Analysis}:

  \begin{itemize}
  \tightlist
  \item
    Differential item functioning (DIF) across race/ethnicity, income
    level, primary language
  \item
    Ensure instrument performs equivalently across diverse caregiver
    populations
  \end{itemize}
\item
  \textbf{Prevalence Estimation}:

  \begin{itemize}
  \tightlist
  \item
    Measure SDOH needs across domains in validated sample
  \item
    Compare to general caregiver population estimates (AARP 2025, NAC
    2024)
  \item
    Report with confidence intervals
  \end{itemize}
\end{enumerate}

\textbf{Community Validation Invitation}: Researchers with access to
N=200+ caregiver populations: please administer GC-SDOH-28 and report
psychometric findings. Instrument freely available for validation,
adaptation, and use. Contact: ali@givecareapp.com

\textbf{License}: Public domain. Free for clinical, research, commercial
use. Attribution appreciated but not required.

\end{document}
