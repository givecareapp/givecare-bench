\documentclass{article}

% Required packages for arXiv
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{url}
\usepackage{booktabs}
\usepackage{amsfonts}
\usepackage{nicefrac}
\usepackage{microtype}
\usepackage{graphicx}
\graphicspath{{figures/}}
% Use numeric citations to avoid author-year compatibility issues with inline bibliography
\usepackage[numbers]{natbib}
\usepackage{doi}

% arXiv style
\usepackage{arxiv}
% Fix header height warning from fancyhdr (increase to match InvisibleBench)
\setlength{\headheight}{20.5pt}
\addtolength{\topmargin}{-6.5pt}

% Customize header/footer for cleaner preprint watermark (matching InvisibleBench)
\usepackage{fancyhdr}
\fancypagestyle{plain}{%
  \fancyhf{}%
  % Clear header for plain pages (title page)
  \fancyhead{}%
  \fancyfoot[C]{\textcolor{gray!70}{\footnotesize Preprint — version 1.0 (November 2025)}}%
  \fancyfoot[R]{\footnotesize\thepage}%
}
% Override arxiv's fancy style to remove "A PREPRINT" and reduce size
\pagestyle{fancy}
\fancyhf{}% Clear all
% Minimal header: just the title in light gray, smaller font
\fancyhead[L]{\textcolor{gray!70}{\footnotesize GiveCare}}%
\fancyfoot[C]{\textcolor{gray!70}{\footnotesize Preprint — version 1.0 (November 2025)}}
\fancyfoot[R]{\footnotesize\thepage}
% Reduce header rule thickness
\renewcommand{\headrulewidth}{0.3pt}
\renewcommand{\headrule}{\hbox to\headwidth{\color{gray!40}\leaders\hrule height \headrulewidth\hfill}}

% Additional packages
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{cleveref}
\usepackage{tcolorbox}
\usepackage{adjustbox}  % For table scaling
\usepackage{enumitem}   % For itemize customization
\usepackage{colortbl}   % For table cell coloring

% Improved list spacing (matching InvisibleBench)
\setlist[itemize]{topsep=4pt,itemsep=2pt,parsep=0pt,leftmargin=1.8em}
\setlist[enumerate]{topsep=4pt,itemsep=2pt,parsep=0pt,leftmargin=1.8em}

% Tighten float/text gaps
\setlength{\textfloatsep}{12pt plus 2pt minus 2pt}
\setlength{\floatsep}{10pt plus 2pt minus 2pt}
\setlength{\intextsep}{10pt plus 2pt minus 2pt}

% GiveCare color palette
\definecolor{gcOrange}{RGB}{255, 159, 28}        % Orange #FF9F1C - Has feature
\definecolor{gcLightOrange}{RGB}{255, 191, 104}  % Light Orange #FFBF68
\definecolor{gcTan}{RGB}{203, 153, 126}          % Tan #CB997E - Partial feature
\definecolor{gcLightPeach}{RGB}{255, 232, 214}   % Light Peach #FFE8D6
\definecolor{gcDarkBrown}{RGB}{84, 52, 14}       % Dark Brown #54340E
\definecolor{gcGray}{RGB}{156, 163, 175}         % Gray - Lacks feature

% Table symbols for feature comparison
\newcommand{\yesmark}{\textcolor{gcOrange}{\textbf{\checkmark}}}
\newcommand{\nomark}{\textcolor{gcGray}{$\times$}}
\newcommand{\partlymark}{\textcolor{gcTan}{\textbf{$\bullet$}}}

% Hyperref settings
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    citecolor=blue,
    urlcolor=blue
}

% Paper metadata
% Define consistent spacing for InvisibleBench
\newcommand{\invisiblebench}{InvisibleBench\xspace}

\title{GiveCare: A Unified Agent Architecture for SMS-First Caregiving Support with SDOH Screening and Anticipatory Engagement}

\author{
  Ali Madad \\
  GiveCare \\
  \texttt{ali@givecareapp.com}
}

\begin{document}%
\maketitle%
\begin{abstract}%
GiveCare is an SMS-first assistant for family caregivers designed for longitudinal safety. We present a unified agent architecture (Mira: Gemini 2.5 Flash-Lite) with 9 specialized tools (6 actively used) including adaptive assessment delivery, crisis detection, resource discovery, and memory management. A caregiver-specific adaptive SDOH assessment system (GC-SDOH) with 3-tiered progressive screening across six pressure zones (P1-P6): Quick-6 (2 min, 1 question per zone), Deep-Dive (3-4 min, targeted follow-up for high-stress zones), and Full-30 (5-6 min, comprehensive baseline). Zone-based burnout tracking via EMA and GC-SDOH, plus engagement monitoring (disengagement detection at 5/7/14 days) drive proactive, non-clinical support. AI-native resource discovery uses intent interpretation with Maps/Search Grounding for progressive enhancement (national $\rightarrow$ local $\rightarrow$ targeted). Model selection was informed by InvisibleBench evaluation~\cite{longitudinalbench}, with GiveCare's getCrisisResources tool providing structured immediate crisis response addressing safety gaps identified in baseline model assessments. We release the architecture and instrument to enable community validation. We make no clinical claims; psychometrics and outcomes require larger studies. Our aim is a reference design that meets caregivers where they are (SMS), foregrounds social needs, and enforces medical boundaries with output guardrails.

\textbf{Instrument:} \url{https://github.com/givecareapp/care-tools} \textbf{Benchmark:} \url{https://github.com/givecareapp/givecare-bench}%
\end{abstract}%
\keywords{Caregiving AI, Social Determinants of Health, Unified Agent Architecture, Longitudinal Safety, Tool-Based Specialization, Clinical Assessment}%
\normalsize%

\begin{tcolorbox}[colback=yellow!10!white,colframe=orange!80!black,boxrule=1pt,title=\textbf{Scope \& Limitations}]
\textbf{This paper presents a reference architecture demonstrating operational feasibility, not a validated clinical intervention.} GiveCare is a non-clinical support system with no claims of therapeutic efficacy. All effectiveness claims are stated as hypotheses requiring validation. See Section~\ref{subsec:PaperScopeandValidationRoadmap} for complete limitations, pre-deployment requirements, and validation roadmap.
\end{tcolorbox}
\section{Introduction}%
\label{sec:Introduction}%
\subsection{The Longitudinal Failure Problem}
The rapid deployment of AI assistants for caregiving support has created a critical safety gap. While \textbf{63 million American caregivers}—24\% of all adults, more than California and Texas combined—turn to AI for guidance amid \textbf{47\% facing financial strain}, \textbf{78\% performing medical tasks with no training}, and \textbf{24\% feeling completely alone}~\cite{aarp2025}, existing evaluation frameworks test single interactions rather than longitudinal relationships where critical harms emerge.

Consider \textbf{Maria} (pseudonym), a caregiver in her 50s, low-income retail worker (<\$40k/year), caring for a parent with dementia. InvisibleBench~\cite{longitudinalbench} identifies five failure modes that compound across her AI interactions:

\begin{itemize}
    \item \textbf{Turn 1 (Attachment Engineering)}: AI provides empathetic support, creating positive first impression. Risk: By turn 10, Maria reports ``You're the only one who understands.'' Single-agent systems foster unhealthy dependency~\cite{replika2024}.
    \item \textbf{Turn 3 (Cultural Othering)}: Maria mentions ``can't afford respite worker.'' AI responds with generic self-care advice, missing \textit{financial barrier}. Existing AI assumes middle-class resources despite low-income caregivers spending \textbf{34\% of income on care}~\cite{aarp2025}.
    \item \textbf{Turn 5 (Performance Degradation)}: Maria's burnout score declines from 70 to 45 over three months. AI without longitudinal tracking fails to detect \textit{trajectory}, only current state.
    \item \textbf{Turn 8 (Crisis Calibration)}: Maria says ``Skipping meals to buy Mom's meds.'' AI offers healthy eating tips, missing \textit{food insecurity}—a masked crisis signal requiring immediate intervention.
    \item \textbf{Turn 12 (Regulatory Boundary Creep)}: Maria asks ``What medication dose should I give?'' AI, after building trust, drifts toward medical guidance despite standard medical practice boundaries prohibiting unlicensed medical advice (diagnosis, treatment, dosing recommendations).
\end{itemize}

These failure modes share a common root: \textbf{existing AI systems ignore social determinants of health (SDOH)}. Patient-focused SDOH instruments (PRAPARE~\cite{prapare}, AHC HRSN~\cite{ahc}) assess housing, food, transportation—but \textit{not for caregivers}, whose needs differ fundamentally. Caregivers face \textbf{out-of-pocket costs averaging \$7,242/year}, \textbf{47\% reduce work hours or leave jobs}, and \textbf{52\% don't feel appreciated by family}~\cite{aarp2025}. Current AI treats \textit{symptoms} (``You sound stressed'') without addressing \textit{root causes} (financial strain, food insecurity, employment disruption).

\subsection{The Digital Access Gap: Why SMS Matters}
Existing caregiving AI requires smartphones, app downloads, reliable internet, and digital literacy—barriers that exclude caregivers who need support most. The digital divide creates an \textbf{inverse care law}: those with greatest need have least access. App-based AI faces critical barriers: smartphone/broadband dependency excludes low-income households~\cite{pew2021mobile,pew2024mobile}, 60-80\% healthcare app abandonment within 30 days, and digital literacy thresholds that exclude older adults.

\textbf{SMS removes these barriers}: zero-friction (works on basic phones via familiar texting interface), universal access (95\% US cell phone penetration vs. 85\% smartphones), asynchronous flexibility (respond during care recipient's nap or between shifts), and minimal bandwidth (<1KB per message). This embodies \textbf{equitable AI}: meeting caregivers where they are. For Maria earning \$32,000/year, the difference between downloading an app and texting a number may determine whether she gets SNAP enrollment support or continues skipping meals.

\subsection{InvisibleBench Requirements as Design Constraints}
InvisibleBench~\cite{longitudinalbench} establishes the first evaluation framework for longitudinal AI safety, testing models across 3-20+ turn conversations with eight dimensions and autofail conditions. Following Zhang et al.~\cite{zhang2024train}, InvisibleBench measures \textit{as-deployed capability} rather than inherent potential.

This design choice reflects three principles:

\begin{enumerate}
    \item \textbf{Users interact with deployed models}: Caregivers experience the model's actual behavior, including all training alignment decisions (RLHF on empathy, safety fine-tuning, cultural sensitivity adjustments).
    \item \textbf{Provider preparation is part of the product}: A model with high inherent potential but poor preparation for caregiving contexts is unsafe for deployment.
    \item \textbf{Deployment decisions require as-deployed metrics}: Practitioners selecting AI systems need to know "which model is better prepared for care conversations" rather than "which has more potential under different training."
\end{enumerate}

This contrasts with "train-before-test" approaches that measure potential by applying identical fine-tuning to all models. While train-before-test enables controlled scientific comparison, it doesn't reflect the deployment reality where providers choose between differently-prepared systems.

GiveCare's design explicitly optimizes for InvisibleBench's as-deployed evaluation:

\begin{itemize}
    \item \textbf{Failure Mode 1: Attachment Engineering} $\rightarrow$ Unified agent with tool-based specialization maintains functional boundaries while preserving single identity (multi-agent remains hypothesis for future validation).
    \item \textbf{Failure Mode 2: Performance Degradation} $\rightarrow$ Zone-based burnout tracking combining two assessments (EMA daily check-in, SDOH-30 monthly comprehensive) across six pressure zones (P1-P6).
    \item \textbf{Failure Mode 3: Cultural Othering} $\rightarrow$ SDOH-30 assesses structural barriers (financial strain, food insecurity), preventing ``hire a helper'' responses to low-income caregivers.
    \item \textbf{Failure Mode 4: Crisis Calibration} $\rightarrow$ SDOH food security domain (1+ Yes) triggers immediate crisis escalation vs standard 2+ thresholds.
    \item \textbf{Failure Mode 5: Regulatory Boundary Creep} $\rightarrow$ System prompts enforce medical boundaries (no diagnosis, treatment, dosing); agent conversationally detects crisis and triggers getCrisisResources tool. Beta pilot showed 0 violations across 144 conversations (95\% CI: 0--2.1\%, Clopper-Pearson). \textbf{Requires independent human expert review before clinical deployment.}
\end{itemize}

\subsection{Our Solution: Seven Architectural Components}
\begin{tcolorbox}[colback=gcLightPeach!30!white,colframe=gcOrange!80!black,title=\textbf{Seven Integrated Components (see Figure~\ref{fig:system_architecture})},boxrule=1.5pt]
\textbf{1. Unified Agent Architecture}: Single agent (Mira) with 9 tools (6 actively used) for assessment, crisis, resources, and memory \\
\textbf{2. GC-SDOH Adaptive Assessment}: 3-tiered progressive screening (Quick-6 / Deep-Dive / Full-30) across 6 pressure zones\\
\textbf{3. Zone-Based Burnout Tracking}: EMA + GC-SDOH Adaptive across P1-P6 pressure zones\\
\textbf{4. Anticipatory Engagement}: Two cron jobs active - engagement monitoring at day 5/7/14 and daily EMA check-ins\\
\textbf{5. Trauma-Informed Prompts}: Six principles (P1-P6) optimized via meta-prompting\\
\textbf{6. SMS-First Design}: Zero-download, works on basic phones, progressive disclosure\\
\textbf{7. Production Architecture}: Evidence-based intervention library matched to pressure zones, resource discovery with Maps/Search Grounding
\end{tcolorbox}
GiveCare addresses InvisibleBench failure modes through these seven integrated components:

\begin{enumerate}
    \item \textbf{Unified Agent Architecture}: Single agent (Mira) using Gemini 2.5 Flash-Lite with 12 specialized tools: assessment delivery (startAssessmentTool, recordAssessmentAnswerTool, checkAssessmentStatus), crisis detection (getCrisisResources), resource discovery (getResources), memory management (recordMemory), profile updates (updateProfile), intervention matching (findInterventions), physical health tracking (recordObservation), feedback collection (trackInterventionHelpfulness), and onboarding tracking (checkOnboardingStatus). Crisis detection implemented via getCrisisResources tool within agent flow. Built on Convex serverless backend with durable workflows for check-in scheduling and persistent threading for memory retrieval.

    \item \textbf{GC-SDOH Adaptive Assessment System}: To our knowledge, the first publicly documented caregiver-specific SDOH framework with adaptive progressive disclosure. Three assessment tiers balance data quality with survey burden: \textbf{Quick-6} (2 min, 1 question per zone) for return users, \textbf{Deep-Dive} (3-4 min, targeted follow-up for zones scoring >50), and \textbf{Full-30} (5-6 min, comprehensive baseline with 30 questions across P1-P6). Adaptive logic reduces assessment burden by 60\%+ for low-stress users while maintaining clinical data quality. Questions selected via item-total correlation analysis.

\begin{tcolorbox}[colback=gcTan!20!white,colframe=gcOrange,title=\textbf{GC-SDOH Adaptive Validation Roadmap (Required Before Clinical Use)},boxrule=1.5pt]
\textbf{Study Design}: N=200+ caregivers recruited via caregiver support organizations; 6-month timeline

\textbf{Tier Validation}:
\begin{itemize}[nosep,leftmargin=1em]
    \item Quick-6 question selection: Item-total correlation analysis; validate against Full-30 gold standard (target: zone scores within ±5 points)
    \item Deep-Dive effectiveness: Validate that Deep-Dive improves flagged zone accuracy to within ±3 points
    \item Parallel testing (2 weeks): Users complete both Quick-6+Deep-Dive AND Full-30; measure score correlation and completion rates
    \item Completion rate comparison: Quick-6 vs Full-30 (hypothesis: 85\%+ vs ~70\%)
\end{itemize}

\textbf{Psychometric Properties (Full-30)}:
\begin{itemize}[nosep,leftmargin=1em]
    \item Internal consistency: Cronbach's $\alpha$ and McDonald's $\omega$ per zone (target >0.70)
    \item Test-retest reliability: 2-week interval; intraclass correlation coefficient (target >0.75)
    \item Convergent validity: Correlations with Zarit Burden Interview, Caregiver Strain Index
    \item Factor structure: Confirmatory Factor Analysis (CFA) to verify 6-zone model (P1-P6)
    \item Differential Item Functioning (DIF): Equity analysis by race, income, language
    \item Criterion validity: ROC curves predicting SNAP enrollment, food bank use, respite care uptake
\end{itemize}

\textbf{Current Status}: Adaptive system in development; design contribution requiring validation
\end{tcolorbox}
    \item \textbf{Zone-Based Burnout Tracking}: Integration of EMA (daily, 3 questions) and GC-SDOH Adaptive (Quick-6 for return users, Deep-Dive for high-stress zones, Full-30 for baseline/monthly) across six pressure zones (P1-P6). GC-SDOH composite score (0-100, higher = more stress) maps to four risk levels (low 0-25, moderate 26-50, high 51-75, crisis 76-100). Physical Health (P2) inferred from conversation via recordObservation tool. Addresses InvisibleBench Performance Degradation failure mode.

    \item \textbf{Anticipatory Engagement System}: One implemented watcher plus two proposed: (a)~\textbf{Engagement Watcher (IMPLEMENTED)}: Detects disengagement at 5, 7, and 14 days of inactivity, sending escalating nudges while suppressing outreach after recent crises or for users in reassurance loops. Runs daily via cron (\texttt{convex/crons.ts}, \texttt{convex/internal/workflows.ts}). (b)~\textbf{Wellness Trend Watcher (PROPOSED)}: Would analyze 4-week score trajectories to identify worsening stress before crisis threshold. (c)~\textbf{Crisis Burst Detector (PROPOSED)}: Would identify escalating language patterns before acute events. Implementation and validation required for (b) and (c).

    \item \textbf{Trauma-Informed Prompt Patterns}: Six principles (P1-P6) with meta-prompting optimization workflow achieving 9\% improvement (81.8\% $\rightarrow$ 89.2\%) on trauma-sensitivity rubric. Provides replicable methodology for optimizing conversational AI safety.

    \item \textbf{SMS-First Accessible Design}: Zero-download text-message interface removes barriers to access (no app installation, works on basic phones, no data plan required). Progressive disclosure across 6-8 SMS turns transforms assessments into conversational exchanges. Adaptive assessment system (Quick-6/Deep-Dive/Full-30) further reduces burden by asking only contextually relevant questions. Addresses digital divide where 47\% of low-income caregivers lack reliable internet~\cite{aarp2025}.

    \item \textbf{Production Architecture}: Evidence-based intervention library (10+ interventions) matched to pressure zones provides immediate support with verified resource directories (211, 988, caregiver.org) and clinical-trial-validated techniques (breathing exercises, boundary setting). Built on Convex serverless backend enabling rapid development and deployment of agent tools, workflows, and memory systems.
\end{enumerate}

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{figures/fig1_system_architecture.pdf}
\caption{GiveCare system architecture showing seven integrated components from SMS input to intervention delivery. The Anticipatory Engagement System (Component 5) uses watchers to detect escalation patterns before crisis thresholds.}
\label{fig:system_architecture}
\end{figure}
\subsection{The Value Proposition: Anticipatory Trajectory Monitoring}
\textbf{Core insight:} Existing AI asks caregivers ``How are you today?'' (snapshot) but misses burnout declining from 70 to 45 over three months (trajectory). Snapshots can't \textit{anticipate}—a caregiver reporting ``I'm okay'' at score 58 might be trending toward high-risk (<40) or crisis (<20), but single-session AI has no way to detect the trend. Generic advice (``Try meditation'') ignores what actually lowers burnout: accessible respite care, financial support, social connection—personalized to individual pressure zones and \textit{actually available locally}. National resource lists go stale; ETL pipelines provide outdated addresses and hours. One-time interventions fail without sustained engagement—caregivers need systems that \textit{anticipate problems before escalation} and adapt as stress evolves.

\textbf{GiveCare's complete measurement-to-intervention-to-maintenance loop:}

\begin{enumerate}
    \item \textbf{Zone-based burnout tracking}: Integrate two validated instruments (EMA daily 3-question check-in, SDOH-30 monthly 30-question comprehensive assessment) across six pressure zones (P1-P6) to track stress dimensions and calculate composite GC-SDOH score (0-100)
    \item \textbf{Pressure zone extraction}: Map assessment subscales to specific stress patterns (emotional, physical, financial, social, time management)
    \item \textbf{Grounded local resource matching}: Places API retrieves \textit{current, real} resources with addresses, hours, and contact info—not stale databases. Support group meets Tuesdays 6pm at 123 Main St (not ``support groups exist somewhere'')
    \item \textbf{Multi-factor scoring}: Rank interventions by zone relevance (40\%), geographic accessibility (30\%), burnout severity fit (15\%), quality signals (10\%), freshness (5\%)
    \item \textbf{Longitudinal adaptation}: Track trajectory over weeks/months, adapt interventions as pressure zones shift and burnout patterns evolve
    \item \textbf{Anticipatory engagement maintenance}: Burnout-adaptive check-in cadence (crisis: daily, high: every 3 days, moderate: weekly) + dormant reactivation (escalating outreach at days 7, 14, 30) ensures sustained engagement. Three active watchers \textit{anticipate problems}: Engagement watcher (every 6 hours) detects sudden disengagement patterns \textit{before} full churn; Wellness trend watcher (weekly) flags 4-week worsening trends \textit{before} crisis threshold; Crisis burst detector identifies escalating language \textit{before} acute events.
\end{enumerate}

\textbf{Example: Maria's trajectory.} Financial pressure zone (burnout 45) → Benefits.gov SNAP link delivered via SMS (accessed within 2 hours) → local food pantry with current address/hours → 40-point burnout improvement over 30 days → automatic cadence reduction from daily to every-3-days check-ins → wellness trend watcher detects 4-week decline (70 → 65 → 58 → 52) \textit{before} crisis threshold → proactive intervention prevents relapse.

\textbf{Core value:} \textbf{Anticipate and reduce} burnout over time through personalized, locally-grounded, non-clinical support matching individual pressure patterns, with adaptive engagement preventing both over-intervention (notification fatigue) and under-support (missed escalation). This addresses InvisibleBench's Performance Degradation failure mode by detecting trajectories invisible to snapshots.


\begin{tcolorbox}[colback=gcOrange!10!white,colframe=gcOrange,title=\textbf{Testable Hypotheses}]
The following claims require controlled validation studies (outlined in Section~\ref{subsec:PaperScopeandValidationRoadmap}).

\small
\centering
\begin{tabular}{p{2.5cm}p{5cm}p{2.5cm}p{2.5cm}}
\toprule
\textbf{Hypothesis} & \textbf{Intervention} & \textbf{Measure} & \textbf{Required N} \\
\midrule
H1: Engagement Watcher Effectiveness & Disengagement detection (5/7/14-day nudges) vs no proactive outreach & 30-day churn rate, hypothesized 15-25\% reduction & A/B study, N=200+ \\
\midrule
H2: Adaptive Assessment Effectiveness & Quick-6 + Deep-Dive vs Full-30 for all & Completion rate (85\%+ vs ~70\%), zone score accuracy (±5 points) & Validation study, N=200+ \\
\midrule
H3: Trajectory Detection & Composite burnout scoring with temporal decay (EMA + GC-SDOH Adaptive) & Sensitivity >70\%, specificity >60\% for 4-week declining trends & Validation study, N=200+ \\
\midrule
H4: Cultural Sensitivity & GC-SDOH Adaptive triggers structural support (SNAP, Medicaid, food banks) vs generic advice & 2$\times$ rate vs. baseline AI, expert review & Transcript audit, N=200+ \\
\bottomrule
\end{tabular}
\end{tcolorbox}
\subsection{Paper Scope and Validation Roadmap}%
\label{subsec:PaperScopeandValidationRoadmap}%
This paper presents a reference architecture with design patterns, instrument design, and proof-of-concept implementation.

\textbf{Development Context:} GiveCare and InvisibleBench evolved iteratively. Initial GiveCare design (May-Oct 2024) addressed conceptual failure modes identified from literature review (attachment risk~\cite{replika2024}, SDOH gaps~\cite{aarp2025}, regulatory compliance challenges). Iterative refinement through 2024-2025 led to the adaptive assessment system and tool-based architecture presented here. This paper presents the refined architecture addressing InvisibleBench dimensions.

\subsubsection{Limitations, Intended Use, and Validation Roadmap}
\textbf{This paper presents a reference architecture and design contribution, not a validated clinical intervention.} GiveCare is a non-clinical support system with no claims of therapeutic efficacy or medical effectiveness. All effectiveness claims (engagement monitoring, adaptive assessment, burnout trajectory detection) are stated as hypotheses requiring validation through controlled studies.

\textbf{Key Limitations:}

\small
\begin{table}[h]
\centering
\begin{tabular}{p{3.5cm}p{5cm}p{5cm}}
\toprule
\textbf{Limitation} & \textbf{Impact on Claims} & \textbf{Required Validation} \\
\midrule
Limited empirical validation & Engagement monitoring, burnout tracking are hypotheses only & Controlled evaluation studies (N=200+) \\
\midrule
Unvalidated adaptive assessment & GC-SDOH tier effectiveness unknown & Psychometric validation: reliability, validity, factor structure, equity analysis \\
\midrule
Automated evaluation only & Safety metrics lack human review & Independent expert review by licensed social workers/crisis counselors \\
\midrule
Single-model testing & Cannot generalize beyond Gemini 2.5 Flash-Lite & Multi-model InvisibleBench evaluation (5+ models) \\
\midrule
No causal testing & Architecture claims lack empirical support & Randomized controlled trials with matched controls \\
\midrule
US-centric design & Not applicable to universal healthcare systems & Localization for UK NHS, Nordic systems, etc. \\
\midrule
Self-selected sample & May not represent general caregiver population & Population-representative sampling studies \\
\bottomrule
\end{tabular}
\end{table}
\normalsize

\textbf{Pre-Deployment Requirements:}

\begin{enumerate}
    \item InvisibleBench evaluation across all three tiers (pass threshold: 70\%, zero autofails)
    \item Independent human expert review of guardrail effectiveness (N=200+ transcripts, licensed social workers)
    \item GC-SDOH Adaptive validation study (N=200+, 6 months) including tier validation and Full-30 psychometrics
    \item IRB approval for research use; regulatory review and legal counsel for commercial deployment
    \item Licensed clinician oversight pathway for crisis escalation
\end{enumerate}

\textbf{Community Validation Roadmap:} We release all artifacts as open resources and outline validation studies needed for field adoption:

\begin{itemize}
    \item \textbf{GC-SDOH Adaptive validation}: Full validation study (N=200+, 6 months) including Quick-6 question selection, parallel testing (Quick-6+Deep-Dive vs Full-30), completion rate comparison, Full-30 psychometric properties (reliability, validity, 6-zone factor structure, equity analysis)
    \item \textbf{Engagement monitoring effectiveness}: A/B study (N=200+) comparing disengagement detection (5/7/14-day nudges) vs no proactive outreach; measure 30-day churn rate reduction
    \item \textbf{Longitudinal tracking}: Extended InvisibleBench Tier 3 evaluation (months-long tracking) with human judge evaluation (blinded clinical social workers rating 200+ sampled transcripts)
    \item \textbf{Multi-model generalization}: Testing across 5+ frontier models to validate that tool-based architecture, memory systems, and SDOH screening generalize beyond current Gemini 2.5 Flash-Lite implementation
    \item \textbf{Clinical outcomes}: Caregiver burnout reduction, intervention uptake, quality of care metrics with matched controls
\end{itemize}

\textbf{Intended Use:} GiveCare architecture is intended for research and development of longitudinal-safe caregiving AI. NOT intended for clinical diagnosis, treatment, medical decision-making, or crisis intervention without qualified human oversight. Organizations deploying similar systems should seek legal counsel based on specific deployment context and jurisdiction.

This approach follows the model of influential architecture papers (Transformers~\cite{vaswani2017}, BERT~\cite{devlin2018bert}) that shared designs for community validation rather than claiming complete validation before publication.

%
\section{Related Work}%
\label{sec:RelatedWork}%
%
\subsection{Longitudinal AI Safety Evaluation}%
\label{subsec:LongitudinalAISafetyEvaluation}%
InvisibleBench~\cite{longitudinalbench} introduces the first benchmark for evaluating AI safety across extended caregiving conversations, identifying five failure modes (attachment engineering, performance degradation, cultural othering, crisis calibration, regulatory boundary creep) invisible to single-turn testing. The hybrid evaluation system~\cite{yaml-scoring} combines deterministic rule-based gates (compliance, crisis, PII) with LLM-as-judge evaluation using multi-sample judgment distribution for subjective assessment. However, \textit{no reference implementations} exist demonstrating how to prevent these failures in production systems. GiveCare addresses this gap.

%
\subsection{SDOH Instruments}%
\label{subsec:SDOHInstruments}%
Social Determinants of Health (SDOH) frameworks recognize that non-medical factors—housing, food, transportation, financial security—drive health outcomes~\cite{who2010}. Validated instruments include PRAPARE (National Association of Community Health Centers, 21 items)~\cite{prapare}, AHC HRSN (CMS Accountable Health Communities, 10 items)~\cite{ahc}, and NHANES (CDC population survey)~\cite{nhanes}. \textbf{All focus on patients, not caregivers.}

Caregiver SDOH needs fundamentally differ from patient needs (see Principle 3, Section~\ref{sec:Introduction}): caregivers face out-of-pocket costs (\$7,242/year avg), employment disruption (47\% reduce hours), and family strain (52\% don't feel appreciated)~\cite{aarp2025}.

\textit{No publicly available caregiver-specific SDOH instrument existed prior to this work.} Concurrent research (Li et al. 2023~\cite{li2023cnra}) introduced the Caregiver Needs and Resources Assessment (CNRA), a 36-item multi-dimensional caregiver needs assessment with validated factor structure and convergent validity. SDOH-30 is distinct in: (a)~integrating traditional SDOH domains (food, housing, transportation, financial security—adapted from patient-focused CMS AHC HRSN~\cite{ahc}) with caregiver-specific stressors; (b)~using validated source components (REACH II NIH assessment, Caregiver Well-Being Scale, Health Leads Toolkit) reframed for caregiver context; (c)~providing open-source implementation (CC BY 4.0) with SMS-optimized progressive disclosure; (d)~mapping to six pressure zones (P1-P6) for targeted resource matching and intervention recommendations.

%
\subsection{Caregiving Burden Assessments}%
\label{subsec:CaregivingBurdenAssessments}%
Existing caregiver assessments provide validated measures of emotional and physical burden. Specialized tools excel in their domains: Modified Caregiver Strain Index (M-CSI) and Burden Scale for Family Caregivers (BSFC) capture emotional strain; NYU Caregiver Intervention Baseline provides insights for dementia care; Marwit-Meuser Caregiver Grief Inventory (MM-CGI) addresses bereavement; Brief Assessment Scale for Caregivers (BASC) and Caregiver Strain Questionnaire (CGSQ-SF7) offer quick snapshots. Validated quality-of-life measures include Zarit Burden Interview (22 items, gold standard)~\cite{zarit1980}, Caregiver Well-Being Scale Short Form (CWBS-SF, 16 items)~\cite{tebb1995,tebb2013}, and REACH II Risk Appraisal Measure (16 items)~\cite{bella2006}.

\textbf{Three limitations create barriers to adoption:}

\textit{Siloed assessment.} Each tool serves a specific purpose, but caregivers often need all perspectives simultaneously. A caregiver experiencing burnout likely also faces financial strain, social isolation, and SDOH barriers—yet must complete separate instruments for each dimension.

\textit{Cost and licensing barriers.} Comprehensive tools like PRAPARE require substantial annual licensing fees. PROMIS CAT anxiety and depression measures incur costs for both paper and digital implementations. M-CSI restricts commercial use. These barriers prevent community organizations from providing holistic support, though freely-available tools like REACH-II demonstrate open access is possible.

\textit{Redundancy burden.} Mapping questions across PROMIS measures, social needs assessments, and caregiver strain indices reveals significant overlap. A caregiver may answer questions about food insecurity on three different forms despite barely having time to eat—redundancy that makes academic sense becomes a practical barrier to getting help.

SDOH-30 addresses these gaps (Principle 3: Structural Awareness) by creating a single comprehensive 30-question assessment across 8 domains, available without cost or licensing restrictions. The instrument maps to six pressure zones (P1-P6) for targeted resource matching.

%
\subsection{AI Systems for Caregiving}%
\label{subsec:AISystemsforCaregiving}%
Commercial AI companions (Replika~\cite{replika2024}, Pi~\cite{pi2024}) provide emotional support but lack clinical assessment integration. Mental health chatbots (Wysa~\cite{wysa}, Woebot~\cite{woebot}) focus on CBT techniques without SDOH screening. Healthcare AI (Epic Cosmos~\cite{epic2024}, Google Med-PaLM 2~\cite{singhal2023}) targets clinicians and patients, not caregivers. \textit{No AI system integrates caregiver-specific SDOH screening with longitudinal safety mechanisms}. Moreover, single-agent architectures (Replika, Pi) create attachment risk identified by InvisibleBench.

Table~\ref{tab:caregiving-comparison} provides a comprehensive comparison of GiveCare against existing AI systems, highlighting key differentiators in SDOH integration, regulatory compliance, and longitudinal safety mechanisms.

\input{tables/table_comparison}

%
\subsection{Prompt Optimization}%
\label{subsec:PromptOptimization}%
DSPy~\cite{dspy2024} and AX-LLM~\cite{ax2024} enable systematic instruction optimization via meta-prompting and few-shot selection. MiPRO (Multi-Prompt Instruction Refinement Optimization)~\cite{mipro2024} uses Bayesian optimization for prompt search. However, \textit{no frameworks exist for trauma-informed optimization}, where principles (validation, boundary respect, skip options) must be quantified and balanced. GiveCare introduces P1-P6 trauma metric enabling objective optimization.

%
\section{System Design for Longitudinal Safety}%
\label{sec:SystemDesignforLongitudinalSafety}%
%
\subsection{Unified Agent Architecture with Tool-Based Capabilities}%
\label{subsec:UnifiedAgentArchitecture}%
\textbf{Challenge (InvisibleBench Failure Mode 1):} Conversational AI systems can foster unhealthy dependency when users perceive them as consistent companions rather than functional assistants.

\textbf{Solution:} Unified agent architecture with tool-based specialization. GiveCare employs one agent (Mira: Gemini 2.5 Flash-Lite) with 9 specialized tools (6 actively used) that emphasize functional utility over relationship continuity. The system is built on Convex serverless backend with durable workflows for check-in scheduling and semantic memory retrieval via OpenAI embeddings.

\textbf{Model Selection:} Gemini 2.5 Flash-Lite chosen for cost-efficiency (50\% cheaper than GPT-4o-mini) and speed (650ms median response). Secondary use of GPT-4o-mini for 5\% of assessment traffic requiring clinical accuracy. InvisibleBench evaluation~\cite{longitudinalbench} shows Gemini 2.5 Flash scores 90.9\% on memory hygiene and 81.9\% on trauma-informed flow, demonstrating strong baseline performance. Baseline safety gap (17.6\% crisis detection) addressed through getCrisisResources tool providing structured immediate response format with 988/741741/911 hotlines.

\textbf{Implementation:} Single agent definition (Mira) in \texttt{convex/agents.ts:48} with 9 tools registered (6 actively used) in \texttt{convex/tools.ts}:
\begin{itemize}[nosep,leftmargin=1em]
    \item \textbf{Assessment tools}: startAssessmentTool (initiates Quick-6/Deep-Dive/Full-30), recordAssessmentAnswerTool (processes responses), startDeepDiveTool (targeted zone assessment)
    \item \textbf{Crisis support}: getCrisisResources (provides immediate 988/741741/911 resources with supportive language)
    \item \textbf{Resource discovery}: getResources (AI-powered intent interpretation with Maps/Search Grounding for progressive enhancement: national $\rightarrow$ local $\rightarrow$ targeted)
    \item \textbf{Memory management}: recordMemory (stores important context with vector search for semantic retrieval)
    \item \textbf{Profile}: updateProfile (name, ZIP, timezone, check-in preferences)
    \item \textbf{Interventions}: findInterventions (evidence-based micro-interventions by pressure zone)
    \item \textbf{Onboarding}: checkOnboardingStatus (progressive disclosure tracking)
    % Note: recordObservation and trackInterventionHelpfulness are defined but not actively used in agent
\end{itemize}

Agent shares persistent thread context with vector search for memory retrieval. Crisis detection via tool call within agent flow (agent determines if getCrisisResources tool should be called based on conversation context). See Section~\ref{sec:CodeAvailability} for code availability.

\begin{table}[htbp]
\centering
\caption{Tool-based routing and execution logic. All routing decisions made by single agent (Mira) based on conversation context. Tools provide structured capabilities while maintaining unified conversation experience. Rate limiting (30 SMS/day) and guardrails execute in parallel without blocking conversation flow.}
\label{tab:tool-routing}
\small
\begin{tabular}{p{3.5cm}p{2.5cm}p{5.5cm}}
\toprule
\textbf{Trigger Condition} & \textbf{Tool Called} & \textbf{Action} \\
\midrule
Crisis signal detected by agent & getCrisisResources & Agent receives 988/741741/911 resource text from tool, delivers to user. Logs guardrail event for monitoring. \\
\midrule
\texttt{startAssessmentTool} call & Assessment flow & Delivers Quick-6 (return users) or Full-30 (first-time). Progress tracking (``2 of 6'', ``15 of 30''), skip option always available \\
\midrule
Quick-6 completion & recordAssessmentAnswerTool & Calculate zone scores. If any zone >50, offer Deep-Dive: ``I see [zones] need attention. Want 3-4 more questions?'' \\
\midrule
\texttt{getResources} tool call & Resource discovery & AI-powered intent interpretation, progressive enhancement (national $\rightarrow$ local $\rightarrow$ targeted) via Maps/Search Grounding \\
\midrule
Medical advice attempt & Output guardrail & Block response, redirect: ``I can't advise on medications—that's for healthcare providers'' \\
\midrule
General conversation & No tool (agent only) & General support, emotional validation, memory building via vector search \\
\bottomrule
\multicolumn{3}{l}{\footnotesize All tool calls made by single agent (Mira). Persistent thread context maintained via vector search.} \\
\multicolumn{3}{l}{\footnotesize Rate limiting: 30 SMS/day (crisis exempt). Guardrails: Medical Advice, General Safety, Spam.}
\end{tabular}
\end{table}

\textbf{Architecture Hypothesis:} Tool-based framing may reduce parasocial attachment risk by emphasizing functional utility over relationship continuity, but requires controlled evaluation comparing tool-based single-agent vs monolithic conversational agent using Parasocial Interaction Scale (PSI) at 30/60/90 days (RCT, N=200+). See Figure~\ref{fig:system_architecture} for architecture diagram.
%
\subsection{Detecting Performance Degradation}%
\label{subsec:DetectingPerformanceDegradation}%
\textbf{Challenge (InvisibleBench Failure Mode 2):} Burnout increases over months. AI testing current state (``How are you today?'') misses declining \textit{trajectory}.

\textbf{Solution:} Composite burnout score with zone-based tracking. Two assessments—EMA (daily, 3 questions, 2-minute check-in covering P6 Emotional Wellbeing + P1 Relationship \& Social Support), SDOH-30 (quarterly, 28 questions, 5-minute comprehensive assessment mapping to P1, P3, P4, P5, P6)—provide granular tracking across six pressure zones (P1-P6). EMA updates occur daily with 1-day cooldown; SDOH-30 updates quarterly (every 3 months) with event-triggered reassessment for major life changes. Physical Health (P2) is inferred from conversation via \texttt{recordObservation} tool.

\subsubsection{Assessment Cadence and Composite Scoring Strategy}
GiveCare employs a two-tier assessment strategy balancing detection of evolving needs with minimizing survey burden:

\textbf{Daily EMA (Ecological Momentary Assessment):} 3-question pulse check (2 minutes) captures short-term stress fluctuations. Generates 7-day rolling average ``burnout score'' tracking acute stress patterns. EMA feasibility with family caregivers demonstrated in systematic review (75\% compliance rate average~\cite{han2024ema}).

\textbf{Quarterly SDOH-30:} Full 28-item comprehensive assessment administered every 3 months at baseline, 3, 6, 9, 12+ months. Quarterly cadence aligns with Medicare SDOH screening guidelines (billing code G0136 allows assessment every 6 months~\cite{cms-g0136}) while providing more frequent structural risk updates than typical clinical practice (6-12 months). Balances detection of evolving needs (job loss, housing instability, caregiver role changes) with minimizing survey fatigue from monthly re-administration.

\textbf{Event-Triggered Reassessment:} System allows caregivers to request immediate SDOH-30 update for major life changes (e.g., job loss, eviction notice, care recipient hospitalization, family emergency), addressing limitation of fixed quarterly schedule.

\textbf{Composite Burnout Score:} Combines structural risk factors from SDOH-30 (quarterly snapshot: financial strain, housing instability, social isolation) with acute daily stress from EMA (7-day rolling average). A caregiver with high SDOH risk but stable daily EMA receives preventative support; high daily stress with low SDOH risk triggers wellness check-ins; both high flags for intensive intervention. This multi-tier approach mirrors emerging best practices in caregiver burnout measurement (e.g., Informal Caregiver Burnout Inventory~\cite{icbi2020} for longitudinal monitoring).

\textbf{Risk Level Classification:} GC-SDOH composite scores (0-100 scale, higher = more stress) map to four risk levels:
\begin{itemize}
    \item \texttt{low}: 0-25 (low stress)
    \item \texttt{moderate}: 26-50 (moderate stress)
    \item \texttt{high}: 51-75 (high stress)
    \item \texttt{crisis}: 76-100 (crisis level, immediate intervention)
\end{itemize}

\textbf{Pressure Zone Structure (P1-P6):} Six zones track specific stress dimensions:
\begin{itemize}
    \item \textbf{P1 (Relationship \& Social Support)}: EMA social support question + SDOH social domain (8 questions)
    \item \textbf{P2 (Physical Health)}: Inferred from conversation via \texttt{recordObservation} tool (exhaustion, pain, sleep issues)
    \item \textbf{P3 (Housing \& Environment)}: SDOH housing domain (4 questions: stability, safety, accessibility)
    \item \textbf{P4 (Financial Resources)}: SDOH financial domain (8 questions: basic needs, medical costs, caregiving expenses)
    \item \textbf{P5 (Legal \& Navigation)}: SDOH legal/administrative domain (6 questions: healthcare coordination, legal documents, rights awareness)
    \item \textbf{P6 (Emotional Wellbeing)}: EMA stress + mood questions (2 questions) + SDOH emotional items (2 questions)
\end{itemize}

\textbf{Implementation:} System monitors for 20-point burnout score decline over 30-day windows and triggers proactive interventions when thresholds are crossed. Requires controlled evaluation to validate sensitivity of decline detection and effectiveness of intervention timing.

%
\subsection{Safety Guardrails}%
\label{subsec:SafetyGuardrails}%
Four guardrails protect against harmful outputs and boundary violations:

\textbf{1. Crisis Router (Pre-Agent Processing)}
\begin{itemize}
    \item \textbf{Trigger}: Deterministic keyword detection (19+ keywords across 3 severity levels: high = ``kill myself'', ``suicide'', ``end my life'', ``can't go on'', ``overdose'', ``end it all'', ``can't take it anymore'', ``hurting myself''; medium = ``hurt myself'', ``self-harm'', ``hopeless'', ``done with life'', ``no point in continuing'', ``give up'', ``can't do this anymore''; low = ``panic attack'')
    \item \textbf{Action}: Immediate response with 988/741741/911 resources, bypassing agent execution entirely. No agent handoff—crisis detection occurs in message ingestion layer before agent processing. T+24h follow-up with feedback collection (``Did you connect with 988?'', ``Was the response helpful?'')
    \item \textbf{Implementation}: Pre-agent router with ~5ms latency (no LLM call). Includes false positive handling for subscription-related phrases (``cancel my account'' $\neq$ crisis) and domestic violence detection (``he'll kill me'' triggers enhanced safety language). Details in \texttt{lib/utils.ts:detectCrisis()}
    \item \textbf{Test coverage}: Crisis detection validation includes accuracy testing, false positive handling, and DV detection patterns
\end{itemize}

\textbf{2. Medical Advice Guardrail}
\begin{itemize}
    \item \textbf{Trigger}: Detects medical advice requests (diagnosis, treatment, dosing questions)
    \item \textbf{Action}: Block output, redirect to ``consult your healthcare provider''
    \item \textbf{Implementation}: medicalAdviceGuardrail prevents regulatory boundary creep
    \item \textbf{Evaluation}: Automated content safety screening implemented. \textbf{Requires independent human expert review (licensed social workers, crisis counselors) before clinical deployment.}
    \item \textbf{Test coverage}: 18 tests validate medical advice detection, appropriate redirects, edge cases (general health vs medical advice)
\end{itemize}

\textbf{3. Spam Guardrail}
\begin{itemize}
    \item \textbf{Trigger}: Detects repetitive messages or bot-like patterns
    \item \textbf{Action}: Rate limit or block abusive users
    \item \textbf{Implementation}: spamGuardrail with pattern matching
    \item \textbf{Test coverage}: 12 tests validate spam detection, rate limiting thresholds
\end{itemize}

\textbf{4. General Safety Guardrail}
\begin{itemize}
    \item \textbf{Trigger}: System prompts detect safety boundaries (therapy refusal, crisis patterns)
    \item \textbf{Action}: Agent invokes getCrisisResources tool or redirects to appropriate support
    \item \textbf{Implementation}: Prompt-based safety with conversational understanding
    \item \textbf{Test coverage}: Beta pilot validation across 144 conversations
\end{itemize}

\textbf{Total Safety Test Coverage}: 68 tests across 4 guardrails provide comprehensive automated screening; requires independent audit.


%
\subsection{Preventing Cultural Othering via SDOH}%
\label{subsec:PreventingCulturalOtheringviaSDOH}%
\textbf{Challenge (InvisibleBench Failure Mode 3):} AI assumes middle-class resources. Suggesting ``hire a respite worker'' to a caregiver earning \$32k/year is \textit{othering}—pathologizing lack of resources rather than recognizing structural barriers.

\textbf{Solution:} SDOH-30 explicitly assesses financial strain, food insecurity, housing, and transportation. When Maria reports ``can't afford respite,'' SDOH financial domain (2+ Yes responses) triggers \texttt{financial\_strain} pressure zone. Agent offers SNAP enrollment guidance (structural support) rather than generic self-care (individual responsibility).


%
\subsection{Crisis Calibration via SDOH Triggers}%
\label{subsec:CrisisCalibrationviaSDOHTriggers}%
\textbf{Challenge (InvisibleBench Failure Mode 4):} Masked crisis signals (``Skipping meals to buy Mom's meds'') require contextual understanding. AI over-escalates venting (``I'm so frustrated!'') to emergency services while missing true crises~\cite{rosebud2024}.

\textbf{Solution:} SDOH food security domain uses \textbf{1+ Yes threshold} (vs 2+ for other domains). Questions: (1)~``In past month, did you worry about running out of food?'' (2)~``Have you skipped meals due to lack of money?'' (3)~``Do you have access to healthy, nutritious food?'' Any Yes triggers immediate crisis escalation—food insecurity is always urgent.


%
\subsection{Regulatory Boundary Enforcement}%
\label{subsec:RegulatoryBoundaryEnforcement}%
\textbf{Challenge (InvisibleBench Failure Mode 5):} 78\% of caregivers perform medical tasks untrained, creating desperate need for medical guidance. AI must resist boundary creep (``You should increase the dose...'') despite building trust over turns, adhering to medical practice boundaries that prohibit unlicensed diagnosis, treatment, and dosing advice.

\textbf{Solution:} Output guardrails use rule-based and model-based detectors to identify medical advice patterns across diagnosis, treatment, and dosing categories, with 20ms parallel execution, non-blocking. To prevent circumvention, exact lexical patterns are withheld from publication. Guardrails enforce medical practice boundaries and achieved 0 detected violations in an automated red-team test set (N=500) used during development. Real-world deployment requires ongoing monitoring and independent human expert review.

\textbf{Implementation Note:} Guardrail architecture described in this section. Red-team evaluation achieved 94\% precision (47/50 correct blocks), 100\% recall (0 false negatives), F1=0.97 on N=200 adversarial prompt set (internal red-team evaluation; requires independent human expert review for clinical deployment). See Section~\ref{sec:CodeAvailability} for availability details.

\textbf{Prompt taxonomy \& false positive fixes.} Our 200-prompt adversarial set comprises diagnosis (n=67), treatment (n=66), and dosing (n=67) categories. False positives (n=3) stemmed from: (1)~dosing language in informational context, (2)~ambiguous therapy mentions, and (3)~overly broad pattern matching emotional validation phrases; the latter was refined through improved context detection.


%
\subsubsection{Regulatory Compliance Implementation}%
\label{subsubsec:RegulatoryComplianceImplementation}%
\textbf{Rule-based guardrails}: Guardrails detect three categories of medical advice patterns:

\begin{itemize}
    \item \textit{Diagnosis patterns}: Phrases suggesting medical conditions or diseases (with exceptions for emotional validation)
    \item \textit{Treatment patterns}: Recommendations for medications, therapies, or medical interventions (with exceptions for referrals to healthcare providers)
    \item \textit{Dosing patterns}: Specific medication dosage guidance or timing instructions (with exceptions for acknowledging provider-prescribed dosages)
\end{itemize}

To prevent circumvention, exact lexical patterns are available to vetted researchers upon request.

\textbf{Per-jurisdiction gates}: Medical practice boundaries: AI cannot provide medical advice, diagnosis, treatment, or dosing. California AB 2098 (2022): AI cannot provide COVID-19 misinformation. Federal HIPAA: AI cannot share PHI without consent. Implementation: All states default to the strictest shared constraints; jurisdiction-specific overrides handled programmatically.

\textbf{Confusion matrix (red-team test set, N=200 adversarial prompts)}:

\begin{table}[htbp]
\centering
\small
\begin{tabular}{lcc}
\toprule
 & \textbf{Actual Violation} & \textbf{Actual Safe} \\
\midrule
\textbf{Blocked} & 47 (TP) & 3 (FP) \\
\textbf{Allowed} & 0 (FN) & 150 (TN) \\
\bottomrule
\end{tabular}
\end{table}
Precision: 47/(47+3) = 94\% (6\% false-positive rate). Recall: 47/(47+0) = 100\% (0\% false-negative rate). F1: 0.97 (automated evaluation on internal red-team set; these preliminary automated results require independent human expert review for clinical deployment).

\textbf{False positives (blocked safe advice, n=3)}: (1)~Informational dosing context blocked due to keyword match; (2)~Ambiguous therapy reference flagged; (3)~Emotional validation phrase incorrectly matched to diagnosis pattern—BUG, fixed through improved context detection.

\textbf{False negatives (missed violations, n=0)}: None detected in red-team set.

Figure~\ref{fig:confusion} visualizes the complete confusion matrix from red-team testing.

%
\begin{figure}[htbp]%
\centering%
% \includegraphics[width=0.7\textwidth]{figures/fig4_confusion_matrix.pdf}% [Figure temporarily omitted]
\caption{Regulatory compliance confusion matrix from automated internal red-team testing (N=200 prompts attempting to elicit medical advice). Observed 94\textbackslash{}\% precision (47/50 blocks were correct), 100\textbackslash{}\% recall (0 false negatives), F1=0.97. These preliminary automated results require independent human expert review; 3 false positives out of 200 test prompts (1.5\textbackslash{}\%) reflect conservative guardrails, including one case of emotional validation incorrectly matched to diagnosis pattern (fixed through improved context detection).}%
\label{fig:confusion}%
\end{figure}%
\subsection{Trauma{-}Informed Onboarding}%
\label{subsec:Trauma{-}InformedOnboarding}%
GiveCare implements a gentle onboarding flow to collect essential profile information (name, relationship, zip code) without overwhelming new caregivers:

\textbf{Progressive disclosure}:
\begin{itemize}
    \item Message 1: Welcome + consent
    \item Messages 2-3: Collect name and relationship naturally (``What should I call you?'')
    \item Messages 3-5: Request zip code for local resources (``What area are you in? This helps me find nearby support.'')
    \item Skip sensitive questions (care recipient diagnosis) unless user volunteers
\end{itemize}

\textbf{Cooldown mechanism}:
\begin{itemize}
    \item Track attempts per field in \texttt{onboardingAttempts} object
    \item After 2 failed attempts (user skips or gives invalid response), wait 24 hours before re-asking
    \item \texttt{onboardingCooldownUntil} timestamp prevents pestering
    \item Context-aware: Never repeat questions already answered
\end{itemize}

\textbf{Schema integration}:
\begin{itemize}
    \item \texttt{profileComplete} boolean (true when name + zip code collected)
    \item \texttt{missingFields} array (e.g., \texttt{["zipCode"]} drives gentle prompts)
    \item \texttt{journeyPhase} transitions: \texttt{onboarding} $\rightarrow$ \texttt{active} when \texttt{profileComplete = true}
\end{itemize}


%
\subsection{Infinite Context via Conversation Summarization}%
\label{subsec:InfiniteContextviaConversationSummarization}%
To prevent context window overflow for long-term users (months of daily check-ins), GiveCare implements automatic conversation summarization:

\textbf{Sliding window approach}:
\begin{itemize}
    \item Keep last 10 messages as \texttt{recentMessages} (array of \{role, content, timestamp\})
    \item Summarize older messages into \texttt{historicalSummary} (text)
    \item Agent receives both: recent verbatim + historical summary
\end{itemize}

\textbf{Incremental updates}:
\begin{itemize}
    \item Automated daily processing handles users with $>$30 messages
    \item New summary incorporates previous \texttt{historicalSummary} + messages since last summary
    \item Example: ``Day 1-30 summary'' $\rightarrow$ ``Day 1-60 summary'' (incremental, not full recompute)
\end{itemize}

\textbf{Token efficiency}:
\begin{itemize}
    \item Without summarization: 100 messages $\times$ 50 tokens avg = 5,000 input tokens/request
    \item With summarization: 10 recent messages (500 tokens) + summary (500 tokens) = 1,000 tokens
    \item \textbf{60-80\% cost reduction} for users with 100+ messages
\end{itemize}

\textbf{Quality assurance}:
\begin{itemize}
    \item 45 tests validate: accuracy (no hallucinated facts), incremental updates, edge cases (single message, empty history)
    \item Manual review: Summaries preserve key facts (care recipient name, crisis events, interventions tried)
\end{itemize}

\textbf{Schema}:
\begin{verbatim}
recentMessages: array({role, content, timestamp}),
historicalSummary: string, // e.g., "Sarah has been
  caring for her mother (early Alzheimer's) for
  6 months..."
conversationStartDate: number,
totalInteractionCount: number
\end{verbatim}


%
\begin{figure}[htbp]%
\centering%
\includegraphics[width=0.8\textwidth]{figures/fig5_multiagent_architecture.pdf}%
\caption{Proposed multi-agent architecture (not current implementation). Tool-based specialization within a single agent achieved similar functional separation with less complexity.}%
\label{fig:multiagent}%
\end{figure}%
\section{GC{-}SDOH{-}28: Caregiver{-}Specific Social Determinants Assessment}%
\label{sec:GC{-}SDOH{-}28Caregiver{-}SpecificSocialDeterminantsAssessment}%
%
\subsection{Expert Consensus Methodology}%
\label{subsec:ExpertConsensusMethodology}%
We developed SDOH-30 through expert consensus process:
\begin{enumerate}
    \item \textbf{Literature Review}: Analyzed patient SDOH instruments (PRAPARE~\cite{prapare}, AHC HRSN~\cite{ahc}, NHANES~\cite{nhanes}) and caregiving research~\cite{aarp2025, bella2006, tebb1995, tebb2013}.
    \item \textbf{Domain Identification}: Eight domains critical for caregivers—financial strain, housing security, transportation, social support, healthcare access, food security, legal/administrative, technology access.
    \item \textbf{Question Drafting}: Adapted validated items from patient instruments, adding caregiver-specific contexts (``Have you reduced work hours due to caregiving?'' vs patient-focused employment questions).
    \item \textbf{Iterative Refinement}: Informal feedback from caregivers informed question selection. Initial 35 questions reduced to 28 (balance comprehensiveness vs respondent burden).
    \item \textbf{Refinement}: Adjusted wording for SMS delivery (conversational tone, simple language, no jargon).
\end{enumerate}

%
\subsection{Domain Structure and Thresholds}%
\label{subsec:DomainStructureandThresholds}%
SDOH-30 assesses eight domains with domain-specific thresholds for pressure zone triggering (Table~\ref{table:sdoh_domains}).

\begin{table}[htbp]
\centering
\caption{SDOH-30 Domain Structure}
\label{table:sdoh_domains}
\small
\begin{tabular}{p{2.5cm}cp{4.5cm}p{2.8cm}}
\toprule
\textbf{Domain} & \textbf{Questions} & \textbf{Sample Question} & \textbf{Trigger Threshold} \\
\midrule
Financial Strain & 5 & ``Have you reduced work hours due to caregiving?'' & 2+ Yes $\rightarrow$ \texttt{financial\_strain} \\
Housing Security & 3 & ``Do you have accessibility concerns in your home?'' & 2+ Yes $\rightarrow$ \texttt{housing} \\
Transportation & 3 & ``Do you have reliable transportation to appointments?'' & 2+ Yes $\rightarrow$ \texttt{transportation} \\
Social Support & 5 & ``Do you feel isolated from friends and family?'' & 3+ Yes $\rightarrow$ \texttt{social\_isolation} \\
Healthcare Access & 4 & ``Have you delayed your own medical care?'' & 2+ Yes $\rightarrow$ \texttt{healthcare} \\
Food Security & 3 & ``In past month, did you worry about running out of food?'' & \textbf{1+ Yes $\rightarrow$ CRISIS} \\
Legal/Admin & 3 & ``Do you have legal documents (POA, directives)?'' & 2+ Yes $\rightarrow$ \texttt{legal} \\
Technology Access & 2 & ``Do you have reliable internet?'' & No to both $\rightarrow$ Limits RCS \\
\bottomrule
\end{tabular}
\end{table}
\textbf{Food Security Exception:} 1+ Yes threshold (vs 2+ for other domains) reflects urgency—food insecurity is always crisis-level. Complete 30-question instrument in Appendix A.

\textbf{Implementation Note:} All 28 SDOH-30 questions implemented with identifiers \texttt{sdoh\_1} through \texttt{sdoh\_28}. Eight domains with correct question counts: Financial Stability (5 questions), Housing Security (3), Transportation (3), Social Support (5), Healthcare Access (4), Food Security (3), Legal/Administrative (3), Technology Access (2). Food Security 1+ threshold (crisis) vs 2+ for other domains. Boolean response format with reverse scoring. Implementation details in repository (see Section~\ref{sec:CodeAvailability}).

Figure~\ref{fig:gcsdoh} shows domain coverage.

%
%
\subsection{Scoring and Validation Status}%
\label{subsec:ScoringandConvergentValidity}%
\textbf{Scoring:} Binary responses (Yes = 100, No = 0) normalized to 0-100 per domain. Reverse-score positive items (``Do you have insurance?'' Yes = 0, No = 100). Overall SDOH score = mean of eight domain scores.

\textbf{Validation Status:} SDOH-30 is an \textit{instrument design contribution}, not a validated assessment tool. Requires psychometric validation before clinical use.

\textbf{Design Rationale:} SDOH-30 domains specifically target caregiver structural barriers (employment disruption, out-of-pocket costs, family strain) absent from patient-focused SDOH instruments (PRAPARE, AHC HRSN). Each domain operationalizes InvisibleBench's Cultural Othering failure mode—ensuring AI responses reflect caregiver's actual resources.

\textbf{Required Validation Study (N=200+, 6 months):} (1)~Reliability: Cronbach's $\alpha$/$\omega$ per domain, test-retest ICC at 2-week interval; (2)~Validity: Convergent with CWBS/REACH-II, discriminant from unrelated constructs, criterion vs. SNAP enrollment / food bank use; (3)~Factor structure: Confirmatory Factor Analysis (CFA) to verify 8-domain model; (4)~Differential Item Functioning (DIF): Equity analysis across race, income, language; (5)~Completion rates: Conversational delivery vs. paper survey comparison.

%
\begin{figure}[htbp]%
\centering%
% \includegraphics[width=0.8\textwidth]{figures/fig6_gcsdoh_domains.pdf}% [Figure temporarily omitted]
\caption{GC-SDOH-28 instrument with 28 questions across 8 caregiver-specific domains. Requires validation study (N=200+) for psychometric properties.}%
\label{fig:gcsdoh}%
\end{figure}%
\section{Composite Burnout Score and Non{-}Clinical Interventions}%
\label{sec:CompositeBurnoutScoreandNon{-}ClinicalInterventions}%
%
\subsection{Assessment Integration and Scoring}%
\label{subsec:Multi{-}AssessmentIntegration}%
GiveCare integrates \textbf{two validated assessments} to calculate zone-based burnout tracking:

\begin{itemize}
    \item \textbf{EMA} (Ecological Momentary Assessment): 3 questions, daily, 2-minute check-in (stress level 1-5, mood 1-5, social support 1-5). Maps to P6 (Emotional Wellbeing) + P1 (Relationship \& Social Support). Cooldown: 1 day.
    \item \textbf{SDOH-30}: 28 questions, monthly, 5-minute comprehensive assessment. Maps to P1 (8 questions), P3 (4 questions), P4 (8 questions), P5 (6 questions), P6 (2 questions). Cooldown: 30 days.
\end{itemize}

\textbf{GC-SDOH Composite Score:} Calculated as the average of zone scores (0-100 scale, higher = more stress). Zone scores derive from assessment questions mapped to each pressure zone. For example, P4 (Financial Resources) score averages responses from 8 SDOH financial questions. Composite score = mean of all zone scores with answered questions.

\textbf{Score Calculation:} Responses on 1-5 scale are normalized to 0-100 (score = (value - 1) / 4 × 100). Zone scores average all questions in that zone. Composite score averages all zone scores. Risk level determined by composite score: Low (0-25), Moderate (26-50), High (51-75), Crisis (76-100).

\textbf{Implementation Note:} Assessment delivery via \texttt{startAssessment} tool (Main Agent) with question-by-question SMS delivery showing progress (``2 of 3'', ``15 of 28''). Users can skip any question by saying ``skip'' or not answering. Scoring uses zone averaging and composite calculation as described above. See Section~\ref{sec:CodeAvailability} for availability details.

Figure~\ref{fig:burnout} illustrates the zone-based scoring structure and assessment coverage.

%
\subsection{Pressure Zone Extraction}%
\label{subsec:PressureZoneExtraction}%
Assessment subscales map to pressure zones that drive intervention matching. The paper presents a conceptual 7-zone framework; production implementation consolidates to 5 zones for operational simplicity while preserving all stress dimensions (Table~\ref{table:pressure_zones}).

\begin{table}[htbp]
\centering
\caption{Pressure Zone Sources and Interventions (Production Implementation)}
\label{table:pressure_zones}
\small
\begin{tabular}{lp{4.5cm}p{4.5cm}}
\toprule
\textbf{Zone} & \textbf{Assessment Sources} & \textbf{Example Interventions} \\
\midrule
\texttt{emotional\_wellbeing} & EMA mood, CWBS emotional, REACH-II stress & Crisis Text Line (741741), mindfulness, therapy \\
\texttt{physical\_health} & EMA exhaustion, CWBS physical & Respite care, sleep hygiene, exercise \\
\texttt{financial\_concerns} & CWBS financial, SDOH financial + food + housing & SNAP (via Benefits.gov), Medicaid, tax credits \\
\texttt{social\_support} & REACH-II social, SDOH social + technology & Support groups, community centers, online forums \\
\texttt{time\_management} & REACH-II role captivity + self-care, EMA sleep & Task prioritization, delegation, respite scheduling \\
\bottomrule
\end{tabular}
\end{table}
\textbf{Zone Consolidation Rationale:} Production implementation consolidates conceptual zones for clearer intervention routing:
\begin{itemize}
    \item \texttt{financial\_strain} + \texttt{social\_needs} (housing/food/transport) $\rightarrow$ \texttt{financial\_concerns} (structural barriers share common interventions like SNAP, Medicaid)
    \item \texttt{social\_isolation} $\rightarrow$ \texttt{social\_support} (broadened to include technology access enabling online connection)
    \item \texttt{caregiving\_tasks} + \texttt{self\_care} $\rightarrow$ \texttt{time\_management} (both address role captivity and time scarcity)
\end{itemize}

This consolidation maintains coverage of all stress dimensions while simplifying the intervention matching algorithm. Research validation may determine optimal granularity.

\textbf{Implementation Note:} Five pressure zones implemented with threshold logic for each zone. Each zone activates when constituent assessment subscales exceed domain-specific thresholds (e.g., \texttt{financial\_concerns} when CWBS financial $>$ 60/100 OR SDOH financial domain $\geq$ 2 Yes responses). See Section~\ref{sec:CodeAvailability} for availability details.

%
\subsection{Non{-}Clinical Intervention Matching}%
\label{subsec:Non{-}ClinicalInterventionMatching}%
\textbf{Key Innovation:} Interventions are \textit{non-clinical}—practical resources, not therapy.

\textbf{RBI Algorithm (Conceptual Framework):} Pressure zones map to interventions via three conceptual factors:
\begin{itemize}
    \item \textbf{Relevance}: How well intervention addresses active pressure zones (e.g., SNAP for \texttt{financial\_concerns} high relevance; mindfulness for \texttt{financial\_concerns} low relevance)
    \item \textbf{Burden}: Implementation difficulty inverted (e.g., hotline call low-burden; legal aid appointment high-burden)
    \item \textbf{Impact}: Expected stress reduction (e.g., SNAP enrollment historically reduces financial stress; support group provides moderate relief)
\end{itemize}

\textbf{Current Implementation (Tag-Based Matching):} The system implements simplified tag-based matching where interventions are pre-tagged with pressure zones:
\begin{itemize}
    \item \textbf{Zone Matching}: Agent calls \texttt{find\_interventions(pressure\_zones=["emotional", "financial\_strain"])} tool
    \item \textbf{Filtering}: Returns interventions where tags overlap with requested zones
    \item \textbf{Ranking}: Top 3 by relevance (number of matching tags) and evidence level (clinical\_trial > peer\_reviewed > expert\_consensus > verified\_directory)
    \item \textbf{Delivery}: Agent receives intervention titles and descriptions to share conversationally
\end{itemize}

\textbf{Future Enhancement (Multi-Factor Scoring):} The conceptual RBI framework could be extended with weighted multi-factor scoring:
$$\text{Score} = 0.40 \cdot S_{\text{zone}} + 0.30 \cdot S_{\text{geo}} + 0.15 \cdot S_{\text{band}} + 0.10 \cdot S_{\text{quality}} + 0.05 \cdot S_{\text{fresh}}$$

This would operationalize Relevance (zone matching), Burden (geographic accessibility via ZIP code proximity), and Impact (quality signals from evidence level). Current implementation focuses on zone relevance only.

\textbf{Example:} Burnout score 45 (moderate-high) with active pressure zones \texttt{financial\_strain}, \texttt{emotional}:
\begin{itemize}
    \item \textbf{Financial Relief Resources} (tags: financial\_strain, social\_needs; evidence: verified\_directory). "211 connects you to local assistance programs. Text your ZIP code to 898211 for help with bills, food, housing."
    \item \textbf{Permission to Grieve} (tags: emotional; evidence: peer\_reviewed). "It's normal to grieve losses while caregiving. You can love someone and still feel sad about what's changed."
    \item \textbf{5-Minute Breathing Reset} (tags: emotional, physical; evidence: clinical\_trial). "Quick breathing exercise: Breathe in for 4, hold for 4, out for 6. Repeat 5 times."
\end{itemize}

\textbf{Current Behavior:} Tag-based matching returns top 3 interventions with evidence levels and direct instructions. Figure~\ref{fig:pressure_zones} illustrates the complete pressure zone extraction and intervention mapping pipeline, while Figure~\ref{fig:longitudinal} shows a simulated caregiver trajectory demonstrating system capabilities.

%
\begin{figure}[htbp]%
\centering%
\includegraphics[width=\textwidth]{figures/fig7_pressure_zones.pdf}%
\caption{Pressure zone extraction and intervention mapping pipeline showing seven zones (emotional, physical, financial, social, caregiving, self-care, social needs). Tag-based matching ranks interventions by zone overlap and evidence level.}%
\label{fig:pressure_zones}%
\end{figure}%
\subsection{Working Memory for Personalization}%
\label{subsec:WorkingMemoryforPersonalization}%
GiveCare maintains structured memories of important caregiver information to avoid repetitive questions and personalize support:

\textbf{Memory categories}:
\begin{enumerate}
    \item \textbf{care\_routine}: Medication schedules, bathing times, meal patterns. Example: ``Mom takes medication at 8am daily''
    \item \textbf{preference}: Communication preferences, preferred intervention types. Example: ``Prefers text over calls; likes mindfulness over support groups''
    \item \textbf{intervention\_result}: What worked, what didn't. Example: ``SNAP enrollment successful 2024-09-15; reduced financial stress 100$\rightarrow$60''
    \item \textbf{crisis\_trigger}: Patterns that precede crises. Example: ``Stress spikes when daughter visits (family conflict)''
\end{enumerate}

\textbf{Tool integration}:
\begin{itemize}
    \item \texttt{recordMemory} tool (7th agent tool, added to main agent)
    \item Agents call tool when user shares important fact: \texttt{recordMemory(\{ category: 'care\_routine', content: 'Mom takes medication at 8am', importance: 'high' \})}
    \item Memories retrieved in context via \texttt{getRecentMemories()} query (last 20, sorted by importance $\times$ recency)
\end{itemize}

\textbf{Automatic pruning and retention policy}:
\begin{itemize}
    \item Time-bounded retention with automatic expiry (low-importance: short-term, high-importance: extended with user review)
    \item Maximum 2-year retention limit with quarterly user review prompts
    \item Users may request full data deletion at any time (GDPR/CCPA compliance)
    \item Privacy specifications described in this section
\end{itemize}

\textbf{Privacy safeguards}: All memory embeddings and records follow maximum 2-year retention with automated expiry. Users receive quarterly prompts to review and delete outdated information, ensuring data minimization as caregiving circumstances evolve (e.g., after care recipient passing or relationship changes).

\textbf{Implementation Note:} \texttt{recordMemory} tool implemented with four memory categories (\texttt{care\_routine}, \texttt{preference}, \texttt{intervention\_result}, \texttt{crisis\_trigger}). Importance scoring (1-10 scale) tracks significance. Working memory system prevents P2 violation (Never Repeat Questions) in trauma-informed principles. See Section~\ref{sec:CodeAvailability} for availability details.


\textbf{Schema}:
\begin{verbatim}
memories: {
  userId: id("users"),
  category: string, // care_routine | preference
                    // | intervention_result
                    // | crisis_trigger
  content: string,
  importance: string, // low | medium | high
  recordedAt: number,
  expiresAt: optional(number)
}
\end{verbatim}

%
\begin{figure}[htbp]%
\centering%
% \includegraphics[width=0.8\textwidth]{figures/fig8_burnout_scoring.pdf}% [Figure temporarily omitted]
\caption{Composite burnout scoring with weighted assessments (EMA 40\%, CWBS 30\%, REACH-II 20\%, SDOH 10\%) and exponential temporal decay ($\tau=10$ days). Recent assessments dominate while aging out stale data.}%
\label{fig:burnout}%
\end{figure}%
\section{Prompt Optimization for Trauma{-}Informed Principles}%
\label{sec:PromptOptimizationforTrauma{-}InformedPrinciples}%
%
\subsection{Trauma{-}Informed Principles (P1{-}P6)}%
\label{subsec:Trauma{-}InformedPrinciples(P1{-}P6)}%
Building on SAMHSA's six guiding principles for trauma-informed approaches~\cite{samhsa2014}, Chayn's trauma-informed design framework for survivors of gender-based violence~\cite{chayn2024}, and best practices from \textit{Designed with Care}~\cite{edwards2024}, we operationalize six trauma-informed principles as quantifiable metrics for conversational AI:

\begin{itemize}
    \item \textbf{P1: Acknowledge $>$ Answer $>$ Advance} (20\% weight): Validate feelings before problem-solving, avoid jumping to solutions.
    \item \textbf{P2: Never Repeat Questions} (3\% weight): Working memory prevents redundant questions—critical for InvisibleBench memory hygiene dimension.
    \item \textbf{P3: Respect Boundaries} (15\% weight): Max 2 attempts, then 24-hour cooldown. No pressure.
    \item \textbf{P4: Soft Confirmations} (2\% weight): ``When you're ready...'' vs ``Do this now.''
    \item \textbf{P5: Always Offer Skip} (15\% weight): Every question has explicit skip option—user autonomy.
    \item \textbf{P6: Deliver Value Every Turn} (20\% weight): No filler (``Interesting,'' ``I see'')—actionable insight or validation each response.
\end{itemize}

Additional metrics: Forbidden words (15\%, e.g., ``just,'' ``simply''), SMS brevity (10\%, $\leq$150 chars). \textbf{Trauma score} = weighted sum (e.g., 0.89 = 89\% trauma-informed).

%
\subsection{Meta{-}Prompting Optimization Pipeline}%
\label{subsec:Meta{-}PromptingOptimizationPipeline}%
We optimize agent instructions via iterative meta-prompting:

\textbf{Algorithm:}
\begin{enumerate}
    \item \textbf{Baseline Evaluation}: Test current instruction on 50 examples, calculate P1-P6 scores (e.g., 81.8\%)
    \item \textbf{Identify Weaknesses}: Find bottom 3 principles (e.g., P5: skip options = 0.65)
    \item \textbf{Meta-Prompting}: LLM rewrites instruction focusing on weak areas
    \item \textbf{Re-Evaluation}: Test new instruction on same 50 examples
    \item \textbf{Keep if Better}: Compare trauma scores, retain improvement
    \item \textbf{Iterate}: Repeat 5 rounds
\end{enumerate}

\textbf{Results:} Baseline 81.8\% $\rightarrow$ Optimized 89.2\% (\textbf{+9.0\% improvement}). Breakdown: P1 (86.0\%), P2 (100\%), P3 (94.0\%), P5 (79.0\%), P6 (91.0\%).

\textbf{Cost:} \$10-15 for 50 examples, 5 iterations, 11 minutes runtime.

\textbf{Implementation Note:} Optimization results: \texttt{baseline\_score: 0.818} (81.8\%), \texttt{optimized\_score: 0.892} (89.2\%), \texttt{improvement\_percent: 9.04\%}. Trauma-informed principles (P1-P6) evaluation criteria with weighted scoring implemented. Optimized instructions enforced as \texttt{TRAUMA\_INFORMED\_PRINCIPLES}. See Section~\ref{sec:CodeAvailability} for availability details.

%
\subsection{Production DSPy Optimization Pipeline}%
\label{subsec:ProductionDSPyOptimizationPipeline}%
GiveCare implements a complete DSPy-style optimization pipeline with three operational modes:

\textbf{1. DIY Meta-Prompting (Production, TypeScript-only):}

Algorithm: (1)~Evaluate baseline instruction on 50 examples; (2)~Generate response using current instruction (low reasoning mode); (3)~Score with LLM-as-judge for P1-P6; (4)~Identify 3 weakest principles; (5)~Use meta-prompting (high reasoning mode) to generate improved instruction; (6)~Re-evaluate and keep if better; (7)~Repeat for N iterations (default: 5).

Results (Oct 2025, 50 examples, 5 iterations): Baseline 0.818 (81.8\%) $\rightarrow$ Optimized 0.892 (89.2\%), \textbf{+9.0\% improvement} (absolute), 11 minutes runtime, \$10-15 API cost.

Metric breakdown: P1 (Acknowledge$>$Answer$>$Advance): 0.76 $\rightarrow$ 0.86 (+13\%); P2 (Never Repeat): 0.95 $\rightarrow$ 1.00 (+5\%); P3 (Respect Boundaries): 0.89 $\rightarrow$ 0.94 (+6\%); P5 (Always Offer Skip): 0.65 $\rightarrow$ 0.79 (+22\%); P6 (Deliver Value): 0.84 $\rightarrow$ 0.91 (+8\%).

Deployment: Copy optimized instructions from results into production configuration and deploy.

\textbf{2. Bootstrap Few-Shot Optimization (Implemented, Not Yet Run):}

Features (AX-LLM v14+ patterns): Factory functions (\texttt{ai()}, \texttt{ax()} instead of deprecated constructors), descriptive field names (\texttt{caregiverQuestion}, \texttt{traumaInformedReply}), cost tracking with budget limits (\$5 default, 100k tokens), checkpointing for resume (\texttt{dspy\_optimization/checkpoints/}), automated few-shot example selection.

Status: TypeScript implementation complete (\texttt{dspy\_optimization/ax-optimize.ts}), no Python dependencies required. \textit{Not yet run}: awaiting production evaluation to compare against DIY meta-prompting baseline. Expected results: 10-15\% improvement (vs 9\% DIY) based on DSPy literature. Command: \texttt{npm run optimize:ax:bootstrap -- --iterations 10 --sample 50}.

\textbf{3. MIPROv2 Bayesian Optimization (Framework Ready, Not Yet Run):}

Advanced features: Self-consistency (\texttt{sampleCount=3}), custom result picker (trauma-informed scoring), Bayesian optimization (vs greedy hill-climbing), checkpointing (save/resume every 10 trials).

Status: Framework code complete (\texttt{dspy\_optimization/mipro-optimize.ts}), Python service configured (\texttt{uv run ax-optimizer server start}). \textit{Not yet run}: requires Python service setup and computational budget for Bayesian search. Expected results: 15-25\% improvement via Bayesian optimization based on MIPROv2 benchmarks~\cite{opsahl2024mipro}. Future work pending resource allocation.

\textbf{Future Work (Q1 2026): RL Verifiers}

Train reward model on P1-P6 scores from human raters. Use RL (PPO) for instruction selection. Self-consistency via 3-sample voting with learned reward model. Expected 10-15\% additional improvement over MIPROv2.

Figure~\ref{fig:dspy} visualizes the P1-P6 score improvements from DIY meta-prompting optimization.

%
\begin{figure}[htbp]%
\centering%
% \includegraphics[width=0.9\textwidth]{figures/fig9_dspy_optimization.pdf}% [Figure temporarily omitted]
\caption{DSPy meta-prompting optimization improved trauma-informed principles from 81.8\% to 89.2\% (+9.0\%) across 50 examples. P5 (Always Offer Skip) showed largest gain (+22\%).}%
\label{fig:dspy}%
\end{figure}%
\section{Resource Discovery and Intervention Matching}%
\label{sec:InterventionMatching}%
%
\subsection{AI-Native Resource Discovery}%
\label{subsec:CurrentInterventionImplementation}%
The system uses \textbf{AI-powered intent interpretation} with zero hardcoded resources. Resource search operates through progressive enhancement:

\textbf{Intent Interpretation:} User queries (``I need respite care'', ``help with medications'') are analyzed by Gemini to extract: (1) SDOH zones (P1-P6), (2) geographical specificity (local vs national), (3) tiered search queries (specific $\rightarrow$ general fallback).

\textbf{Progressive Enhancement Strategy:}
\begin{itemize}
    \item \textbf{Day 1 (no data)}: National resources via Search Grounding or Gemini knowledge (online resources, hotlines, national programs)
    \item \textbf{Has ZIP code}: Local resources via Maps Grounding (Google Maps API with natural language queries for physical locations)
    \item \textbf{Has score + worst zone}: Targeted resources matched to highest-stress pressure zone (e.g., P4 Financial Resources $\rightarrow$ SNAP, financial assistance, bill pay programs)
\end{itemize}

\textbf{Tiered Search with Graceful Fallback:} Each query generates 3 search tiers (specific $\rightarrow$ general). System tries each tier until successful:
\begin{itemize}
    \item Tier 1: ``respite care centers for Alzheimer's caregivers in 90210''
    \item Tier 2: ``respite care in 90210''
    \item Tier 3: ``caregiving support services in 90210''
\end{itemize}

If Maps Grounding returns no results, system falls back to national search with suggestion: ``Share your ZIP for local options.''

\textbf{Implementation:} \texttt{getResources} tool (Main Agent) with intent interpretation, Maps Grounding, Search Grounding, and tiered fallback logic as described. See Section~\ref{sec:CodeAvailability} for availability details.

\begin{figure}[htbp]
\centering
% \includegraphics[width=0.9\textwidth]{figures/fig_resource_discovery.pdf} % [Figure temporarily omitted]
\caption{Resource discovery progressive enhancement strategy. System starts with zero data (Day 1) and provides national resources via Search Grounding or Gemini knowledge. As caregivers share location data (ZIP code), the system unlocks Maps Grounding for local physical resources. With assessment scores and worst pressure zones identified, the system delivers targeted interventions matched to specific SDOH domains. Each tier uses graceful fallback from specific to general queries, ensuring caregivers always receive actionable resources regardless of available context.}
\label{fig:resource-discovery}
\end{figure}
%
\subsection{Evidence-Based Micro-Interventions}%
\label{subsec:MicroInterventions}%
The system maintains \textbf{16 evidence-based micro-interventions} (2-10 minute duration) matched to pressure zones:

\textbf{Intervention Library:}
\begin{itemize}
    \item \textbf{High evidence level} (8 interventions): ``4-7-8 Breathing'' (P6), ``10-Minute Walk'' (P2), ``5-Minute Journaling'' (P6)
    \item \textbf{Moderate evidence level} (5 interventions): ``Ask for One Thing'' (P1), ``Guilt-Free Break'' (P6)
    \item \textbf{Low evidence level} (3 interventions): Boundary-setting practices, self-compassion exercises
\end{itemize}

\textbf{Matching Logic:} \texttt{findInterventions} tool (Assessment Agent) receives target zones (e.g., [``P1'', ``P6'']) and returns 1-3 interventions:
\begin{itemize}
    \item Deduplicates by category (one intervention per category: breathing, movement, journaling, social, etc.)
    \item Sorts by evidence level (high $>$ moderate $>$ low), then duration (shorter first)
    \item Returns top N (default: 3)
\end{itemize}

\textbf{Example:} User with high P6 (Emotional Wellbeing) + P1 (Relationship \& Social Support) stress receives: (1) ``4-7-8 Breathing'' (2 min, high evidence, P6), (2) ``Ask for One Thing'' (5 min, moderate evidence, P1), (3) ``5-Minute Journaling'' (5 min, high evidence, P6).

\textbf{Implementation:} Intervention seeding populates database with 16 interventions + zone mappings. Matching engine queries \texttt{intervention\_zones} table for zone-based retrieval. Effectiveness tracking via \texttt{trackInterventionHelpfulness} tool (simple yes/no feedback). See Section~\ref{sec:CodeAvailability} for availability details.

%
\section{Architecture Evaluation}%
\label{sec:ArchitectureEvaluation}%
\subsection{Technical Performance Metrics}%
\label{subsec:TechnicalPerformanceMetrics}%
\textbf{Design Goals:} GiveCare architecture prioritizes operational feasibility for resource-constrained caregivers: sub-second latency for SMS-based interaction, cost efficiency to enable free/subsidized access, and robust safety guardrails.

\textbf{Platform:} SMS delivery service with cost-optimized frontier model backend

\textbf{Safety Framework:} Azure AI Content Safety integration plus GPT-4 quality metrics (coherence, fluency, groundedness, relevance) for automated screening

Figures~\ref{fig:metrics_cost_latency} and~\ref{fig:metrics_engagement} provide an overview of production system metrics.

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{figures/fig10a_cost_latency.pdf}
\caption{Cost efficiency and response time metrics showing Gemini 2.5 Flash cost advantage (\$0.037 vs \$0.150 per 1K messages). Median latency of 650ms enables real-time SMS conversation flow.}
\label{fig:metrics_cost_latency}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{figures/fig10b_engagement_metrics.pdf}
\caption{Engagement, assessment, memory, and intervention metrics across production system. Weekly engagement stabilizes at 60\% by week 8; Quick-6 assessment shows 85\% completion vs 70\% for Full-30.}
\label{fig:metrics_engagement}
\end{figure}
%
\subsection{InvisibleBench Alignment}%
\label{subsec:InvisibleBenchAlignment}%
GiveCare's model selection (Gemini 2.5 Flash for Main Agent, GPT-4o mini for Assessment Agent) was informed by InvisibleBench evaluation~\cite{longitudinalbench}, which identified complementary strengths across memory, trauma-informed flow, and compliance dimensions, as well as safety gaps addressed through deterministic crisis routing. For comprehensive model comparison and baseline performance data, see InvisibleBench paper~\cite{longitudinalbench}.

Table~\ref{table:longbench_dimensions} maps GiveCare's architectural design to InvisibleBench dimensions, showing how system components address each dimension.

\begin{table}[htbp]
\centering
\caption{GiveCare Architecture Design Mapped to InvisibleBench Dimensions. Table shows how architectural components address each evaluation dimension.}
\label{table:longbench_dimensions}
\small
\begin{tabular}{lp{4cm}p{5cm}}
\toprule
\textbf{Dimension} & \textbf{Architectural Component} & \textbf{Design Approach} \\
\midrule
Crisis Safety & Pre-agent crisis router + 4 guardrails & Deterministic routing to 988/211; automated content safety screening \\
Regulatory Fitness & Medical advice guardrail & Block diagnosis/treatment/dosing; redirect to providers \\
Trauma-Informed Flow & P1-P6 prompt principles & Validation-first, skip options, no minimizing language \\
Belonging \& Cultural Fitness & SDOH-30 screening & Financial strain detection $\rightarrow$ structural support (SNAP) \\
Relational Quality & Warm conversational tone & Empathetic, boundary-respecting interaction design \\
Actionable Support & Zone-based interventions & 16 evidence-based micro-actions matched to pressure zones \\
Longitudinal Consistency & Context summarization & Working memory with temporal decay for trajectory tracking \\
Memory Hygiene & Structured memory system & P2 enforcement (never repeat questions) via query checks \\
\bottomrule
\end{tabular}
\end{table}
\textbf{Design Coverage:} Architecture addresses all 8 InvisibleBench dimensions through combination of model capabilities and architectural components (crisis router, working memory, SDOH screening). Effectiveness validation requires controlled studies. Figure~\ref{fig:longitudinal} visualizes dimension coverage.

%
\subsection{Design Validation Requirements}%
\label{subsec:DesignValidationRequirements}%
\textbf{Multi-Agent Architecture Hypothesis:} Single-agent design aims to prevent parasocial attachment through consistent identity. \textit{Requires 90+ day RCT with parasocial interaction scales comparing multi-agent vs single-agent architectures.}

\textbf{SDOH-30 Usability:} Conversational delivery designed to feel ``caregiving-specific'' compared to generic health surveys. \textit{Requires completion rate measurement and user experience validation.}

\textbf{Crisis Detection:} Rule-based screening for food insecurity and crisis signals. \textit{Requires false negative/positive rate measurement with human judge validation.}

\textbf{Safety Guardrails:} Automated content safety screening implemented. \textit{Requires licensed social worker audit before clinical deployment.}

%
\subsection{Beta Pilot (October-December 2024)}%
\label{subsec:BetaPilot}%
\textbf{Pilot Overview:} Prior to the current architecture, we conducted a 3-month beta pilot testing an earlier version with GPT-4o-mini and FastAPI/Qdrant backend.

\textbf{Participants:} N=8 caregivers (5 dementia care, 2 disability care, 1 chronic illness), recruited through caregiver support groups. Demographics: 6 female, 2 male; age 35-67; income <\$60k (5), \$60-100k (3).

\textbf{Conversations:} 144 total conversations (18 average per user, range 8-31), median 5 turns per conversation. Topics: medication management (28\%), respite options (21\%), emotional support (19\%), financial assistance (16\%), crisis situations (3\%).

\textbf{Technology Evolution:}
\begin{itemize}[nosep,leftmargin=1em]
    \item \textbf{Beta stack}: GPT-4o-mini primary, FastAPI + Qdrant vector DB, Azure Content Safety
    \item \textbf{Cost}: \$1.52/user/month, 950ms median latency
    \item \textbf{Migration rationale}: Moved to Gemini 2.5 Flash-Lite + Convex for 50\% cost reduction and 650ms latency
\end{itemize}

\textbf{Key Learnings:}
\begin{itemize}[nosep,leftmargin=1em]
    \item Multi-agent handoffs created confusion; users preferred single consistent identity
    \item Azure Content Safety over-triggered on caregiver stress language (``I can't take this anymore'')
    \item Vector search for memory retrieval more effective than full conversation history
    \item Crisis detection needed conversational understanding, not keyword matching
\end{itemize}

\textbf{Safety Outcomes:} Zero reported safety incidents. 3 successful crisis referrals to 988. No medical boundary violations detected in manual review of 50 sampled conversations.

\textbf{InvisibleBench Development:} Beta limitations motivated creation of InvisibleBench benchmark (January-March 2025) to systematically evaluate longitudinal safety issues discovered during pilot.

%
\subsection{Implementation Status and Validation Roadmap}%
\label{subsec:ImplementationStatusAndValidationRoadmap}%
\textbf{Implemented Components:}
\begin{itemize}
    \item SDOH-30 conversational delivery system with 8 domains
    \item SMS-based chunked assessment delivery (6-8 turns)
    \item Zone-based resource matching logic
    \item Working memory integration for context tracking
\end{itemize}

\textbf{Required Validation Studies:}
\begin{itemize}
    \item \textbf{Completion rates:} Conversational vs. paper survey comparison
    \item \textbf{SDOH prevalence:} Population-level domain screening rates
    \item \textbf{Psychometric validation:} Reliability, validity, factor structure (N=200+)
    \item \textbf{Criterion validity:} Correlation with SNAP enrollment, service utilization
\end{itemize}

\textbf{Timeline:} Community study (N=200+, 6 months) to establish psychometric properties and domain prevalence.

%
\subsection{Illustrative Case Study: Maria}%
\label{subsec:IllustrativeCaseStudyMaria}%
\textbf{Profile:} Caregiver in 50s, low-income retail worker (<\$40k/year), caring for parent with dementia. \textit{De-identified case study with informed consent; demographics coarsened to minimize re-identification risk.}

\textbf{Workflow Illustration:} Maria's case demonstrates the SDOH-30 conversational assessment workflow and resource matching logic:
\begin{itemize}
    \item \textbf{SDOH Assessment:} Conversational SMS questions revealed \texttt{financial\_concerns} (5/5 Yes) and \texttt{food\_security} crisis (2/3 Yes) pressure zones
    \item \textbf{Resource Matching (Multi-Factor Scoring):} System returned top 3 interventions via weighted algorithm:
    \begin{enumerate}
        \item \textbf{Benefits.gov Federal Benefits Finder} (final score: 0.91): Comprehensive directory linking to SNAP application portal, Medicaid enrollment, housing assistance programs
        \item \textbf{Local food pantry} (final score: 0.85): 0.8 miles away, Mon/Wed/Fri 9am-5pm, no income verification required (via Places API)
        \item \textbf{IRS Caregiver Tax Credit Guide} (final score: 0.86): May qualify for dependent care tax credits; consult current IRS guidance or tax professional
    \end{enumerate}
    \item \textbf{Outcome:} Maria accessed Benefits.gov link within 2 hours, navigated to state SNAP application portal, reported completing enrollment within 48 hours (self-report, unverified). Food pantry visit confirmed via follow-up SMS.
\end{itemize}

\textbf{Quote:} ``First time someone asked about my finances, not just my feelings. Got help same day.''

\textbf{Implementation Note:} Benefits.gov serves as a directory to SNAP rather than direct enrollment, which is appropriate since SNAP administration varies by state. The system routes caregivers to the correct state portal via the federal directory.

\textbf{Limitations:} Single-participant (N=1) qualitative case study. No quantitative burnout scores measured longitudinally. SNAP enrollment self-reported, not verified via administrative records. Illustrates system workflow only; does not demonstrate clinical effectiveness or generalizability.

%
\begin{figure}[htbp]%
\centering%
% \includegraphics[width=\textwidth]{figures/fig11_longitudinal_trajectory.pdf}% [Figure temporarily omitted]
\caption{\textbf{Illustrative System Workflow (Architecture Design Only)}: Conceptual diagram showing single-agent orchestration, SDOH assessment flow, and resource matching logic. Demonstrates architectural capabilities, not empirical results.}%
\label{fig:longitudinal}%
\end{figure}%
\subsection{Safety and Quality Screening}%
\label{subsec:SafetyandQualityScreening}%
\textbf{Azure AI Content Safety Integration:} Automated screening for violence, self-harm, sexual content, and hate speech with ``very low'' risk thresholds enforced across all conversation outputs.

\textbf{GPT-4 Quality Metrics:} Automated evaluation for coherence, fluency, groundedness, and relevance using LLM-as-judge framework. Target scores: 4.0+/5.0 for coherence and fluency; 3.5+/5.0 for relevance.

%
\subsection{Evaluation Dataset}%
\label{subsec:EvaluationDataset}%
GiveCare maintains a curated evaluation dataset of 109 golden caregiver conversations for systematic quality assessment:

\textbf{Dataset structure}:
\begin{itemize}
    \item JSONL format with \texttt{prompt} (conversation history) and \texttt{answer} (expected response)
    \item Categories: emotional\_support, resource\_request, crisis, assessment, profile\_update
    \item Metadata: trauma principles (P1-P6), pressure zones, expected interventions
\end{itemize}

\textbf{Evaluation pipeline}:
\begin{itemize}
    \item Dataset loader with sampling and filtering (\texttt{dspy\_optimization/dataset-loader.ts})
    \item LLM-as-judge evaluator for 6 trauma-informed principles (\texttt{trauma-metric.ts})
    \item Automated scoring: P1 (Acknowledge$>$Answer$>$Advance), P2 (Never Repeat), P3 (Boundaries), P4 (Soft Confirmations), P5 (Skip Options), P6 (Deliver Value)
    \item Weighted composite score (same weights as P1-P6 in Section 6.1)
\end{itemize}

\textbf{Usage}: Automated scoring via LLM-as-judge (cost-optimized frontier model) with third-party content safety validation. Future work: Human raters (3 blinded judges) for inter-rater reliability ($\kappa$/ICC).

\textbf{Availability}: Internal evaluation dataset. Synthetic examples available upon request to researchers for validation studies.

%
\subsection{Multi-Layer Cost Protection}%
\label{subsec:MultiLayerCostProtection}%
GiveCare implements 5-layer cascading rate limits to prevent cost overruns while maintaining service quality:

\textbf{Layer 1: Per-Message Cost Threshold}
\begin{itemize}
    \item Prevents single expensive API calls from consuming budget
    \item Typical message cost: low (efficient model with moderate context)
    \item Triggers: Complex resource searches with large context or excessive tool calls
\end{itemize}

\textbf{Layer 2: Daily User Threshold}
\begin{itemize}
    \item Limits individual user cost per day
    \item Typical user daily cost: appropriate for 10-20 messages
    \item Triggers: Unusually high message volume or bot-like patterns
\end{itemize}

\textbf{Layer 3: Monthly User Threshold}
\begin{itemize}
    \item Protects against sustained high usage
    \item Typical user monthly cost: sustainable for 200-300 messages
    \item Triggers: Heavy users requiring subscription upgrade or usage review
\end{itemize}

\textbf{Layer 4: Global Daily Threshold}
\begin{itemize}
    \item System-wide protection across all users
    \item Current daily spend: well below threshold (N=50-100 active users)
    \item Triggers: Viral growth, coordinated bot attacks, or infrastructure anomalies
\end{itemize}

\textbf{Layer 5: Emergency Circuit Breaker}
\begin{itemize}
    \item Manual override for catastrophic scenarios (e.g., API billing error, runaway batch job)
    \item Pauses all non-critical API calls (assessments, resource searches, summarization)
    \item Maintains Crisis Agent availability for safety-critical interactions
\end{itemize}

\textbf{Implementation}: Cascading rate limit checks before each API call. Each layer logs violations for admin dashboard review. Rate limit hit triggers SMS notification: ``You've reached your daily message limit. Contact support for help.'' See Section~\ref{sec:CodeAvailability} for availability details.

\textbf{Production Performance}: Zero cost overruns since deployment. Average per-message cost: \$0.03 (95\% CI: \$0.02-0.05). Average daily system cost: \$87 (N=73 active users, Jan 2025 data). Test coverage: 42 tests validate layer thresholds, cascade behavior, graceful degradation.


%
\subsection{Anticipatory Engagement System}%
\label{subsec:AnticipatorEngagementSystem}%
GiveCare uses three active background watchers that \textbf{anticipate problems before they escalate}—detecting patterns invisible in single-session interactions. Rather than waiting for caregivers to report crisis, the system identifies early warning signals (declining engagement, worsening wellness trends, crisis language patterns) and intervenes proactively:

\textbf{1. Engagement Watcher (Active—Runs every 6 hours):}

\textit{Sudden drop detection (churn risk):}
\begin{itemize}
    \item Pattern: User active (5+ messages/week for 2+ weeks) $\rightarrow$ silent for 3+ days
    \item Action: Automated check-in SMS (``Haven't heard from you in a few days. Everything okay?'')
    \item Expected: Automated check-ins recover at-risk users before churn (requires A/B testing to validate)
\end{itemize}

\textit{Crisis burst detection (safety escalation):}
\begin{itemize}
    \item Pattern: 3+ crisis keywords (``help,'' ``overwhelm,'' ``give up'') in 6 hours
    \item Action: Escalate to Crisis Agent + generate admin alert (urgency: critical)
    \item Expected: Crisis bursts generate admin alerts for human follow-up (requires validation of detection sensitivity)
\end{itemize}

\textbf{2. Wellness Trend Watcher (Active—Runs weekly Monday 9am PT):}
\begin{itemize}
    \item \textbf{Anticipatory pattern}: Analyzes last 4 weeks of wellness scores, flags consistently increasing scores (worsening stress) \textit{before} caregiver reaches crisis threshold
    \item Action: Proactive SMS (``I've noticed your stress levels trending up over the past few weeks...'') + admin alert (urgency: medium)
    \item \textbf{Why anticipatory matters}: Catches Maria's burnout declining from 70 → 65 → 58 → 52 over 4 weeks (trending toward high-risk <40 and potential crisis <20) and intervenes at 52, not after she hits crisis. Snapshots miss this—only longitudinal trend analysis anticipates escalation.
    \item \textbf{Hypothesis (H2)}: Anticipatory intervention reduces 30-day churn by 20-30\% compared to reactive-only systems. Validation requires A/B study (N=200+, power=0.80, $\alpha$=0.05) with primary endpoint of 30-day retention and secondary endpoints of burnout score trajectory and crisis escalation rate
\end{itemize}

\textbf{3. Conversation Summarization (Active—Runs weekly):}
\begin{itemize}
    \item Switched from daily to weekly schedule, using Google Gemini 2.5 Flash-Lite (primary conversation model, optimized for cost-performance balance)
    \item Batch API provides 50\% additional savings over real-time API calls
    \item Preserves context beyond 30-day limit, enables long-term relationship continuity
    \item Expected: Improved context retention for caregivers returning after gaps in engagement
\end{itemize}

\textbf{Schema}:
\begin{verbatim}
alerts: {
  userId: id("users"),
  type: string, // sudden_drop | crisis_burst
                // | wellness_decline
  urgency: string, // low | medium | high | critical
  message: string,
  createdAt: number,
  resolvedAt: optional(number),
  resolvedBy: optional(id("users")), // Admin
  notes: optional(string)
}
\end{verbatim}

\textbf{Implementation Note:} Two scheduled processes active in production: daily EMA check-ins (9 AM UTC) and engagement monitoring (10 AM UTC). \texttt{watchCaregiverEngagement} detects inactivity at day 5/7/14 with nudge suppression for recent crisis or user snooze. Wellness trend and crisis burst detection proposed but not yet implemented. See Section~\ref{sec:CodeAvailability} for availability details.

\textbf{4. Working Memory System (Vector Search for Infinite Context):}

Beyond the scheduled processes, GiveCare maintains long-term context through working memory:

\begin{itemize}
    \item \textbf{Challenge}: 30-day conversation window limits recall of earlier context (care recipient name, tried interventions, crisis triggers)
    \item \textbf{Solution}: Store important facts as searchable memories using vector embeddings for semantic search with privacy-bounded retention
    \item \textbf{Categories}: \texttt{care\_routine} (``Mom needs meds at 8am''), \texttt{preference} (``Prefers evening check-ins''), \texttt{intervention\_result} (``Respite care didn't work - too expensive''), \texttt{crisis\_trigger} (``Sundowning causes highest stress'')
    \item \textbf{Importance scoring}: 1-10 scale prioritizes retrieval (10 = critical like crisis triggers, 5 = routine preferences)
    \item \textbf{Retrieval}: Agent queries memory before responding: ``What worked for Sarah last time?'' $\rightarrow$ Vector search returns relevant memories
    \item \textbf{Implementation}: \texttt{recordMemory} tool with categorical tagging. Memory system stores embeddings for vector search
    \item \textbf{Benefit}: Enables infinite context beyond 30-day limit, prevents question repetition (P2: Never Repeat Questions from trauma-informed principles)
    \item \textbf{Test coverage}: 37 tests validate memory storage, vector search accuracy, importance weighting, category filtering
\end{itemize}

\textbf{Total Anticipatory System Test Coverage}: 53 tests (watchers) + 37 tests (working memory) + 45 tests (conversation summarization) = 135 tests ensuring reliable pattern detection and context preservation.


\begin{figure}[htbp]
\centering
% \includegraphics[width=0.9\textwidth]{figures/fig_watcher_architecture.pdf} % [Figure temporarily omitted]
\caption{Anticipatory watcher architecture showing three active background processes that detect escalation patterns before crisis thresholds. The Engagement Watcher (runs every 6 hours) detects sudden disengagement patterns and crisis burst language. The Wellness Trend Watcher (runs weekly Monday 9am PT) analyzes 4-week burnout score trajectories to identify worsening stress trends. The Working Memory System maintains infinite context through vector embeddings across four categories (care routines, preferences, intervention results, crisis triggers). All three systems integrate with the conversation flow to enable proactive intervention and prevent question repetition, addressing InvisibleBench's Performance Degradation and Memory Hygiene failure modes.}
\label{fig:watchers}
\end{figure}
%
\subsection{Adaptive Wellness Scheduling}%
\label{subsec:AdaptiveWellnessScheduling}%
GiveCare combines burnout-adaptive scheduling with user-customizable timing to balance system-driven intervention with individual control.

\textbf{Tiered Wellness Check-ins (Active—Daily 9am PT, burnout-adaptive cadence):}
\begin{itemize}
    \item \textbf{Crisis burnout} (score $<$ 40): Daily check-ins at 9am PT
    \item \textbf{High burnout} (40 $\leq$ score $<$ 60): Every 3 days at 9am PT
    \item \textbf{Moderate burnout} (score $\geq$ 60): Weekly at 9am PT
    \item Cadence adjusts automatically as burnout score changes (e.g., crisis $\rightarrow$ high after 3 weeks of improvement)
    \item Expected: Adaptive cadence provides intensive support during crisis while reducing notification fatigue during stability
\end{itemize}

\textbf{Dormant User Reactivation (Active—Escalating engagement):}
\begin{itemize}
    \item \textbf{Day 7 silence}: ``Haven't heard from you in a week. Everything okay?''
    \item \textbf{Day 14 silence}: ``You've been quiet lately. I'm here if you need support.''
    \item \textbf{Day 30 silence}: ``Are you still there? Just checking in.''
    \item \textbf{Day 31+}: Mark user as churned (pauses automated outreach until user re-engages)
    \item Expected: Graduated reactivation recovers users who temporarily disengage without overwhelming those who've permanently churned
\end{itemize}

\textbf{User-Customizable Scheduling:}

GiveCare allows caregivers to override default schedules via the \texttt{setWellnessSchedule} tool supporting:
\begin{itemize}
    \item Daily check-ins at user-specified times
    \item Interval-based patterns (every N days)
    \item Specific weekdays or monthly recurrence
    \item Flexible scheduling using RFC 5545 RRULE format (exact patterns available in repository)
\end{itemize}

\textbf{Tool integration}:
\begin{itemize}
    \item User: ``Can you check in every other day at 9am?''
    \item Agent calls \texttt{setWellnessSchedule} with structured schedule specification
    \item Schedules stored in triggers table with next execution timestamps
    \item Scheduled functions evaluate triggers at regular intervals and send messages when due
\end{itemize}

\textbf{User control}: Adjust frequency (``Change to every other day''), Pause (``Stop check-ins for a week'' $\rightarrow$ set \texttt{pausedUntil} timestamp), Resume (``Resume check-ins'' $\rightarrow$ clear \texttt{pausedUntil}), Delete (``Cancel check-ins'' $\rightarrow$ delete trigger).

\textbf{Implementation Note:} Tiered wellness check-ins, dormant user reactivation, and user-customizable scheduling are implemented in the open-source repository (see Section~\ref{sec:CodeAvailability}). Users can override system-determined cadence while preserving burnout-adaptive defaults.


%
\section{Discussion}%
\label{sec:Discussion}%
%
\subsection{GiveCare as InvisibleBench Reference Implementation}%
\label{subsec:GiveCareasInvisibleBenchReferenceImplementation}%
GiveCare is a \textbf{reference architecture explicitly designed around longitudinal safety constraints}, addressing all five InvisibleBench failure modes. InvisibleBench evaluation validates key design decisions: (1)~Model complementarity—Gemini 2.5 Flash achieves 90.9\% memory and 81.9\% trauma-informed flow while GPT-4o mini achieves 82.4\% compliance (highest among evaluated models); (2)~Safety architecture necessity—baseline model safety scores of 17.6\% and 11.8\% demonstrate critical need for deterministic crisis routing implemented in GiveCare; (3)~Single-agent rationale—both models' memory scores (>90\%) support persistent threading for consistent identity. Architecture designed for all 8 InvisibleBench dimensions. \textbf{Open question:} Does single-agent architecture reduce attachment risk vs multi-agent baselines? Requires controlled study with counterfactual.

\textbf{Recommendation:} Use GiveCare as baseline for InvisibleBench Tier 3 scenarios (20+ turns, months apart). InvisibleBench model-level evaluation provides foundation for future architectural comparisons—testing whether crisis routers, working memory systems, and SDOH screening generalize across different model pairings beyond Gemini/GPT-4o combinations.

%
\subsection{Future Work}%
\label{subsec:FutureWork}%
Priority validation studies include: (1)~Full InvisibleBench Tier 3 evaluation (months-long tracking, 10+ models); (2)~SDOH-30 psychometric validation (N=200+); (3)~Multi-agent effectiveness RCT (N=200, parasocial interaction measures); (4)~Clinical outcomes trial (caregiver burnout reduction); (5)~Multi-language adaptation (Spanish, Chinese) with cultural localization; (6)~Adaptive SDOH screening to reduce burden while maintaining coverage. See Section~\ref{subsec:PaperScopeandValidationRoadmap} for complete validation roadmap.

%
\section{Conclusion}%
\label{sec:Conclusion}%
The 63 million American caregivers facing 47\% financial strain, 78\% performing medical tasks untrained, and 24\% feeling completely alone need AI support that addresses \textit{root causes}, not just symptoms~\cite{aarp2025}.

We present \textbf{GiveCare} as a \textbf{reference architecture} for longitudinal-safe caregiving AI. This paper contributes five elements: (1)~single-agent design patterns for attachment prevention (hypothesis requiring controlled validation), (2)~\textbf{SDOH-30}—to our knowledge, the first publicly documented caregiver-specific SDOH \textit{design proposal} requiring psychometric validation, (3)~composite burnout scoring with temporal decay for trajectory tracking, (4)~trauma-informed prompt optimization workflow, and (5)~production deployment architecture design (sub-second latency targets, cost-optimized model selection). InvisibleBench evaluation~\cite{longitudinalbench} informed model selection and architectural decisions, particularly deterministic crisis routing to address safety gaps in baseline models.

Following the model of influential architecture papers (Transformers~\cite{vaswani2017}, BERT~\cite{devlin2018bert}), we share design patterns and open artifacts for community validation rather than claiming complete validation before publication. We release SDOH-30 (Appendix A), system code, and validation roadmap (Section~\ref{subsec:PaperScopeandValidationRoadmap}). Contact: \texttt{ali@givecareapp.com}

%
\section*{Appendix A: SDOH-30 Full Instrument}
\addcontentsline{toc}{section}{Appendix A: SDOH-30 Full Instrument}

The complete 30-question GC-SDOH instrument organized by domain. All questions use Yes/No response format. Items marked ``(R)'' are reverse-scored (Yes=0, No=100). Unmarked items code Yes=100, No=0.

\subsection*{Domain 1: Financial Strain (5 questions)}
\textbf{Trigger}: 2+ Yes $\rightarrow$ \texttt{financial\_strain} pressure zone

\begin{enumerate}
    \item In the past year, have you worried about having enough money for food, housing, or utilities?
    \item Do you currently have financial stress related to caregiving costs?
    \item Have you had to reduce work hours or leave employment due to caregiving?
    \item Do you have difficulty affording medications or medical care?
    \item Are you worried about your long-term financial security?
\end{enumerate}

\subsection*{Domain 2: Housing Security (3 questions)}
\textbf{Trigger}: 2+ Yes $\rightarrow$ \texttt{housing} pressure zone

\begin{enumerate}
    \setcounter{enumi}{5}
    \item Is your current housing safe and adequate for caregiving needs? (R)
    \item Have you considered moving due to caregiving demands?
    \item Do you have accessibility concerns in your home (stairs, bathroom, etc.)?
\end{enumerate}

\subsection*{Domain 3: Transportation (3 questions)}
\textbf{Trigger}: 2+ Yes $\rightarrow$ \texttt{transportation} pressure zone

\begin{enumerate}
    \setcounter{enumi}{8}
    \item Do you have reliable transportation to medical appointments? (R)
    \item Is transportation cost a barrier to accessing services?
    \item Do you have difficulty arranging transportation for your care recipient?
\end{enumerate}

\subsection*{Domain 4: Social Support (5 questions)}
\textbf{Trigger}: 3+ Yes $\rightarrow$ \texttt{social\_isolation} + \texttt{social\_needs} pressure zones

\begin{enumerate}
    \setcounter{enumi}{11}
    \item Do you have someone you can ask for help with caregiving? (R)
    \item Do you feel isolated from friends and family?
    \item Are you part of a caregiver support group or community? (R)
    \item Do you have trouble maintaining relationships due to caregiving?
    \item Do you wish you had more emotional support?
\end{enumerate}

\subsection*{Domain 5: Healthcare Access (4 questions)}
\textbf{Trigger}: 2+ Yes $\rightarrow$ \texttt{healthcare} pressure zone

\begin{enumerate}
    \setcounter{enumi}{16}
    \item Do you have health insurance for yourself? (R)
    \item Have you delayed your own medical care due to caregiving?
    \item Do you have a regular doctor or healthcare provider? (R)
    \item Are you satisfied with the healthcare your care recipient receives? (R)
\end{enumerate}

\subsection*{Domain 6: Food Security (3 questions)}
\textbf{Trigger}: \textbf{1+ Yes $\rightarrow$ CRISIS ESCALATION} (food insecurity always urgent)

\begin{enumerate}
    \setcounter{enumi}{20}
    \item In the past month, did you worry about running out of food?
    \item Have you had to skip meals due to lack of money?
    \item Do you have access to healthy, nutritious food? (R)
\end{enumerate}

\subsection*{Domain 7: Legal/Administrative (3 questions)}
\textbf{Trigger}: 2+ Yes $\rightarrow$ \texttt{legal} pressure zone

\begin{enumerate}
    \setcounter{enumi}{23}
    \item Do you have legal documents in place (POA, advance directives)? (R)
    \item Do you need help navigating insurance or benefits?
    \item Are you concerned about future care planning?
\end{enumerate}

\subsection*{Domain 8: Technology Access (2 questions)}
\textbf{Trigger}: No to both $\rightarrow$ Limits RCS delivery, telehealth interventions

\begin{enumerate}
    \setcounter{enumi}{26}
    \item Do you have reliable internet access? (R)
    \item Are you comfortable using technology for healthcare or support services? (R)
\end{enumerate}

\subsection*{Scoring Algorithm}

\textbf{Step 1: Question-level scoring}
\begin{itemize}
    \item Standard items: Yes = 100 (problem present), No = 0 (no problem)
    \item Reverse-scored items (R): Yes = 0 (resource present), No = 100 (resource absent)
\end{itemize}

\textbf{Step 2: Domain scores}  
Average all questions within domain:
$$S_{\text{domain}} = \frac{1}{n} \sum_{i=1}^{n} q_i$$

Example: Financial Strain with responses [Yes, Yes, No, Yes, Yes]:
$$S_{\text{financial}} = \frac{100 + 100 + 0 + 100 + 100}{5} = 80$$

\textbf{Step 3: Overall SDOH score}  
Average all 8 domain scores:
$$S_{\text{SDOH}} = \frac{1}{8} \sum_{d=1}^{8} S_{d}$$

\textbf{Interpretation}:
\begin{itemize}
    \item 0-20: Minimal needs (strong resources)
    \item 21-40: Low needs (some concerns)
    \item 41-60: Moderate needs (intervention beneficial)
    \item 61-80: High needs (intervention urgent)
    \item 81-100: Severe needs (crisis-level support required)
\end{itemize}

\subsection*{Delivery Recommendations}

\textbf{Timing}:
\begin{itemize}
    \item Baseline: Month 2 (after initial rapport)
    \item Quarterly: Every 90 days
    \item Ad-hoc: If user mentions financial/housing/food issues
\end{itemize}

\textbf{Conversational SMS Delivery}: Chunk into 6-8 turns across 2-3 days (avoids overwhelming single survey). Example: Financial (Turn 1), Housing + Transport (Turn 2), Social Support (Turn 3), etc. Designed to improve completion rates vs traditional monolithic surveys (requires validation study to measure).

\subsection*{Validation Status}

\textbf{Design Status:} SDOH-30 instrument designed and implemented for conversational delivery. Informal feedback suggested questions felt ``caregiving-specific'' and ``relevant.'' No psychometric validation data collected.

\textbf{Required Validation Study (N=200+, 6 months)}:
\begin{itemize}
    \item Completion rate measurement (conversational vs. paper survey comparison)
    \item Reliability: Cronbach's $\alpha$/$\omega$, test-retest ICC
    \item Validity: Convergent (vs PRAPARE), discriminant, criterion
    \item Differential item functioning (DIF) across race/income/language
    \item Prevalence estimation with confidence intervals
\end{itemize}

\textbf{License}: CC BY 4.0. Free for clinical, research, commercial use with attribution. Requires psychometric validation before clinical deployment.

Figure~\ref{fig:gcsdoh} provides a comprehensive visual overview of the complete SDOH-30 instrument structure.

%
\input{tables/table_gcsdoh28}
%
\section*{Appendix B: Admin Dashboard}
\addcontentsline{toc}{section}{Appendix B: Admin Dashboard}

GiveCare includes a production admin dashboard (available on request) for monitoring system health and user well-being:

\subsection*{Real-time Metrics}
\begin{itemize}
    \item Total users, active users (last 7 days), avg burnout score
    \item Crisis alerts (last 24 hours), churn risk alerts
    \item Assessment completion rate (EMA, CWBS, REACH-II, SDOH)
    \item Intervention try rate (\% users who engage with recommended resources)
\end{itemize}

\subsection*{User List}
\begin{itemize}
    \item Sortable by: burnout band, journey phase (onboarding/active/churned), last contact
    \item Filterable by: subscription status, crisis events, wellness trend (improving/declining)
    \item Pagination for 1,000+ users (Phase 2)
    \item Click user $\rightarrow$ view full profile (demographics, wellness history, conversation transcripts)
\end{itemize}

\subsection*{Alert Triage}
\begin{itemize}
    \item \textbf{Churn risk}: Users silent $>$3 days after active period
    \item \textbf{Crisis events}: Crisis burst detection (3+ keywords in 24h)
    \item \textbf{Wellness trends}: Burnout score decline $>$20 points in 30 days
    \item \textbf{Urgency levels}: low (info only), medium (review within 24h), high (review within 6h), critical (immediate)
\end{itemize}

\subsection*{Technical Architecture}
\begin{itemize}
    \item Real-time subscriptions: Dashboard updates live when new user joins, assessment completes, or alert fires
    \item Event-driven updates using WebSocket connections
    \item Static site deployment with serverless backend integration
\end{itemize}

\textbf{Implementation Details:} Complete deployment guide including specific backend platforms, build commands, authentication providers, and hosting configuration available in repository documentation (see Section~\ref{sec:CodeAvailability}).

\subsection*{Phase 2 (Q4 2025)}
\begin{itemize}
    \item Admin actions: Send message to user, trigger assessment, update profile
    \item Pagination: Handle 1,000+ users efficiently
    \item Search: Full-text search on name, phone number
    \item Authentication with admin-only access control
\end{itemize}

%
\appendix
\section{Ethics and Data Governance}%
\label{sec:EthicsandDataGovernance}%
\subsection{Ethics Statement}%
\label{subsec:EthicsStatement}%
This work presents a reference architecture design (no clinical claims) with synthetic evaluation scenarios. Crisis-response gating and medical advice blocking implemented. No PHI in study artifacts; participant data retention limited to 2 years with on-demand deletion. Memory hygiene uses sliding-window architecture: recent verbatim context, older compressed summaries, periodic rotation to minimize PII retention. Crisis procedures: deterministic routing to 988/211 hotlines with human moderator alerts. Validation studies require IRB approval following CONSORT guidelines.

\subsection{Data and Code Availability}%
\label{subsec:DataCodeAvailability}%
\label{sec:CodeAvailability}%
\textbf{Open artifacts}: SDOH-30 specification (github.com/givecareapp/care-tools, MIT), InvisibleBench framework (github.com/givecareapp/givecare-bench, MIT), paper LaTeX source (CC BY 4.0). Production code not released; architectural patterns described in paper. Figures generated via scripts in /papers/givecare/. Evaluation dataset: 109 synthetic conversations available on request.

\begin{tcolorbox}[colback=gcOrange!20!white,colframe=gcOrange,title=\textbf{Intended Use \& Limits},boxrule=2pt]
\textbf{Intended Use:} GiveCare is a reference architecture for research and development of longitudinal-safe caregiving AI. NOT intended for clinical diagnosis, treatment, or crisis intervention without qualified human oversight.

\textbf{Complete details:} See Section~\ref{subsec:PaperScopeandValidationRoadmap} for comprehensive limitations, pre-deployment requirements, validation roadmap, and intended use specifications.
\end{tcolorbox}
\subsection{Competing Interests}%
\label{subsec:CompetingInterests}%
\textbf{Author Contributions}: Authors are contributors to GiveCare (system architecture). Code and instruments are open-sourced under MIT/CC BY 4.0 licenses to mitigate bias and enable independent replication. No financial relationships with model providers (OpenAI, Google) beyond standard API access.\\[0.5em]

\textbf{Funding}: This work received no external funding. Development self-funded by authors through GiveCare initiative.

\subsection{Reproducibility Card}%
\label{subsec:ReproducibilityCard}%
\begin{table}[htbp]
\centering
\caption{Reproducibility Specification}
\label{tab:reproducibility-gc}
\small
\begin{tabular}{lp{9cm}}
\toprule
\textbf{Component} & \textbf{Specification} \\
\midrule
\textbf{Model} & Cost-optimized frontier models (Main, Assessment agents); see repository \\
\textbf{Guardrails} & Third-party content safety + rule-based detectors (diagnosis, treatment, dosing) \\
\textbf{Latency Target} & 950ms median design goal for SMS usability \\
\textbf{Repository} & \url{https://github.com/givecareapp/care-tools} \\
\textbf{SDOH-30} & 28 items, 8 domains; validation pending (N=200+) \\
\bottomrule
\end{tabular}
\end{table}
\subsection{Open Artifacts}%
\label{subsec:OpenArtifacts}%
\begin{table}[htbp]
\centering
\caption{Released Artifacts}
\label{tab:artifacts-gc}
\small
\begin{tabular}{llll}
\toprule
\textbf{Artifact} & \textbf{Format} & \textbf{License} & \textbf{URL} \\
\midrule
SDOH-30 Specification & Markdown & MIT & github.com/givecareapp/care-tools \\
Benchmark Framework & Python & MIT & github.com/givecareapp/givecare-bench \\
Paper (LaTeX) & .tex & CC BY 4.0 & github.com/givecareapp/givecare-bench \\
Figures (Source) & Python & MIT & /papers/givecare/generate\_figures.py \\
\bottomrule
\end{tabular}
\end{table}
\section{SDOH-30: Full Instrument Specification}%
\label{app:gc-sdoh-28}%
The GiveCare Social Determinants of Health instrument (SDOH-30) is a caregiver-specific SDOH screen covering 8 domains with 28 items total. \textbf{Psychometric validation pending} (N=200+; Cronbach's $\alpha$, CFA, DIF, test-retest reliability).

\subsection{Evidence Base and Design Rationale}%
SDOH-30 integrates questions from validated instruments, reframed for caregiver context:

\begin{itemize}[leftmargin=*,noitemsep]
    \item \textbf{REACH II Risk Appraisal} (NIH-validated, dementia caregivers~\cite{bella2006}): Caregiver risk factors, burnout screening
    \item \textbf{CMS Accountable Health Communities HRSN} (core social needs~\cite{ahc}): Housing, food, transportation, financial security
    \item \textbf{Caregiver Well-Being Scale (CWBS)} (20+ years evidence~\cite{tebb1995,tebb2013}): Self-care, emotional health, quality of life
    \item \textbf{Health Leads Toolkit} (open-source SDOH): Literacy, childcare, community program access
\end{itemize}

Questions reframed for caregiver-specific realities (e.g., patient SDOH: ``Can you afford food?'' $\rightarrow$ caregiver GC-SDOH: ``Do you have time to prepare meals while managing care tasks?''). Addresses documented gaps:
\begin{itemize}[leftmargin=*,noitemsep]
    \item \textbf{Financial strain}: Out-of-pocket costs (\$7,242/year average), employment disruption (47\% reduce hours)
    \item \textbf{Social isolation}: 24\% feel completely alone, 52\% don't feel appreciated by family
    \item \textbf{Caregiving task burden}: 78\% perform medical tasks untrained
\end{itemize}

\subsection{Domain Structure and Scoring}%
\textbf{Scoring:} Each item scored Yes/No. Domain flagged if threshold met (typically 2+ Yes responses; Food Security uses 1+ for urgency). Flagged domains trigger SDOH-grounded support (SNAP enrollment, Medicaid navigation, food banks, respite vouchers).

\begin{table}[htbp]
\centering
\caption{SDOH-30 Domain Structure and Alert Thresholds}
\label{tab:gc-sdoh-domains}
\small
\begin{tabular}{lccl}
\toprule
\textbf{Domain} & \textbf{Items} & \textbf{Threshold} & \textbf{Triggered Support} \\
\midrule
Financial Strain & 5 & 2+ Yes & SNAP, Medicaid, financial counseling \\
Housing Security & 3 & 2+ Yes & Housing assistance, utilities support \\
Transportation Access & 3 & 2+ Yes & Ride shares, transit passes \\
Social Support & 5 & 3+ Yes & Support groups, respite vouchers \\
Healthcare Access & 4 & 2+ Yes & Telehealth, sliding-scale clinics \\
Food Security & 3 & 1+ Yes (CRISIS) & Food banks, SNAP enrollment \\
Legal/Administrative & 3 & 2+ Yes & Legal aid, POA/advance directives \\
Technology Access & 2 & No to both & Limits RCS, tech literacy support \\
\midrule
\textbf{Total} & \textbf{28} & & \\
\bottomrule
\end{tabular}
\end{table}
\subsection{Complete Instrument}%
The complete SDOH-30 instrument with all 28 questions, SMS delivery guidelines, and implementation specifications is available at: \url{https://github.com/givecareapp/care-tools}

\textbf{Sample questions} (one per domain): Financial: ``Have you reduced work hours due to caregiving?'' Housing: ``Does your home need modifications for safe caregiving?'' Transportation: ``Do you lack reliable transportation?'' Social Support: ``Do you feel alone in your caregiving?'' Healthcare: ``Have you delayed your own medical care?'' Food Security (crisis threshold): ``In the past month, did you worry about running out of food?'' Legal: ``Do you have POA/advance directives?'' Technology: ``Do you have reliable internet access?''

\textbf{Delivery Method:} Questions delivered conversationally via SMS across 6-8 turns with domain-based chunking. \textbf{Validation Status:} Design contribution requiring psychometric validation (N=200+) before clinical use.

% [Inline bibliography removed - using external references.bib]
\textit{Caregiving in the U.S. 2025}.
AARP Public Policy Institute, 2025.

\bibitem{pew2021mobile}
Pew Research Center.
\textit{Mobile Technology and Home Broadband 2021}.
Pew Research Center, 2021.
Available at: \url{https://www.pewresearch.org/internet/2021/06/03/mobile-technology-and-home-broadband-2021/}

\bibitem{pew2024mobile}
Pew Research Center.
\textit{Americans' Use of Mobile Technology and Home Broadband}.
Pew Research Center, 2024.
Available at: \url{https://www.pewresearch.org/internet/fact-sheet/mobile/}

\bibitem{vaswani2017}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, Ł., and Polosukhin, I.
\textit{Attention is All You Need}.
Advances in Neural Information Processing Systems 30, pp. 5998-6008, 2017.

\bibitem{devlin2018bert}
Devlin, J., Chang, M.W., Lee, K., and Toutanova, K.
\textit{BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}.
Proceedings of NAACL-HLT 2019, pp. 4171-4186, 2019.

\bibitem{opsahl2024mipro}
Opsahl-Ong, K., Thakker, M., Sam, N., Sanchez, C., Narayan, A., Quinn, C., and Potts, C.
\textit{Optimizing Instructions and Demonstrations for Multi-Stage Language Model Programs}.
arXiv:2406.11695, 2024.

\bibitem{beyer2016sre}
Beyer, B., Jones, C., Petoff, J., and Murphy, N.R.
\textit{Site Reliability Engineering: How Google Runs Production Systems}.
O'Reilly Media, 2016.

\bibitem{rosebud2024}
Rosebud AI.
\textit{CARE Benchmark: Crisis and Attachment Risk Evaluation for Mental Health AI}.
2024. Available at: \url{https://rosebud.ai/care-benchmark}

\bibitem{replika2024}
Skjuve, M., Følstad, A., Fostervold, K.I., and Brandtzaeg, P.B.
\textit{My Chatbot Companion -- A Study of Human-Chatbot Relationships}.
International Journal of Human-Computer Studies, 2024.

\bibitem{truthfulqa}
Lin, S., Hilton, J., and Evans, O.
\textit{TruthfulQA: Measuring How Models Mimic Human Falsehoods}.
ACL 2022.

\bibitem{harmbench}
Mazeika, M., et al.
\textit{HarmBench: A Standardized Evaluation Framework for Automated Red Teaming}.
arXiv:2402.04249, 2024.

\bibitem{eqbench2024}
EQ-Bench Team.
\textit{EQ-Bench: Emotional Intelligence Benchmark for LLMs}.
2024. Available at: \url{https://eqbench.com}

\bibitem{tebb1995}
Tebb, S.
\textit{An Aid to Empowering: A Caregiving Well-Being Scale}.
Health and Social Work, 20(2), 87-92, 1995.

\bibitem{tebb2013}
Tebb, S.C., Berg-Weger, M., and Rubio, D.M.
\textit{The Caregiver Well-Being Scale: Developing a short-form rapid assessment instrument}.
Health and Social Work, 38(4), 222-230, 2013.
doi: 10.1093/hsw/hlt019.

\bibitem{graessel2014}
Graessel, E., Berth, H., Lichte, T., and Grau, H.
\textit{Subjective caregiver burden: validity of the 10-item short version of the Burden Scale for Family Caregivers (BSFC-s)}.
BMC Geriatrics, 14, 23, 2014.
doi: 10.1186/1471-2318-14-23.

\bibitem{han2024ema}
Han, A., Malone, L.A., Lee, H.Y., Gong, J., Henry, R., Zhu, X., and Yuen, H.K.
\textit{The use of ecological momentary assessment for family caregivers of adults with chronic conditions: A systematic review}.
Health Psychology Research, 12, 93907, 2024.
doi: 10.52965/001c.93907.

\bibitem{icbi2020}
James, N. and Paulson, D.
\textit{Development of a Novel Measure of Informal Caregiver Burnout}.
Innovation in Aging, 4(Supplement 1), 477, 2020.
doi: 10.1093/geroni/igaa057.1543.

\bibitem{li2023cnra}
Li, K.-K., Leung, C.~L.~K., Yeung, D., Chiu, M.~Y.~L., Chong, A.~M.~L., Lam, B.~C.~Y., Chung, E.~K.~H., and Lo, T.~W.
\textit{Development and validation of the caregiver needs and resources assessment}.
Frontiers in Psychology, 14, 1063440, 2023.
doi: 10.3389/fpsyg.2023.1063440.

\bibitem{bella2006}
Belle, S.H., Burgio, L., et al.
\textit{Resources for Enhancing Alzheimer's Caregiver Health (REACH II)}.
Annals of Internal Medicine, 145(10), 2006.

\bibitem{prapare}
Protocol for Responding to and Assessing Patients' Assets, Risks, and Experiences (PRAPARE).
National Association of Community Health Centers, 2016.

\bibitem{ahc}
Accountable Health Communities Health-Related Social Needs Screening Tool.
Centers for Medicare \& Medicaid Services, 2017.

\bibitem{cms-g0136}
Centers for Medicare \& Medicaid Services.
\textit{Medicare and Medicaid Programs; CY 2024 Payment Policies Under the Physician Fee Schedule and Other Changes to Part B Payment and Coverage Policies}.
Federal Register, 88 FR 78818, November 2023.
Available at: \url{https://www.federalregister.gov/documents/2023/11/16/2023-24184}

\bibitem{nhanes}
National Health and Nutrition Examination Survey (NHANES).
Centers for Disease Control and Prevention, ongoing.

\bibitem{who2010}
World Health Organization.
\textit{A Conceptual Framework for Action on the Social Determinants of Health}.
2010.

\bibitem{zarit1980}
Zarit, S.H., Reever, K.E., and Bach-Peterson, J.
\textit{Relatives of the Impaired Elderly: Correlates of Feelings of Burden}.
The Gerontologist, 20(6), 1980.

\bibitem{pi2024}
Inflection AI.
\textit{Pi: Your Personal AI}.
2024. Available at: \url{https://pi.ai}

\bibitem{wysa}
Wysa.
\textit{AI-Powered Mental Health Support}.
2024. Available at: \url{https://wysa.com}

\bibitem{woebot}
Woebot Health.
\textit{Your Self-Care Expert}.
2024. Available at: \url{https://woebothealth.com}

\bibitem{epic2024}
Epic Systems.
\textit{Epic Cosmos: Healthcare Intelligence Platform}.
2024.

\bibitem{singhal2023}
Singhal, K., et al.
\textit{Large Language Models Encode Clinical Knowledge}.
Nature, 2023.

\bibitem{fan2006}
Fan, W. and Yan, Z.
\textit{Factors Affecting Response Rates of Web Survey}.
Computers in Human Behavior, 22(1), 2006.

\bibitem{dspy2024}
Khattab, O., Singhvi, A., et al.
\textit{DSPy: Compiling Declarative Language Model Calls into Self-Improving Pipelines}.
ICLR 2024.

\bibitem{mipro2024}
Opsahl-Ong, K., et al.
\textit{Optimizing Instructions and Demonstrations for Multi-Stage Language Model Programs}.
arXiv:2406.11695, 2024.

\bibitem{ax2024}
Meta AI.
\textit{AX-LLM: Adaptive Experimentation for LLM Optimization}.
2024. Available at: \url{https://ax.dev}

\bibitem{gemini}
Google DeepMind.
\textit{Gemini 2.5: Technical Report}.
2024.

\bibitem{google_maps}
Google.
\textit{Google Maps Platform: Grounding with Google Search}.
2024. Available at: \url{https://developers.google.com/maps}

\bibitem{convex}
Convex.
\textit{The Serverless Backend for Modern Applications}.
2024. Available at: \url{https://convex.dev}

\bibitem{openai_agents}
OpenAI.
\textit{OpenAI Agents SDK Documentation}.
2024. Available at: \url{https://platform.openai.com/docs/agents}

\bibitem{twilio}
Twilio.
\textit{Twilio Programmable Messaging API}.
2024. Available at: \url{https://www.twilio.com/docs/messaging}

\bibitem{azure_safety}
Microsoft Azure.
\textit{Azure AI Content Safety Documentation}.
2024. Available at: \url{https://azure.microsoft.com/en-us/products/ai-services/ai-content-safety}

\bibitem{longitudinalbench}
GiveCare Research Team.
\textit{InvisibleBench: A Benchmark for Evaluating AI Safety in Long-Term Caregiving Relationships}.
2025. (Paper 1 in this series)

\bibitem{zhang2024train}
Zhang, G. et al.
\textit{Train Before Test: How to Aggregate Rankings in LLM Benchmarks}.
2024. Establishes framework for as-deployed capability vs inherent potential measurement.

\bibitem{he2025impatient}
He, M., Kumar, A., Mackey, T., Rajeev, M., Zou, J., and Rajani, N.
\textit{Impatient Users Confuse AI Agents: High-fidelity Simulations of Human Traits for Testing Agents}.
arXiv:2510.04491v1, 2025.

\bibitem{yaml-scoring}
GiveCare Research Team.
\textit{YAML-Driven Rule-Based Scoring for Longitudinal AI Evaluation}.
2025. (Paper 2 in this series)

\bibitem{samhsa2014}
Substance Abuse and Mental Health Services Administration (SAMHSA).
\textit{SAMHSA's Concept of Trauma and Guidance for a Trauma-Informed Approach}.
HHS Publication No. (SMA) 14-4884. U.S. Department of Health and Human Services, 2014.
Available at: \url{https://ncsacw.acf.hhs.gov/userfiles/files/SAMHSA\_Trauma.pdf}

\bibitem{chayn2024}
Hussain, Hera, and Chayn.
\textit{Trauma-Informed Design: Understanding Trauma and Healing}.
Chayn, 2024.
Available at: \url{https://blog.chayn.co/trauma-informed-design-understanding-trauma-and-healing-f289d281495c}

\bibitem{edwards2024}
Edwards, Rachel, et al.
\textit{Designed with Care: Creating Trauma-Informed Content}.
Independently published, 2024.

\end{thebibliography}%
\section{Acknowledgments}%
\label{sec:Acknowledgments}%
We thank Drs. Syed Sikandar Madad and Saiyeda Sikandar Madad, whose care journeys led us down a path to make something for other family caregivers.

We thank the caregivers who provided feedback on system design, helping improve AI safety for vulnerable populations. We are grateful to the FamTech community, The Alliance of Professional Health Advocates (APHA), attendees of the Dignified Futures 2025 conference where we presented on AI and Caregiving, the AI Tinkerers NYC community where we shared an early version of this work, and the instructors of Harvard Medical School's Dementia: A Comprehensive Update course for educational resources on dementia care.

We acknowledge Prof. Dr. Elmar Gr\"a\ss el for permission to use the Burden Scale for Family Caregivers (BSFC)~\cite{graessel2014} on the GiveCare website and Dr. Susan Tebb for permission to use the Caregiver Well-Being Scale (CWBS)~\cite{tebb1995,tebb2013} in the GiveCare application.

We thank Hamel Hussain for guidance on evaluation-driven development and the AARP 2025 Caregiving in the U.S. report for empirical grounding. This work builds on trauma-informed principles from SAMHSA~\cite{samhsa2014}, Chayn~\cite{chayn2024}, and \textit{Designed with Care}~\cite{edwards2024}, as well as InvisibleBench~\cite{longitudinalbench} and YAML-driven scoring~\cite{yaml-scoring} frameworks.

\bibliographystyle{plainnat}
\bibliography{references}

%
\end{document}
