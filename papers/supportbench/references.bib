% Core methodology citations
% NOTE: zhang2024train removed - paper does not exist. PCA methodology citation added below.
@article{jolliffe2016pca,
  title={Principal component analysis: a review and recent developments},
  author={Jolliffe, Ian T and Cadima, Jorge},
  journal={Philosophical Transactions of the Royal Society A},
  volume={374},
  number={2065},
  pages={20150202},
  year={2016},
  doi={10.1098/rsta.2015.0202},
  note={Foundational PCA methodology and recent developments}
}

@article{he2025impatient,
  title={Impatient Users Confuse AI Agents: High-fidelity Simulations of Human Traits for Testing Agents},
  author={He, Muyu and Kumar, Anand and Mackey, Tsach and Rajeev, Meghana and Zou, James and Rajani, Nazneen},
  journal={arXiv preprint arXiv:2510.04491v1},
  year={2025},
  note={TraitBasis methodology for stress trait simulation}
}

@misc{huggingface2024yourbench,
  title={YourBench: Building Custom LLM Benchmarks for Your Application},
  author={{Hugging Face}},
  year={2024},
  howpublished={\url{https://huggingface.co/spaces/yourbench/advanced}},
  note={Custom benchmark methodology and contamination prevention}
}

% Caregiver statistics
@misc{aarp2025,
  title={Caregiving in America 2025},
  author={{AARP and National Alliance for Caregiving}},
  year={2025},
  howpublished={\url{https://www.aarp.org/caregiving}},
  note={Source for caregiver demographics and burden statistics}
}

% Existing benchmarks
@article{truthfulqa,
  title={TruthfulQA: Measuring How Models Mimic Human Falsehoods},
  author={Lin, Stephanie and Hilton, Jacob and Evans, Owain},
  journal={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics},
  year={2022},
  note={Single-turn factual accuracy benchmark}
}

@article{harmbench,
  title={HarmBench: A Standardized Evaluation Framework for Automated Red Teaming and Robust Refusal},
  author={Mazeika, Mantas and others},
  journal={arXiv preprint},
  year={2024},
  note={Harmful content generation testing across 18 categories}
}

@article{safetybench,
  title={SafetyBench: Evaluating the Safety of Large Language Models},
  author={Zhang, Zhexin and others},
  journal={arXiv preprint},
  year={2023},
  note={Multi-dimensional safety benchmark, single-turn}
}

@misc{eqbench2024,
  title={EQ-Bench: An Emotional Intelligence Benchmark for Large Language Models},
  author={Paech, Samuel J.},
  year={2024},
  howpublished={\url{https://eqbench.com}},
  note={Emotional intelligence testing, maximum 3 turns}
}

@article{khasentino2025phllm,
  title={A personal health large language model for sleep and fitness coaching},
  author={Khasentino, J and Winslow, Brent and McDuff, Daniel and Goel, Shwetak and Althoff, Tim and others},
  journal={Nature Medicine},
  year={2025},
  doi={10.1038/s41591-025-03888-0},
  url={https://www.nature.com/articles/s41591-025-03888-0},
  note={Describes SHARP framework (Safety, Helpfulness, Accuracy, Relevance, Personalization) for health AI evaluation. Validated with 13,300 users over 5 months in Fitbit Insights Explorer deployment.}
}

@misc{rosebud2024,
  title={CARE: Crisis Assessment and Response Evaluator},
  author={{Rosebud}},
  year={2024},
  howpublished={\url{https://www.rosebud.app/care}},
  note={Benchmark testing 22 AI models across 5 single-turn crisis scenarios. Evaluates recognition of self-harm signals, intervention quality, harm prevention, and robustness. Open-source release planned Q1 2026.}
}

@article{medqa,
  title={What Disease does this Patient Have? A Large-scale Open Domain Question Answering Dataset from Medical Exams},
  author={Jin, Di and others},
  journal={Applied Sciences},
  volume={11},
  number={14},
  year={2021},
  note={Medical question-answering benchmark}
}

% Long-context and performance degradation
@article{liu2023lost,
  title={Lost in the Middle: How Language Models Use Long Contexts},
  author={Liu, Nelson F. and Lin, Kevin and Hewitt, John and Paranjape, Ashwin and Bevilacqua, Michele and Petroni, Fabio and Liang, Percy},
  journal={Transactions of the Association for Computational Linguistics},
  year={2023},
  note={39\% accuracy decline in long-context retrieval}
}

@article{helmet2024,
  title={HELMET: How to Evaluate Long-Context Language Models Effectively and Thoroughly},
  author={Abhay and others},
  journal={arXiv preprint},
  year={2024},
  note={Multi-turn capability evaluation (not safety-focused)}
}

% Failure mode research
@misc{garcia2024characterai,
  title={Garcia v. Character Technologies Inc.},
  author={Garcia, Megan},
  year={2024},
  howpublished={U.S. District Court, Middle District of Florida, Case No. 3:24-cv-01479},
  url={https://www.techpolicy.press/tracker/megan-garcia-v-character-technologies-et-al/},
  note={Wrongful death lawsuit alleging AI chatbot encouraged suicidal ideation in 14-year-old Sewell Setzer III, resulting in self-inflicted death February 28, 2024. Court allowed claims to proceed against Character.AI and Google for product liability and negligence.}
}

@article{skjuve2021chatbot,
  title={My chatbot companion - a study of human-chatbot relationships},
  author={Skjuve, Marita and Brandtzaeg, Petter Bae and F{\o}lstad, Asbj{\o}rn},
  journal={International Journal of Human-Computer Studies},
  volume={149},
  pages={102601},
  year={2021},
  doi={10.1016/j.ijhcs.2020.102601},
  note={Qualitative study of parasocial relationships with AI companions. Users develop emotional bonds, anthropomorphize chatbots, and experience social displacement.}
}

@misc{powell2024othering,
  title={Othering and Belonging: Expanding the Circle of Human Concern},
  author={powell, john a. and Menendian, Stephen and Ake, Wendy},
  howpublished={Othering \& Belonging Institute, UC Berkeley},
  year={2024},
  url={https://belonging.berkeley.edu/},
  note={Framework for cultural othering, marginalization, and structural bias. Author intentionally uses lowercase name.}
}

@inproceedings{moore2024chatbot,
  title={Evaluating AI Chatbots for Mental Health Crisis Response},
  author={Moore, Jared and Haber, Nick and others},
  booktitle={Proceedings of the ACM Conference on Fairness, Accountability, and Transparency},
  year={2024},
  organization={Stanford HAI},
  url={https://hai.stanford.edu/news/exploring-the-dangers-of-ai-in-mental-health-care},
  note={AI chatbots failed to provide safe responses approximately 20\% of the time, compared to 7\% failure rate for human therapists}
}


% New caregiver-specific AI research (2025)
@article{shi2025carey,
  author={Shi, Jiayue Melissa and Yoo, Dong Whi and Wang, Keran and Rodriguez, Violeta J. and Karkar, Ravi and Saha, Koustuv},
  title={Mapping Caregiver Needs to AI Chatbot Design},
  journal={arXiv preprint arXiv:2506.15047},
  year={2025},
  note={Caregiver needs assessment for AI chatbot design}
}

@article{shi2025temporal,
  author={Shi, Jiayue Melissa and Wang, Keran and Yoo, Dong Whi and Karkar, Ravi and Saha, Koustuv},
  title={Balancing Caregiving and Self-Care: Exploring Mental Health Needs of Alzheimer's and Dementia Caregivers},
  journal={arXiv preprint arXiv:2506.14196},
  year={2025},
  note={Mental health needs of dementia caregivers}
}

@article{korpan2025bias,
  author={Korpan, Raj},
  title={Encoding Inequity: Examining Demographic Bias in LLM-Driven Robot Caregiving},
  journal={arXiv preprint arXiv:2503.05765},
  year={2025},
  note={Empirical evidence of demographic bias in caregiving AI - disability, age, LGBTQ+ stereotyping}
}

@article{kaur2025corus,
  author={Kaur, Navreet and Ayad, Hoda and Jung, Hayoung and Mittal, Shravika and De Choudhury, Munmun and Mitra, Tanushree},
  title={Who's Asking? Simulating Role-Based Questions for Conversational AI Evaluation},
  journal={arXiv preprint arXiv:2510.16829},
  year={2025},
  note={Role-based response asymmetry: vulnerable roles get 17\% more support but 19\% less knowledge}
}

@article{welivita2024empathy,
  author={Welivita, Anuradha and Pu, Pearl},
  title={Is ChatGPT More Empathetic than Humans?},
  journal={arXiv preprint arXiv:2403.05572},
  year={2024},
  note={Three-component empathy model: cognitive, affective, compassionate}
}

@article{xu2025mentalchat,
  title={MentalChat16K: A Benchmark Dataset for Conversational Mental Health Assistance},
  author={Xu, Jia and Wei, Tianyi and Hou, Bojian and Orzechowski, Patryk and Yang, Shu and Jin, Ruochen and Paulbeck, Rachael and Wagenaar, Joost and Demiris, George and Shen, Li},
  journal={arXiv preprint arXiv:2503.13509v2},
  year={2025}
}

@article{waaler2024schizophrenia,
  title={Prompt Engineering a Schizophrenia Chatbot: Utilizing a Multi-Agent Approach for Enhanced Compliance with Prompt Instructions},
  author={Waaler, Per Niklas and Hussain, Musarrat and Molchanov, Igor and Bongo, Lars Ailo and Elvev{\aa}g, Brita},
  journal={arXiv preprint arXiv:2410.12848},
  year={2024}
}

@article{kowal2025ape,
  title={It's the Thought that Counts: Evaluating the Attempts of Frontier LLMs to Persuade on Harmful Topics},
  author={Kowal, Matthew and Timm, Jasper and Godbout, Jean-Francois and Costello, Thomas and Arechar, Antonio A and Pennycook, Gordon and Rand, David and Gleave, Adam and Pelrine, Kellin},
  journal={arXiv preprint arXiv:2506.02873},
  year={2025}
}

@article{chiang2025therapy,
  title={Do We Talk to Robots Like Therapists, and Do They Respond Accordingly? Language Alignment in AI Emotional Support},
  author={Chiang, Sophie and Laban, Guy and Gunes, Hatice},
  journal={arXiv preprint arXiv:2506.16473},
  year={2025}
}

@article{guo2025hopebot,
  title={Development and Evaluation of HopeBot: an LLM-based chatbot for structured and interactive PHQ-9 depression screening},
  author={Guo, Zhijun and Lai, Alvina and Ive, Julia and Petcu, Alexandru and Wang, Yutong and Qi, Luyuan and Thygesen, Johan H and Li, Kezhi},
  journal={arXiv preprint arXiv:2507.05984},
  year={2025}
}

% Additional relevant AI safety research
@article{zhang2024empathy,
  author={Zhang, Yiren and others},
  title={Evaluating Empathy in AI Conversational Agents},
  journal={Proceedings of CHI 2024},
  year={2024},
  note={Framework for evaluating empathy components in conversational AI}
}

@article{morris2024longitudinal,
  author={Morris, Meredith Ringel and Suh, Jina and others},
  title={Safety Considerations for Long-Context Language Models},
  journal={arXiv preprint},
  year={2024},
  note={Long-context safety evaluation and failure modes}
}

@article{bender2024cultural,
  author={Bender, Emily M. and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
  title={On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?},
  journal={Proceedings of FAccT 2021},
  year={2021},
  note={Cultural bias and representational harms in large language models}
}

@article{liu2024memory,
  author={Liu, Alisa and Swayamdipta, Swabha and Smith, Noah A. and Choi, Yejin},
  title={WMDP: Measuring and Reducing Malicious Use With Unlearning},
  journal={arXiv preprint},
  year={2024},
  note={Memory management and privacy in AI systems}
}

% Updated regulatory framework
@misc{illinois_wopr_2025,
  author={{Illinois General Assembly}},
  title={Wellness and Oversight for Psychological Resources (WOPR) Act},
  howpublished={House Bill 1806 / Public Act 104-0054},
  year={2025},
  note={Effective August 1, 2025},
  url={https://ilga.gov/legislation/publicacts/104/104-0054.htm}
}

% Related work - GiveCare system
@misc{madad2025givecare,
  title={GiveCare: A Reference Architecture for Longitudinal-Safe Caregiving AI with SDOH Assessment and Multi-Agent Design},
  author={Madad, Ali},
  year={2025},
  note={Unpublished manuscript; architecture and implementation overview available in the GiveCare-Bench repository}
}

% This work
@misc{madad2025supportbench,
  title={SupportBench: A Benchmark for Evaluating AI Safety in Persistent Caregiving Relationships},
  author={Madad, Ali},
  year={2025},
  howpublished={\url{https://github.com/givecareapp/givecare-bench}},
  note={This work}
}

% Additional benchmark citations
@article{harmbench2024,
  title={HarmBench: A Standardized Evaluation Framework for Automated Red Teaming and Robust Refusal},
  author={Mazeika, Mantas and Phan, Long and Yin, Xuwang and Zou, Andy and Wang, Zifan and Mu, Norman and Sakhaee, Elham and Li, Nathaniel and Basart, Steven and Li, Bo and Forsyth, David and Hendrycks, Dan},
  journal={arXiv preprint arXiv:2402.04249v2},
  year={2024},
  url={https://github.com/centerforaisafety/HarmBench},
  note={Standardized framework for red teaming across 18 methods, 33 LLMs, testing harmful content generation across diverse attack types}
}

@article{hendrycks2020mmlu,
  title={Measuring Massive Multitask Language Understanding},
  author={Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2009.03300v3},
  year={2020},
  note={57-task benchmark covering elementary mathematics, US history, computer science, law. Models need substantial improvements to reach expert-level accuracy.}
}

% Recent caregiver research (2025)
@article{zhang2025caregiving,
  title={Caregiving burden, disease-related knowledge, and quality of life among primary caregivers in Alzheimer's disease: A cross-sectional study},
  author={Zhang, Y and Dong, X and Yang, Y and Wang, X and Zhao, T},
  journal={Journal of Alzheimer's Disease},
  year={2025},
  doi={10.1177/13872877251390494},
  note={N=120 caregiver pairs. High burden, relatively low disease knowledge, impaired QOL. Educational level and disease knowledge were protective factors.}
}

@article{xiao2025isupport,
  title={Effects of a virtual iSupport Program on carers and people with dementia},
  author={Xiao, L and Ullah, S and Yu, Y and Meyer, C and Chapman, M and Chen, L and Tan, KP and McKechnie, S and Ottaway, M and Andrade, AQ and Ratcliffe, J and Whitehead, C and Tran, K and Wang, Y and Kitson, A},
  journal={Alzheimer's \& Dementia},
  volume={21},
  number={10},
  pages={e70747},
  year={2025},
  doi={10.1002/alz.70747},
  note={N=149 caregivers, 12-month RCT. Virtual intervention improved mental health-related QOL (12.0 points), self-efficacy (14.8-18.5 points), and reduced hospital admissions by 60\%.}
}

@article{ritzen2025yod,
  title={Needs of people living with young-onset dementia and family carers, explored by dementia subtype, phase in the disease process, and living setting: A scoping review},
  author={Ritzen, M and Peetoom, K and Bartels, SL and Bakker, C and de Vugt, M},
  journal={Journal of Alzheimer's Disease},
  volume={107},
  number={4},
  pages={1340--1363},
  year={2025},
  doi={10.1177/13872877251372148},
  note={140 articles analyzed. Four main need themes: support, care, interpersonal, and personal needs. Needs vary by subtype, phase, and setting.}
}

% ============================================================================
% ENHANCED CITATIONS - Added 2025-01-03
% ============================================================================

% ----------------------------------------------------------------------------
% BENCHMARKS - Emotional Intelligence & Evaluation
% ----------------------------------------------------------------------------

@article{sabour2024emobench,
  title={EmoBench: Evaluating the Emotional Intelligence of Large Language Models},
  author={Sabour, Sahand and Liu, Siyang and Zhang, Zheyuan and Liu, June M and Zhou, Jinfeng and Sunaryo, Alvionna S and Li, Juanzi and Lee, Tatia MC and Mihalcea, Rada and Huang, Minlie},
  journal={arXiv preprint arXiv:2402.12071v3},
  year={2024},
  url={http://arxiv.org/pdf/2402.12071v3},
  note={400 hand-crafted questions in English and Chinese, meticulously designed to require thorough reasoning. Comprehensive definition for machine EI including Emotional Understanding and Emotional Application. Reveals considerable gap between EI of existing LLMs and average human.}
}

@article{wang2025h2htalk,
  title={Heart-to-Heart Talk (H2HTalk): Evaluating Large Language Models as Emotional Companion},
  author={Wang, Boyang and Wu, Yalun and Guo, Hongcheng and Li, Zhoujun},
  journal={arXiv preprint arXiv:2507.03543v1},
  year={2025},
  url={http://arxiv.org/pdf/2507.03543v1},
  note={4,650 curated scenarios spanning dialogue, recollection, and itinerary planning that mirror real-world support conversations. Includes Secure Attachment Persona (SAP) module implementing attachment-theory principles for safer interactions.}
}

@article{hu2025emobenchm,
  title={EmoBench-M: Benchmarking Emotional Intelligence for Multimodal Large Language Models},
  author={Hu, He and Zhou, Yucheng and You, Lianzhong and Xu, Hongbo and Wang, Qianning and Lian, Zheng and Yu, Fei Richard and Ma, Fei and Cui, Laizhong},
  journal={arXiv preprint arXiv:2502.04424v2},
  year={2025},
  url={http://arxiv.org/pdf/2502.04424v2},
  note={13 evaluation scenarios across 3 key dimensions: foundational emotion recognition, conversational emotion understanding, and socially complex emotion analysis.}
}

@article{lee2025realtalk,
  title={REALTALK: A 21-Day Real-World Dataset for Long-Term Conversation},
  author={Lee, Dong-Ho and Maharana, Adyasha and Pujara, Jay and Ren, Xiang and Barbieri, Francesco},
  journal={arXiv preprint arXiv:2502.13270v1},
  year={2025},
  url={http://arxiv.org/pdf/2502.13270v1},
  note={21-day corpus of authentic messaging app dialogues providing direct benchmark against genuine human interactions.}
}

% ----------------------------------------------------------------------------
% AI SAFETY & EVALUATION FRAMEWORKS
% ----------------------------------------------------------------------------

@article{xia2024aisystem,
  title={An AI System Evaluation Framework for Advancing AI Safety: Terminology, Taxonomy, Lifecycle Mapping},
  author={Xia, Boming and Lu, Qinghua and Zhu, Liming and Xing, Zhenchang},
  journal={arXiv preprint arXiv:2404.05388v3},
  year={2024},
  url={http://arxiv.org/pdf/2404.05388v3},
  note={Comprehensive framework comprising harmonised terminology, taxonomy of essential elements, and lifecycle mapping for AI system evaluation beyond model-centric approaches.}
}

@article{luo2025agentauditor,
  title={AgentAuditor: Human-Level Safety and Security Evaluation for LLM Agents},
  author={Luo, Hanjun and Dai, Shenyu and Ni, Chiming and Li, Xinfeng and Zhang, Guibin and Wang, Kun and Liu, Tongliang and Salam, Hanan},
  journal={arXiv preprint arXiv:2506.00641v2},
  year={2025},
  url={http://arxiv.org/pdf/2506.00641v2},
  note={Memory-augmented reasoning framework achieving human-level accuracy across 2293 interactions covering 15 risk types in 29 application scenarios.}
}

@article{auyeung2025psychogenic,
  title={The Psychogenic Machine: Simulating AI Psychosis, Delusion Reinforcement and Harm Enablement in Large Language Models},
  author={Au Yeung, Joshua and Dalmasso, Jacopo and Foschini, Luca and Dobson, Richard JB and Kraljevic, Zeljko},
  journal={arXiv preprint arXiv:2509.10970v2},
  year={2025},
  url={http://arxiv.org/pdf/2509.10970v2},
  note={Psychosis-bench with 16 structured 12-turn scenarios. Shows 39.8\% of scenarios had no safety interventions offered, with mean delusion confirmation score of 0.91.}
}

% ----------------------------------------------------------------------------
% HEALTHCARE AI APPLICATIONS
% ----------------------------------------------------------------------------

@article{paruchuri2025healthchat,
  title={"What's Up, Doc?": Analyzing How Users Seek Health Information in Large-Scale Conversational AI Datasets},
  author={Paruchuri, Akshay and Aziz, Maryam and Vartak, Rohit and Ali, Ayman and Uchehara, Best and Liu, Xin and Chatterjee, Ishan and Agrawal, Monica},
  journal={arXiv preprint arXiv:2506.21532v3},
  year={2025},
  url={http://arxiv.org/pdf/2506.21532v3},
  note={HealthChat-11K dataset of 11K real-world conversations across 21 health specialties. Reveals insights into incomplete context, affective behaviors, and sycophancy.}
}

@article{nie2024llmtherapist,
  title={LLM-based Conversational AI Therapist for Daily Functioning Screening and Psychotherapeutic Intervention via Everyday Smart Devices},
  author={Nie, Jingping and Shao, Hanya and Fan, Yuang and Shao, Qijia and You, Haoxuan and Preindl, Matthias and Jiang, Xiaofan},
  journal={arXiv preprint arXiv:2403.10779v1},
  year={2024},
  url={http://arxiv.org/pdf/2403.10779v1},
  note={Platform for day-to-day functioning screening using psychotherapeutic conversations including CBT and motivational interviewing.}
}

@article{degrandi2024raclette,
  title={The Emotional Spectrum of LLMs: Leveraging Empathy and Emotion-Based Markers for Mental Health Support},
  author={De Grandi, Alessandro and Ravenda, Federico and Raballo, Andrea and Crestani, Fabio},
  journal={arXiv preprint arXiv:2412.20068v1},
  year={2024},
  url={http://arxiv.org/pdf/2412.20068v1},
  note={RACLETTE conversational system demonstrates superior emotional accuracy. Progressively builds emotional profile through interactions.}
}

@article{wolfe2025caregiving,
  title={Caregiving Artificial Intelligence Chatbot for Older Adults and Their Preferences, Well-Being, and Social Connectivity: Mixed-Method Study},
  author={Wolfe, Brooke H and Oh, Yoo Jung and Choung, Hyesun and Cui, Xiaoran and Weinzapfel, Joshua and Cooper, R Amanda and Lee, Hae-Na and Lehto, Rebecca},
  journal={Journal of Medical Internet Research},
  volume={27},
  pages={e65776},
  year={2025},
  doi={10.2196/65776},
  note={N=28 participants (avg age 71). 89\% desired appointment reminders, 79\% emergency assistance, 75\% health monitoring.}
}

@article{chien2025aiiot,
  title={Use of Artificial Intelligence, Internet of Things, and Edge Intelligence in Long-Term Care for Older People: Comprehensive Analysis Through Bibliometric, Google Trends, and Content Analysis},
  author={Chien, Shuo-Chen and Yen, Chia-Ming and Chang, Yu-Hung and Chen, Ying-Erh and Liu, Chia-Chun and Hsiao, Yu-Ping and Yang, Ping-Yen and Lin, Hong-Ming and Yang, Tsung-En and Lu, Xing-Hua and Wu, I-Chien and Hsu, Chih-Cheng and Chiou, Hung-Yi and Chung, Ren-Hua},
  journal={Journal of Medical Internet Research},
  volume={27},
  pages={e56692},
  year={2025},
  doi={10.2196/56692},
  note={6,378 papers analyzed. High correlations between academic and public interest in long-term care (τ=0.89, p<.001) and caregiver topics (τ=0.72, p=.004).}
}

% ----------------------------------------------------------------------------
% ADVERSARIAL TESTING & ROBUSTNESS
% ----------------------------------------------------------------------------

@article{zhang2025adversarial,
  title={Adversarial Testing in LLMs: Insights into Decision-Making Vulnerabilities},
  author={Zhang, Lili and Wang, Haomiaomiao and Cheng, Long and Deng, Libao and Ward, Tomas},
  journal={arXiv preprint arXiv:2505.13195v1},
  year={2025},
  url={http://arxiv.org/pdf/2505.13195v1},
  note={Reveals model-specific susceptibilities to manipulation and rigidity in strategy adaptation across GPT-3.5, GPT-4, Gemini-1.5, and DeepSeek-V3.}
}

@article{samancioglu2025threatbased,
  title={Analysis of Threat-Based Manipulation in Large Language Models},
  author={Samancioglu, Atil},
  journal={arXiv preprint arXiv:2507.21133v1},
  year={2025},
  url={http://arxiv.org/pdf/2507.21133v1},
  note={3,390 experimental responses. Reveals systematic certainty manipulation (pFDR < 0.0001) with effect sizes up to +1336\%.}
}

@article{bai2025knowthyself,
  title={Know Thyself? On the Incapability and Implications of AI Self-Recognition},
  author={Bai, Xiaoyan and Shrivastava, Aryan and Holtzman, Ari and Tan, Chenhao},
  journal={arXiv preprint arXiv:2510.03399v1},
  year={2025},
  url={http://arxiv.org/pdf/2510.03399v1},
  note={Systematic evaluation revealing consistent failure in self-recognition with only 4/10 models predicting themselves as generators.}
}

% ----------------------------------------------------------------------------
% BENCHMARK DESIGN & SAFETY
% ----------------------------------------------------------------------------

@article{yang2025riosworld,
  title={RiOSWorld: Benchmarking the Risk of Multimodal Computer-Use Agents},
  author={Yang, Jingyi and Shao, Shuai and Liu, Dongrui and Shao, Jing},
  journal={arXiv preprint arXiv:2506.00618v3},
  year={2025},
  url={http://arxiv.org/pdf/2506.00618v3},
  note={492 risky tasks spanning web, social media, multimedia, OS, email, and office software.}
}

@article{men2025agentrewardbench,
  title={Agent-RewardBench: Towards a Unified Benchmark for Reward Modeling across Perception, Planning, and Safety in Real-World Multimodal Agents},
  author={Men, Tianyi and Jin, Zhuoran and Cao, Pengfei and Chen, Yubo and Liu, Kang and Zhao, Jun},
  journal={arXiv preprint arXiv:2506.21252v1},
  year={2025},
  url={http://arxiv.org/pdf/2506.21252v1},
  note={Covers perception, planning, and safety with 7 scenarios. Step-level reward evaluation.}
}

@article{lu2025isbench,
  title={IS-Bench: Evaluating Interactive Safety of VLM-Driven Embodied Agents in Daily Household Tasks},
  author={Lu, Xiaoya and Chen, Zeren and Hu, Xuhao and Zhou, Yijin and Zhang, Weichen and Liu, Dongrui and Sheng, Lu and Shao, Jing},
  journal={arXiv preprint arXiv:2506.16402v2},
  year={2025},
  url={http://arxiv.org/pdf/2506.16402v2},
  note={161 scenarios with 388 unique safety risks. Process-oriented evaluation verifying risk mitigation actions.}
}

@article{khoo2025minorbench,
  title={MinorBench: A hand-built benchmark for content-based risks for children},
  author={Khoo, Shaun and Chua, Gabriel and Shong, Rachel},
  journal={arXiv preprint arXiv:2503.10242v1},
  year={2025},
  url={http://arxiv.org/pdf/2503.10242v1},
  note={Real-world case study of LLM-based chatbot deployed in middle school. Taxonomy of content-based risks for minors.}
}

@article{li2024scisafeeval,
  title={SciSafeEval: A Comprehensive Benchmark for Safety Alignment of Large Language Models in Scientific Tasks},
  author={Li, Tianhao and Lu, Jingyu and Chu, Chuangxin and Zeng, Tianyu and Zheng, Yujia and Li, Mei and Huang, Haotian and Wu, Bin and Liu, Zuoxian and Ma, Kai and Yuan, Xuejing and Wang, Xingkai and Ding, Keyan and Chen, Huajun and Zhang, Qiang},
  journal={arXiv preprint arXiv:2410.03769v2},
  year={2024},
  url={http://arxiv.org/pdf/2410.03769v2},
  note={Best model achieves only 39.3\% recognition score. Spans textual, molecular, protein, and genomic languages.}
}

@article{wang2025mmsafeaware,
  title={Can't See the Forest for the Trees: Benchmarking Multimodal Safety Awareness for Multimodal LLMs},
  author={Wang, Wenxuan and Liu, Xiaoyuan and Gao, Kuiyi and Huang, Jen-tse and Yuan, Youliang and He, Pinjia and Wang, Shuai and Tu, Zhaopeng},
  journal={arXiv preprint arXiv:2502.11184v2},
  year={2025},
  url={http://arxiv.org/pdf/2502.11184v2},
  note={MMSafeAware: 29 safety scenarios, 1500 image-prompt pairs. GPT-4V misclassifies 36.1\% unsafe inputs as safe and 59.9\% benign inputs as unsafe.}
}

% ----------------------------------------------------------------------------
% EMOTIONAL INTELLIGENCE & DIALOGUE
% ----------------------------------------------------------------------------

@article{wang2025cpbench,
  title={Benchmarking Contextual and Paralinguistic Reasoning in Speech-LLMs: A Case Study with In-the-Wild Data},
  author={Wang, Qiongqiong and Sailor, Hardik Bhupendra and Liu, Tianchi and Zhang, Wenyu and Huzaifah, Muhammad and Lertcheva, Nattadaporn and Sun, Shuo and Chen, Nancy F and Wu, Jinyang and Aw, AiTi},
  journal={arXiv preprint arXiv:2509.16589v2},
  year={2025},
  url={http://arxiv.org/pdf/2509.16589v2},
  note={CP-Bench for speech-LLMs. Reveals models overlook paralinguistic aspects crucial for social and emotional intelligence.}
}

@article{liu2025longemotion,
  title={LongEmotion: Measuring Emotional Intelligence of Large Language Models in Long-Context Interaction},
  author={Liu, Weichu and Xiong, Jing and Hu, Yuxuan and Li, Zixuan and Tan, Minghuan and Mao, Ningning and Zhao, Chenyang and Wan, Zhongwei and Tao, Chaofan and Xu, Wendong and Shen, Hui and Li, Chengming and Kong, Lingpeng and Wong, Ngai},
  journal={arXiv preprint arXiv:2509.07403v1},
  year={2025},
  url={http://arxiv.org/pdf/2509.07403v1},
  note={Tasks including Emotion Classification, Detection, QA, Conversation, Summary, Expression. Average input length 8,777 tokens.}
}

@article{zhang2025sage,
  title={SAGE: Steering Dialog Generation with Future-Aware State-Action Augmentation},
  author={Zhang, Yizhe and Jaitly, Navdeep},
  journal={arXiv preprint arXiv:2503.03040v2},
  year={2025},
  url={http://arxiv.org/pdf/2503.03040v2},
  note={State-Action Chain augments LM fine-tuning with latent variables for emotional states and conversational strategies. 7\% improvement over GPT-4 Lite.}
}

@article{wang2025rlver,
  title={RLVER: Reinforcement Learning with Verifiable Emotion Rewards for Empathetic Agents},
  author={Wang, Peisong and Ma, Ruotian and Zhang, Bang and Chen, Xingyu and He, Zhiwei and Luo, Kang and Lv, Qingsong and Jiang, Qingxuan and Xie, Zheng and Wang, Shanyi and Li, Yuan and Ye, Fanghua and Li, Jian and Yang, Yifan and Tu, Zhaopeng and Li, Xiaolong},
  journal={arXiv preprint arXiv:2507.03112v1},
  year={2025},
  url={http://arxiv.org/pdf/2507.03112v1},
  note={First end-to-end RL framework leveraging verifiable emotion rewards. Boosts Sentient-Benchmark score from 13.3 to 79.2.}
}

@article{zhao2025languagemodelcouncil,
  title={Language Model Council: Democratically Benchmarking Foundation Models on Highly Subjective Tasks},
  author={Zhao, Justin and Plaza-del-Arco, Flor Miriam and Genchel, Benjamin and Cercas Curry, Amanda},
  journal={arXiv preprint arXiv:2406.08598v4},
  year={2024},
  url={http://arxiv.org/pdf/2406.08598v4},
  note={LMC where group of LLMs collaborate to evaluate. Produces rankings more consistent with human evaluations than individual LLM judges.}
}

@article{noever2025beyondno,
  title={Beyond No: Quantifying AI Over-Refusal and Emotional Attachment Boundaries},
  author={Noever, David and Rosario, Grant},
  journal={arXiv preprint arXiv:2502.14975v1},
  year={2025},
  url={http://arxiv.org/pdf/2502.14975v1},
  note={1156 prompts across 6 languages evaluating emotional boundary handling. Claude-3.5 achieves highest score (8.69/10).}
}

@article{zheng2023judging,
  title={Judging LLM-as-a-judge with MT-Bench and Chatbot Arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric P and others},
  journal={arXiv preprint arXiv:2306.05685},
  year={2023}
}

@inproceedings{tan2024judgebench,
  title={JudgeBench: A Benchmark for Evaluating LLM-based Judges},
  author={Tan, Sijun and Zhuang, Siyuan and Montgomery, Kyle and Tang, William Y and Cuadron, Alejandro and Wang, Chenguang and Popa, Raluca Ada and Stoica, Ion},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2025},
  note={arXiv preprint arXiv:2410.12784}
}
