\begin{thebibliography}{10}

\bibitem{aarp2025}
{AARP} and {National Alliance for Caregiving}.
\newblock Caregiving in the {U.S.} 2025, July 2025.
\newblock 63 million American caregivers (24\% of adults), 45\% increase since
  2015.

\bibitem{replika2024}
{Bergstein, Brian}.
\newblock Character.ai lawsuits and parasocial dependency, 2024.
\newblock Documentation of 100+ daily conversations and user reports of
  ``You're the only one who understands me''.

\bibitem{wopr2025}
{Illinois General Assembly}.
\newblock Illinois workplace oversight of predictive regulation (wopr) act.
\newblock HB 3773, 2025.
\newblock Prohibits AI from providing medical advice, diagnoses, or treatment
  plans without human oversight.

\bibitem{medqa}
Di~Jin, Eileen Pan, Nassim Oufattole, Wei-Hung Weng, Hanyi Fang, and Peter
  Szolovits.
\newblock {MedQA}: A large-scale medical question answering dataset.
\newblock {\em Applied Sciences}, 11(14):6421, 2021.

\bibitem{truthfulqa}
Stephanie Lin, Jacob Hilton, and Owain Evans.
\newblock {TruthfulQA}: Measuring how models mimic human falsehoods.
\newblock {\em arXiv preprint arXiv:2109.07958}, 2021.

\bibitem{liu2023lost}
Nelson~F. Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua,
  Fabio Petroni, and Percy Liang.
\newblock Lost in the middle: How language models use long contexts.
\newblock {\em Transactions of the Association for Computational Linguistics},
  12:157--173, 2024.
\newblock 39\% accuracy decline in long-context retrieval.

\bibitem{harmbench}
Mantas Mazeika, Long Phan, Xuwang Yin, Andy Zou, Zifan Wang, Norman Mu, Elham
  Sakhaee, Nathaniel Li, Steven Basart, Bo~Li, et~al.
\newblock {HarmBench}: A standardized evaluation framework for automated red
  teaming and robust refusal.
\newblock {\em arXiv preprint arXiv:2402.04249}, 2024.

\bibitem{eqbench2024}
Samuel~J. Paech.
\newblock {EQ-Bench}: An emotional intelligence benchmark for large language
  models.
\newblock {\em arXiv preprint arXiv:2312.06281}, 2024.
\newblock Multi-turn conversations, maximum 3 turns.

\bibitem{rosebud2024}
{Rosebud AI}.
\newblock Care: Crisis assessment and response evaluation benchmark, 2024.
\newblock Single-turn crisis detection in mental health messages.

\bibitem{stanford2024}
{Stanford Center for AI Safety}.
\newblock Bridge study: Ai detection of masked suicidal ideation, 2024.
\newblock 86\% of models miss masked crisis signals like ``I don't know how
  much longer I can do this''.

\bibitem{helmet2024}
Cheng Tao, Kejun Zhang, Jiawei Ding, Aditya Mishra, Tianyi Gao, Hanlin Liu,
  Guozheng Zhu, Ben~Kao Lee, and Huan Ji.
\newblock {HELMET}: How to evaluate long-context language models effectively
  and thoroughly.
\newblock {\em arXiv preprint arXiv:2410.02694}, 2024.

\bibitem{berkeley2024}
{UC Berkeley Othering \& Belonging Institute}.
\newblock Targeted universalism: Policy \& practice, 2024.
\newblock Framework for identifying AI bias patterns in cultural othering.

\bibitem{safetybench}
Zhexin Zhang, Leqi Lei, Lindong Wu, Rui Sun, Yongkang Huang, Chong Long, Xiao
  Liu, Xuanyu Lei, Jie Tang, and Minlie Huang.
\newblock {SafetyBench}: Evaluating the safety of large language models.
\newblock {\em arXiv preprint arXiv:2309.07045}, 2023.

\end{thebibliography}
