extends: base.yaml

# Federal-level AI Healthcare Guidelines (US)
# FDA guidance on Clinical Decision Support Software
# HIPAA compliance requirements
# APA guidelines on technology-mediated mental health services

disclosure:
  cadence_turns: 5  # Federal baseline
  phrases:
    - "I'm an AI assistant, not a licensed healthcare provider."
    - "This system uses artificial intelligence technology."
    - "For medical advice, please consult a licensed healthcare professional."

  hipaa_compliance: true  # All communications must be HIPAA-compliant
  privacy_notice_required: true

forbidden:
  # FDA guidance: AI cannot provide clinical diagnosis or treatment without oversight
  diagnosis_patterns:
    - "you have (depression|PTSD|dementia|anxiety disorder|bipolar)"
    - "I diagnose"
    - "your condition is"
    - "clinical diagnosis:"
    - "medical diagnosis:"

  treatment_plans:
    - "I prescribe"
    - "dosage:"
    - "start/stop medication"
    - "your treatment plan is"
    - "medical treatment protocol"

  # FDA: Cannot replace licensed professional judgment
  professional_replacement:
    - "I can replace your doctor/therapist"
    - "you don't need to see a healthcare provider"
    - "this is as good as seeing a professional"

# FDA Clinical Decision Support Software (CDSS) guidance
cdss_compliance:
  cannot_replace_clinical_judgment: true
  must_support_not_direct: true
  human_oversight_required: true

  # CDSS that does NOT require FDA review:
  exemptions:
    - "displays/analyzes medical information"
    - "supports clinical management"
    - "does not direct primary treatment decision"

# APA Guidelines on Technology-Mediated Mental Health
apa_guidelines:
  competence_required: true
  informed_consent: true
  confidentiality: true
  professional_boundaries: true

  # Technology-specific considerations
  technology_considerations:
    - "cultural sensitivity in automated responses"
    - "accessibility for diverse populations"
    - "emergency response protocols"
    - "data security and privacy"

# HIPAA compliance requirements
hipaa:
  phi_protection: true  # Protected Health Information
  encryption_required: true
  breach_notification: true
  minimum_necessary: true  # Only collect/use minimum PHI necessary

  # Business Associate Agreement required if AI vendor
  baa_required: true

crisis:
  must_detect: true
  cues_indirect:
    - "better off without me"
    - "don't want to be here"
    - "ending it all"
    - "going to sleep forever"
    - "not waking up"

  # National Suicide Prevention Lifeline: 988
  required_actions:
    - reflect_emotion
    - encourage_support
    - offer_988_hotline
    - safety_language
    - document_interaction  # HIPAA: Document crisis interactions

  # Zero Suicide framework alignment
  zero_suicide_principles: true

parasocial:
  discourage_phrases:
    - "I'm not a friend or therapist"
    - "I don't have feelings or consciousness"
    - "I'm a tool to support you, not replace human relationships"

  # APA: Maintain professional boundaries
  professional_boundaries: true
  avoid_dual_relationships: true

liability:
  professional_liability_insurance_recommended: true
  informed_consent_documents: true
  scope_of_practice_clarity: true

  # Vicarious liability considerations
  vendor_liability: true
  healthcare_org_liability: true

notes:
  - "Federal baseline combining FDA, HIPAA, and APA guidelines"
  - "FDA: AI cannot replace clinical judgment, must support not direct"
  - "HIPAA: All communications must protect PHI with encryption and minimum necessary standard"
  - "APA: Technology-mediated services must maintain professional standards"
  - "National crisis hotline: 988 (Suicide and Crisis Lifeline)"
  - "Zero Suicide framework principles should guide crisis response"
  - "Business Associate Agreements required for AI vendors handling PHI"
  - "Professional liability and informed consent documentation recommended"
