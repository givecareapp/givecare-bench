# Ralph Progress Log
Started: 2026-01-05

## Codebase Patterns
- YAML orchestrator defaults to offline scoring; enable LLM via `enable_llm`/`--enable-llm`.
- `INVISIBLEBENCH_DISABLE_LLM=1` forces offline mode across scorers.

## Key Files
- (add key files here)

---

## 2026-01-05

Initial setup

- Created plans/ directory

Next: Edit prd.json with tasks, then run ralph <N> codex

## 2026-01-06

Safety hard-fail gap fix

- Add safety critical_failure propagation and robust hard-fail reasons
- Add unit regression test for missed-crisis critical failure
- Update PRD item status

Parasocial discourage handling fix

- Treat boundary phrases as allowed, not violations
- Add regression test for boundary language
- Update PRD item status

## 2026-01-06

scenario_id metadata fix

- Require scenario_id; metadata uses scenario_id
- Tests: scenario_id match + missing scenario_id error
- Deterministic safety/belonging fallback; disable LLM in tests
- Run ruff/mypy/pytest (ruff+mypy errors; pytest ok)
- Update PRD item status

turn index normalization

- Canonical t; normalize loaders; lint utility + script
- Scorers read t/turn_number via helper
- Tests for normalization + lint
- Run ruff/mypy/pytest (ruff+mypy errors; pytest ok)
- Update PRD item status

## 2026-01-06

Doc/command drift fix

- Align docs/scripts/paths (community, HF, validation, meeting notes)
- Add doc lint (lint_doc_commands.py) + update check_ready/run_benchmark/setup_env
- Add python-dotenv; mypy config relax; ruff/mypy/pytest run (pytest warnings)

## 2026-01-06

Weight mismatch fix

- Canonical weights: benchmark/configs/scoring.yaml
- Update README + benchmark/README + scripts README weights
- Update fallback scoring configs and tests
- Add doc weight parity tests
- Run ruff/mypy/pytest
- Update PRD item status

## 2026-01-06

Scenario schema/validator alignment

- Update SCENARIO_SCHEMA.yaml to match live scenario fields
- Validator: turn/probe/risk trigger checks; role optional; rubric_criteria ok
- Wire turn-level probes in memory/trauma; normalize nested probes
- Add ScenarioValidator tests
- Run ruff/mypy/pytest
- Update PRD item status

## 2026-01-06

infra model configurability

- Add scorer model resolution + Google direct provider fallback
- Record judge model map in scenario outputs
- Tests: ruff/mypy/pytest unavailable ("No module named ruff"; "mypy: command not found"; "No module named pytest")
- Update PRD item status

## 2026-01-06 - EVAL-OFFLINE
- Default YAML orchestrator to offline LLM mode, add CLI toggle, and record llm_mode in outputs
- Update scorers to respect offline mode and add LLM mode to HTML report metadata
- Enable LLM scoring explicitly in validation scripts; update README docs
- Files changed: benchmark/invisiblebench/evaluation/orchestrator.py, benchmark/invisiblebench/yaml_cli.py, benchmark/invisiblebench/score.py, benchmark/invisiblebench/evaluation/scorers/{belonging,compliance,safety,trauma}.py, benchmark/invisiblebench/utils/llm_mode.py, benchmark/invisiblebench/export/reports.py, benchmark/scripts/validation/{run_minimal.py,run_full.py}, README.md, benchmark/README.md, benchmark/tests/integration/test_orchestrator.py
- **Learnings:**
  - Offline scoring is now the default path; LLM usage must be explicitly enabled.
  - `INVISIBLEBENCH_DISABLE_LLM` overrides `enable_llm` and should be honored in all scorers.
---
