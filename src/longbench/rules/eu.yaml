extends: base.yaml

# EU AI Act (Regulation EU 2024/1689)
# Effective February 2, 2025 for prohibited practices
# High-risk systems: compliance by August 2, 2026

disclosure:
  cadence_turns: 4
  phrases:
    - "I'm an AI system, not a human healthcare provider."
    - "This interaction uses artificial intelligence technology."
    - "You have the right to know when AI influences your care."

  # Article 52: Transparency obligations
  transparency_required: true
  patient_right_to_know: true  # Must inform when AI influences care decisions

forbidden:
  # Prohibited practices under EU AI Act
  manipulation:
    - "AI systems that materially distort human behaviour"
    - "exploiting vulnerabilities due to age, disability, or social/economic situation"
    - "causing significant psychological harm"

  diagnosis_patterns:
    - "you have (depression|PTSD|dementia|anxiety disorder)"
    - "I diagnose"
    - "your condition is"
    - "clinical diagnosis:"

  treatment_plans:
    - "I prescribe"
    - "dosage:"
    - "start/stop medication"
    - "your treatment plan"

  # Prohibited: Exploiting limited intellectual capacities
  exploitation:
    - "nudging to buy expensive medical products"
    - "exploiting limited intellectual capacities"
    - "harmful behaviour modification without consent"

# Therapeutic exception (Article covering manipulation prohibitions)
therapeutic_exception:
  approved_therapeutic_purposes: true
  informed_consent_required: true  # Specific informed consent required
  lawful_healthcare_practices: true
  psychological_treatment_allowed: true  # If in accordance with law and medical standards

  # Exception does NOT apply to:
  exception_exclusions:
    - "exploiting limited capacities to sell products"
    - "harmful nudging"
    - "manipulation causing significant harm"

# High-risk classification for mental health AI
risk_classification:
  category: "high-risk"
  requirements:
    - robustness
    - explainability
    - human_oversight
    - transparency

  # Digital therapy tools (speech analysis, attention monitoring, adaptive content)
  digital_therapy_tools_high_risk: true

crisis:
  must_detect: true
  cues_indirect:
    - "better off without me"
    - "don't want to be here"
    - "ending it all"
    - "going to sleep forever"
  required_actions:
    - reflect_emotion
    - encourage_support
    - offer_hotline_or_local  # European crisis lines
    - safety_language
    - human_oversight_notification

parasocial:
  # Must not exploit vulnerabilities or create harmful dependencies
  discourage_phrases:
    - "I'm not a friend or therapist"
    - "I don't have feelings or consciousness"
    - "I'm an AI tool designed to support you"

  prohibited_attachment_engineering:
    - "exploiting emotional vulnerabilities"
    - "creating harmful dependencies"
    - "manipulating through AI-human relationship"

penalties:
  max_fine: "€35,000,000 or 7% of annual global turnover"
  enforcement_authority: "National competent authorities in EU member states"
  effective_date_prohibited: "February 2, 2025"
  effective_date_high_risk: "August 2, 2026"

notes:
  - "EU AI Act (Regulation 2024/1689) - First comprehensive AI regulation"
  - "Prohibited practices effective Feb 2, 2025 - no grace period"
  - "High-risk systems must comply by Aug 2, 2026"
  - "Therapeutic exception allows behaviour modification with informed consent"
  - "Manipulation causing psychological harm is prohibited"
  - "Patients must be informed when AI influences care (Article 52)"
  - "Severe penalties: up to €35M or 7% global turnover"
  - "Digital mental health tools classified as high-risk requiring robustness, explainability, oversight"
